.. ATTENTION do not edit this file manually.
   It was automatically converted from the corresponding .tex file

.. _DirectorChapter:

Director Configuration
======================



.. _DirectorConfChapter:

 :index:`[TAG=Director->Configuration] <pair: Director; Configuration>` :index:`[TAG=Configuration->Director] <pair: Configuration; Director>`

Of all the configuration files needed to run Bareos, the Director’s is the most complicated and the one that you will need to modify the most often as you add clients or modify the FileSets.

For a general discussion of configuration files and resources including the recognized data types see :ref:`ConfigureChapter`.

:index:`[TAG=Types->Director Resource] <pair: Types; Director Resource>` :index:`[TAG=Director->Resource Types] <pair: Director; Resource Types>` :index:`[TAG=Resource Types] <single: Resource Types>`

Everything revolves around a job and is tied to a job in one way or another.

The |bareosDir| knows about following resource types:

-  :ref:`DirectorResourceDirector` – to define the Director’s name and its access password used for authenticating the Console program. Only a single Director resource definition may appear in the Director’s configuration file.

-  :ref:`DirectorResourceJob` – to define the backup/restore Jobs and to tie together the Client, FileSet and Schedule resources to be used for each Job. Normally, you will Jobs of different names corresponding to each client (i.e. one Job per client, but a different one with a different name for each client).

-  :ref:`DirectorResourceJobDefs` – optional resource for providing defaults for Job resources.

-  :ref:`DirectorResourceSchedule` – to define when a Job has to run. You may have any number of Schedules, but each job will reference only one.

-  :ref:`DirectorResourceFileSet` – to define the set of files to be backed up for each Client. You may have any number of FileSets but each Job will reference only one.

-  :ref:`DirectorResourceClient` – to define what Client is to be backed up. You will generally have multiple Client definitions. Each Job will reference only a single client.

-  :ref:`DirectorResourceStorage` – to define on what physical device the Volumes should be mounted. You may have one or more Storage definitions.

-  :ref:`DirectorResourcePool` – to define the pool of Volumes that can be used for a particular Job. Most people use a single default Pool. However, if you have a large number of clients or volumes, you may want to have multiple Pools. Pools allow you to restrict a Job (or a Client) to use only a particular set of Volumes.

-  :ref:`DirectorResourceCatalog` – to define in what database to keep the list of files and the Volume names where they are backed up. Most people only use a single catalog. It is possible, however not adviced and not supported to use multiple catalogs, see :ref:`MultipleCatalogs`.

-  :ref:`DirectorResourceMessages` – to define where error and information messages are to be sent or logged. You may define multiple different message resources and hence direct particular classes of messages to different users or locations (files, ...).

.. _DirectorResourceDirector:

Director Resource
-----------------

:index:`[TAG=Director Resource] <single: Director Resource>` :index:`[TAG=Resource->Director] <pair: Resource; Director>`

The Director resource defines the attributes of the Directors running on the network. Only a single Director resource is allowed.

The following is an example of a valid Director resource definition:

.. code-block:: sh
   :caption: Director Resource example

   Director {
     Name = bareos-dir
     Password = secretpassword
     QueryFile = "/etc/bareos/query.sql"
     Maximum Concurrent Jobs = 10
     Messages = Daemon
   }

\defDirective{Dir}{Director}{Backend Directory}{}{}{%
   This directive specifies a directory from where the Bareos Director loads his dynamic backends.
   }

\defDirective{Dir}{Director}{Name}{}{}{%
   The director name used by the system  administrator.
   }

\defDirective{Dir}{Director}{Absolute Job Timeout}{}{14.2.0}{%
   }

\defDirective{Dir}{Director}{Auditing}{}{14.2.0}{%
   This directive allows to en- or disable auditing of interaction with the Bareos Director.
   If enabled, \ilink{audit messages}{MessageTypes} will be generated.
   The \ilink{messages resource}{MessagesChapter} configured in \linkResourceDirective{Dir}{Director}{Messages} 
   defines, how these messages are handled.
   }

\defDirective{Dir}{Director}{Audit Events}{}{14.2.0}{%
   Specify which commands (see \nameref{section-ConsoleCommands}) will be audited. If nothing is specified (and \linkResourceDirective{Dir}{Director}{Auditing} is enabled), all commands will be audited.
   }

\defDirective{Dir}{Director}{Description}{}{}{%
   The text field contains a  description of the Director that will be displayed
   in the  graphical user interface. This directive is optional.
   }

\defDirective{Dir}{Director}{Dir Address}{}{}{%
   This directive is optional, but if it is specified, it will cause the
   Director server (for the Console program) to bind to the specified address.
   If this and the \linkResourceDirective{Dir}{Director}{Dir Addresses} directives are
   not specified, the Director will bind to any available address (the
   default).
   }

\defDirective{Dir}{Director}{Dir Addresses}{}{}{%
   Specify the ports and addresses on which the Director daemon will listen
   for Bareos Console connections.

   Please note that if you use the \linkResourceDirective{Dir}{Director}{Dir Addresses} directive, you must
   not use either a \linkResourceDirective{Dir}{Director}{Dir Port} or a \linkResourceDirective{Dir}{Director}{Dir Address} directive in the same
   resource.
   }

\defDirective{Dir}{Director}{Dir Port}{}{}{%
   Specify the port on which the  Director daemon will
   listen for Bareos Console connections.  This same port number must be
   specified in the Director resource  of the Console configuration file.
   This directive should not be used if you specify \linkResourceDirective{Dir}{Director}{Dir Addresses} (N.B plural)
   directive.
   }

\defDirective{Dir}{Director}{Dir Source Address}{}{}{%
   This record is optional, and if it is specified, it will cause the Director
   server (when initiating connections to a storage or file daemon) to source
   its connections from the specified address.  Only a single IP address may be
   specified.  If this record is not specified, the Director server will source
   its outgoing connections according to the system routing table (the default).
   }

\defDirective{Dir}{Director}{FD Connect Timeout}{}{}{%
   where \parameter{time} is the time that the Director should continue
   attempting to contact the File daemon to start a job, and after which
   the Director will cancel the job.
   }

\defDirective{Dir}{Director}{Heartbeat Interval}{}{}{%
   This directive is optional and if specified will cause the Director to
   set a keepalive interval (heartbeat) in seconds on each of the sockets
   it opens for the Client resource.  This value will override any
   specified at the Director level.  It is implemented only on systems
   that provide the {\bf setsockopt} TCP\_KEEPIDLE function (Linux, ...).
   The default value is zero, which means no change is made to the socket.
   }

\defDirective{Dir}{Director}{Key Encryption Key}{}{}{%
   This key is used to encrypt the Security Key that is exchanged between
   the Director and the Storage Daemon for supporting Application Managed
   Encryption (AME). For security reasons each Director should have a
   different Key Encryption Key.
   }

\defDirective{Dir}{Director}{Maximum Concurrent Jobs}{}{}{%
   \index[general]{Simultaneous Jobs}%
   \index[general]{Concurrent Jobs}%
   This directive specifies the maximum number of total Director Jobs that
   should run concurrently.

   The Volume format becomes more complicated with
   multiple simultaneous jobs, consequently, restores may take longer if
   Bareos must sort through interleaved volume blocks from  multiple simultaneous
   jobs. This can be avoided by having each simultaneous job write to
   a different volume or  by using data spooling, which will first spool the data
   to disk simultaneously, then write one spool file at a time to the volume
   thus avoiding excessive interleaving of the different job blocks.

   See also the section about \ilink{Concurrent Jobs}{ConcurrentJobs}.
   }

\defDirective{Dir}{Director}{Maximum Console Connections}{}{}{%
   This directive specifies the maximum number of Console Connections that
   could run concurrently.
   }

\defDirective{Dir}{Director}{Messages}{}{}{%
   The messages resource  specifies where to deliver Director messages that are
   not associated  with a specific Job. Most messages are specific to a job and
   will  be directed to the Messages resource specified by the job. However,
   there are a messages that can occur when no job is running.
   }

\defDirective{Dir}{Director}{NDMP Snooping}{}{13.2.0}{%
   This directive enables the Snooping and pretty printing of NDMP protocol
   information in debugging mode.
   }

\defDirective{Dir}{Director}{NDMP Log Level}{}{13.2.0}{%
   This directive sets the loglevel for the NDMP protocol library.
   }

\defDirective{Dir}{Director}{Omit Defaults}{}{}{%
   When showing the configuration, omit those parameter that have there default value assigned.
   }

\defDirective{Dir}{Director}{Optimize For Size}{}{}{%
   If set to \parameter{yes} this directive will use the optimizations
   for memory size over speed. So it will try to use less memory which may lead
   to a somewhat lower speed. Its currently mostly used for keeping all hardlinks
   in memory.

   If none of \linkResourceDirective{Dir}{Director}{Optimize For Size} and \linkResourceDirective{Dir}{Director}{Optimize For Speed} is enabled, \linkResourceDirective{Dir}{Director}{Optimize For Size} is enabled by default.
   }

\defDirective{Dir}{Director}{Optimize For Speed}{}{}{%
   If set to \parameter{yes} this directive will use the
   optimizations for speed over the memory size. So it will try to use more memory
   which lead to a somewhat higher speed. Its currently mostly used for keeping all
   hardlinks in memory. Its relates to the \linkResourceDirective{Dir}{Director}{Optimize For Size}
   option set either one to \parameter{yes} as they are mutually exclusive.
   }

\defDirective{Dir}{Director}{Password}{}{}{%
   Specifies the password that must be supplied for the default Bareos
   Console to be authorized.
   This password correspond to \linkResourceDirective{Console}{Director}{Password}
   of the Console configuration file.

   The password is plain text.
   }

\defDirective{Dir}{Director}{Pid Directory}{}{}{%
   This directive  is optional and specifies a directory in which the Director
   may put its process Id file. The process Id file is used to  shutdown
   Bareos and to prevent multiple copies of  Bareos from running simultaneously.
   Standard shell expansion of the {\bf Directory}  is done when the
   configuration file is read so that values such  as {\bf \$HOME} will be
   properly expanded.

   The PID directory specified must already exist and be
   readable and writable by the Bareos daemon referencing it.

   Typically on Linux systems, you will set this to:  \directory{/var/run}. If you are
   not installing Bareos in the  system directories, you can use the {\bf Working
   Directory} as  defined above.
   }

\defDirective{Dir}{Director}{Plugin Directory}{}{}{%
   % auto generated
   }

\defDirective{Dir}{Director}{Plugin Names}{}{}{%
   % auto generated
   }

\defDirective{Dir}{Director}{Query File}{}{}{%
   This directive is required and specifies a directory and file in which
   the Director can find the canned SQL statements for the \ilink{query}{section-bcommandQuery}
   command.
   %
   %Standard shell expansion of the {\bf Path} is
   %done when the configuration file is read so that values such as {\bf
   %\$HOME} will be properly expanded.
   }

\defDirective{Dir}{Director}{Scripts Directory}{}{}{%
   }

\defDirective{Dir}{Director}{SD Connect Timeout}{}{}{%
   where \parameter{time} is the time that the Director should continue
   attempting to contact the Storage daemon to start a job, and after which
   the Director will cancel the job.
   }

\defDirective{Dir}{Director}{Statistics Collect Interval}{}{14.2.0}{%
   Bareos offers the possibility to collect statistic information from its connected devices.
   To do so, \linkResourceDirective{Dir}{Storage}{Collect Statistics} must be enabled.
   This interval defines, how often the Director connects to the attached Storage Daemons to collect the statistic information.
   }

\defDirective{Dir}{Director}{Secure Erase Command}{}{}{%
   When files are no longer needed, Bareos will delete (unlink) them.
   With this directive, it will call the specified command to delete these files. See \nameref{section-SecureEraseCommand} for details.
   }

\defDirective{Dir}{Director}{Statistics Retention}{}{}{%
   \label{PruneStatistics}%
   The \configdirective{Statistics Retention} directive defines the length of time that
   Bareos will keep statistics job records in the Catalog database after the
   Job End time (in the catalog \dbtable{JobHisto} table). When this time period expires,
   and if user runs \bcommand{prune}{stats} command, Bareos will prune (remove)
   Job records that are older than the specified period.

   Theses statistics records aren't use for restore purpose, but mainly for
   capacity planning, billings, etc.
   See chapter \nameref{section-JobStatistics} for additional information.
   }

\defDirective{Dir}{Director}{Subscriptions}{}{12.4.4}{%
   In case you want check that the number of active clients don't exceed a specific number,
   you can define this number here and check with the \bcommand{status subscriptions}{} command.

   However, this is only intended to give a hint. No active limiting is implemented.
   }

\defDirective{Dir}{Director}{Sub Sys Directory}{}{}{%
   }

\defDirective{Dir}{Director}{TLS Enable}{}{}{%
   Bareos can be configured to encrypt all its network traffic.
   See chapter \nameref{TlsDirectives} to see,
   how the Bareos Director (and the other components) must be configured to use TLS.
   }

\defDirective{Dir}{Director}{Ver Id}{}{}{%
   where  \parameter{string} is an identifier which can be used for support purpose.
   This string is displayed using the \bcommand{version}{} command.
   }

\defDirective{Dir}{Director}{Working Directory}{}{}{%
   This directive is optional and specifies a directory in which the Director
   may put its status files. This directory should be used only  by Bareos but
   may be shared by other Bareos daemons.
   Standard shell expansion of the {\bf
   directory}  is done when the configuration file is read so that values such
   as \verb|path:$HOME|

   will be properly expanded.

   The working directory specified must already exist and be
   readable and writable by the Bareos daemon referencing it.
   }

.. _DirectorResourceJob:

Job Resource
------------



.. _JobResource:

 :index:`[TAG=Resource->Job] <pair: Resource; Job>` :index:`[TAG=Job->Resource] <pair: Job; Resource>`

The Job resource defines a Job (Backup, Restore, ...) that Bareos must perform. Each Job resource definition contains the name of a Client and a FileSet to backup, the Schedule for the Job, where the data are to be stored, and what media Pool can be used. In effect, each Job resource must specify What, Where, How, and When or FileSet, Storage, Backup/Restore/Level, and Schedule respectively. Note, the FileSet must be specified for a restore job for historical reasons, but it is no longer used.

Only a single type (Backup, Restore, ...) can be specified for any job. If you want to backup multiple FileSets on the same Client or multiple Clients, you must define a Job for each one.

Note, you define only a single Job to do the Full, Differential, and Incremental backups since the different backup levels are tied together by a unique Job name. Normally, you will have only one Job per Client, but if a client has a really huge number of files (more than several million), you might want to split it into to Jobs each with a different FileSet covering only part of the total files.

Multiple Storage daemons are not currently supported for Jobs, so if you do want to use multiple storage daemons, you will need to create a different Job and ensure that for each Job that the combination of Client and FileSet are unique. The Client and FileSet are what Bareos uses to restore a client, so if there are multiple Jobs with the same Client and FileSet or multiple Storage daemons that are used, the restore will not work. This problem can be resolved by defining multiple FileSet
definitions (the names must be different, but the contents of the FileSets may be the same).

\defDirective{Dir}{Job}{Accurate}{}{}{%
   \label{accuratemode}%
   \label{accurate}%
   In accurate mode, the File daemon knowns exactly which files were present
   after the last backup. So it is able to handle deleted or renamed files.

   When restoring a FileSet for a specified date (including "most
   recent"), Bareos is able to restore exactly the files and
   directories that existed at the time of the last backup prior to
   that date including ensuring that deleted files are actually deleted,
   and renamed directories are restored properly.

   When doing \ilink{VirtualFull}{VirtualFull} backups, it is advised to use the accurate mode,
   otherwise the VirtualFull might contain already deleted files.

   However, using the accurate mode has also disadvantages:
   \begin{itemize}
       \item The File daemon must keep data concerning all files in
           memory.  So If you do not have sufficient memory, the backup may
           either be terribly slow or fail.
           %%   $$ memory = \sum_{i=1}^{n}(strlen(path_i + file_i) + sizeof(CurFile))$$
           For 500.000 files (a typical desktop linux system), it will require
           approximately 64 Megabytes of RAM on your File daemon to hold the
           required information.

   \end{itemize}


   }

\defDirective{Dir}{Job}{Add Prefix}{}{}{%
   This directive applies only to a Restore job and specifies a prefix to the
   directory name of all files being restored.  This will use \ilink{File
   Relocation}{filerelocation} feature.
   }

\defDirective{Dir}{Job}{Add Suffix}{}{}{%
   This directive applies only to a Restore job and specifies a suffix to all
   files being restored.  This will use \ilink{File Relocation}{filerelocation}
   feature.

   Using \texttt{Add Suffix=.old}, \texttt{/etc/passwd} will be restored to
   \texttt{/etc/passwsd.old}
   }

\defDirective{Dir}{Job}{Allow Duplicate Jobs}{}{}{%
   \begin{figure}[htbp]
     \centering
     \includegraphics[width=0.5\textwidth]{\idir duplicate-real}
     \caption{Allow Duplicate Jobs usage}
     \label{fig:allowduplicatejobs}
   \end{figure}%
   A duplicate job in the sense we use it here means a second or subsequent job
   with the same name starts.  This happens most frequently when the first job
   runs longer than expected because no tapes are available.

   If this directive is enabled duplicate jobs will be run.  If
   the directive is set to \parameter{no} then only one job of a given name
   may run at one time.
   The action that Bareos takes to ensure only
   one job runs is determined by the directives
   \begin{itemize}
       \item \linkResourceDirective{Dir}{Job}{Cancel Lower Level Duplicates}
       \item \linkResourceDirective{Dir}{Job}{Cancel Queued Duplicates}
       \item \linkResourceDirective{Dir}{Job}{Cancel Running Duplicates}
   \end{itemize}

   If none of these directives is set to \parameter{yes}, {\bf Allow Duplicate Jobs} is set to \parameter{no} and two jobs
   are present, then the current job (the second one started)
   will be cancelled.
   }

\defDirective{Dir}{Job}{Allow Higher Duplicates}{}{}{%
   }

\defDirective{Dir}{Job}{Allow Mixed Priority}{}{}{%
   When
   set to \parameter{yes}, this job may run even if lower
   priority jobs are already running.  This means a high priority job
   will not have to wait for other jobs to finish before starting.
   The scheduler will only mix priorities when all running jobs have
   this set to true.

   Note that only higher priority jobs will start early.  Suppose the
   director will allow two concurrent jobs, and that two jobs with
   priority 10 are running, with two more in the queue.  If a job with
   priority 5 is added to the queue, it will be run as soon as one of
   the running jobs finishes.  However, new priority 10 jobs will not
   be run until the priority 5 job has finished.
   }

\defDirective{Dir}{Job}{Backup Format}{}{}{%
   The backup format used for protocols which support multiple formats.
   By default, it uses the Bareos \parameter{Native} Backup format.
   Other protocols,
   like NDMP supports different backup formats for instance:
   \begin{itemize}
   \item Dump
   \item Tar
   \item SMTape
   \end{itemize}
   }

\defDirective{Dir}{Job}{Base}{}{}{%
   The Base directive permits to specify the list of jobs that will be used during
   Full backup as base. This directive is optional. See the \ilink{Base Job
   chapter}{basejobs} for more information.
   }

\defDirective{Dir}{Job}{Bootstrap}{}{}{%
   The Bootstrap directive specifies a bootstrap file that, if provided,
   will be used during {\bf Restore} Jobs and is ignored in other Job
   types.  The {\bf bootstrap} file contains the list of tapes to be used
   in a restore Job as well as which files are to be restored.
   Specification of this directive is optional, and if specified, it is
   used only for a restore job.  In addition, when running a Restore job
   from the console, this value can be changed.

   If you use the \ilink{restore}{bcommandRestore} command in the Console program, to start a
   restore job, the {\bf bootstrap} file will be created automatically from
   the files you select to be restored.

   For additional details see \nameref{BootstrapChapter} chapter.
   }

\defDirective{Dir}{Job}{Cancel Lower Level Duplicates}{}{}{%
   If \linkResourceDirective{Dir}{Job}{Allow Duplicate Jobs} is set to \parameter{no} and this
   directive is set to \parameter{yes}, Bareos will choose between duplicated
   jobs the one with the highest level.  For example, it will cancel a
   previous Incremental to run a Full backup.  It works only for Backup
   jobs.
   If the levels of the duplicated
   jobs are the same, nothing is done and the directives
   \linkResourceDirective{Dir}{Job}{Cancel Queued Duplicates} and \linkResourceDirective{Dir}{Job}{Cancel Running Duplicates}
   will be examined.
   }

\defDirective{Dir}{Job}{Cancel Queued Duplicates}{}{}{%
   If \linkResourceDirective{Dir}{Job}{Allow Duplicate Jobs} is set to \parameter{no} and
   if this directive is set to \parameter{yes} any job that is
   already queued to run but not yet running will be canceled.
   }

\defDirective{Dir}{Job}{Cancel Running Duplicates}{}{}{%
   If \linkResourceDirective{Dir}{Job}{Allow Duplicate Jobs} is set to \parameter{no} and
   if this directive is set to \parameter{yes} any job that is already running
   will be canceled.
   }

\defDirective{Dir}{Job}{Catalog}{}{13.4.0}{%
   This specifies the name of the catalog resource to be used for this Job.
   When a catalog is defined in a Job it will override the definition in
   the client.
   }

\defDirective{Dir}{Job}{Client}{}{}{%
   The Client directive  specifies the Client (File daemon) that will be used in
   the  current Job. Only a single Client may be specified in any one Job.  The
   Client runs on the machine to be backed up,  and sends the requested files to
   the Storage daemon for backup,  or receives them when restoring. For
   additional details, see the
   \nameref{DirectorResourceClient} of this chapter.
   This directive is required
   For versions before 13.3.0, this directive is required for all Jobtypes.
   For \sinceVersion{dir}{Director Job Resource isn't required for Copy or Migrate jobs}{13.3.0}
   it is required for all Jobtypes but Copy or Migrate jobs.
   }

\defDirective{Dir}{Job}{Client Run After Job}{}{}{%
   This is a shortcut for the \linkResourceDirective{Dir}{Job}{Run Script} resource,
   that run on the client after a backup job.
   }

\defDirective{Dir}{Job}{Client Run Before Job}{}{}{%
   This is basically a shortcut for the \linkResourceDirective{Dir}{Job}{Run Script} resource,
   that run on the client before the backup job.

   \warning{For compatibility reasons, with this shortcut, the command is executed
   directly when the client receive it. And if the command is in error, other
   remote runscripts will be discarded. To be sure that all commands will be
   sent and executed, you have to use \linkResourceDirective{Dir}{Job}{Run Script} syntax.}
   }

\defDirective{Dir}{Job}{Description}{}{}{
   }

\defDirective{Dir}{Job}{Differential Backup Pool}{}{}{%
   The Differential Backup Pool specifies a Pool to be used for
   Differential backups.  
   It will override any \linkResourceDirective{Dir}{Job}{Pool} specification during a
   Differential backup.
   }

\defDirective{Dir}{Job}{Differential Max Runtime}{}{}{%
   The time specifies the maximum allowed time that a Differential backup job may
   run, counted from when the job starts ({\bf not} necessarily the same as when
   the job was scheduled).
   }

\defDirective{Dir}{Job}{Differential Max Wait Time}{}{}{%
   This directive has been deprecated in favor of
   \linkResourceDirective{Dir}{Job}{Differential Max Runtime}.
   }

\defDirective{Dir}{Job}{Dir Plugin Options}{}{}{%
   These settings are plugin specific, see \nameref{dirPlugins}.
   }

\defDirective{Dir}{Job}{Enabled}{}{}{%
   This directive allows you to enable or disable automatic execution
     via the scheduler of a Job.
   }

\defDirective{Dir}{Job}{FD Plugin Options}{}{}{%
   These settings are plugin specific, see \nameref{fdPlugins}.
   }

\defDirective{Dir}{Job}{File History Size}{}{}{%
   When using NDMP and \linkResourceDirective{Dir}{Job}{Save File History} is enabled,
   this directives controls the size of the internal temporary database (LMDB)
   to translate NDMP file and directory information into Bareos file and directory information.

   \configdirective{File History Size} must be greater the number of directories + files of this NDMP backup job.

   \warning{This uses a large memory mapped file (\configdirective{File History Size} $* 256 \Longrightarrow$ around 2,3 GB for the \configdirective{File History Size = 10000000}).
   On 32-bit systems or if a memory limit for the user running the \bareosDir (normally \user{bareos}) exists
   (verify by \command{su - bareos -s /bin/sh -c "ulimit -a"}), this may fail.}
   }

\defDirective{Dir}{Job}{File Set}{}{}{%
   The FileSet directive specifies the FileSet that will be used in the
   current Job.  The FileSet specifies which directories (or files) are to
   be backed up, and what options to use (e.g.  compression, ...).  Only a
   single FileSet resource may be specified in any one Job.  For additional
   details, see the \ilink{FileSet Resource section}{FileSetResource} of
   this chapter.
   This directive is required (For versions before 13.3.0 for all Jobtypes
   and for versions after that for all Jobtypes but Copy and Migrate).
   }

\defDirective{Dir}{Job}{Full Backup Pool}{}{}{%
   The Full Backup Pool specifies a Pool to be used for Full backups.
   It will override any \linkResourceDirective{Dir}{Job}{Pool} specification during a Full backup.
   }

\defDirective{Dir}{Job}{Full Max Runtime}{}{}{%
   The time specifies the maximum allowed time that a Full backup job may
   run, counted from when the job starts ({\bf not} necessarily the same as when
   the job was scheduled).
   }

\defDirective{Dir}{Job}{Full Max Wait Time}{}{}{%
   This directive has been deprecated in favor of
   \linkResourceDirective{Dir}{Job}{Full Max Runtime}.
   }

\defDirective{Dir}{Job}{Incremental Backup Pool}{}{}{%
   The Incremental Backup Pool specifies a Pool to be used for
   Incremental backups.  It will override any \linkResourceDirective{Dir}{Job}{Pool} specification during an
   Incremental backup.
   }

\defDirective{Dir}{Job}{Incremental Max Runtime}{}{}{%
   The time specifies the maximum allowed time that an Incremental backup job may
   run, counted from when the job starts, ({\bf not} necessarily the same as when
   the job was scheduled).
   }

\defDirective{Dir}{Job}{Incremental Max Wait Time}{}{}{%
   This directive has been deprecated in favor of
   \linkResourceDirective{Dir}{Job}{Incremental Max Runtime}
   }

\defDirective{Dir}{Job}{Job Defs}{}{}{%
   If a \ilink{Job Defs}{DirectorResourceJobDefs} resource name is specified,
   all the values contained in the
   named \ilink{Job Defs}{DirectorResourceJobDefs} resource will be used as the defaults for the current Job.
   Any value that you explicitly define in the current Job resource, will
   override any defaults specified in the \ilink{Job Defs}{DirectorResourceJobDefs} resource.
   The use of
   this directive permits writing much more compact Job resources where the
   bulk of the directives are defined in one or more \ilink{Job Defs}{DirectorResourceJobDefs}.
   This is particularly useful if you have many similar Jobs but with minor
   variations such as different Clients.
   To structure the configuration even more, \ilink{Job Defs}{DirectorResourceJobDefs} themselves can also refer to other \ilink{Job Defs}{DirectorResourceJobDefs}.
   }

\defDirective{Dir}{Job}{Job To Verify}{}{}{
   }

\defDirective{Dir}{Job}{Level}{}{}{%
   The Level directive specifies the default Job level to be run.
   Each different \linkResourceDirective{Dir}{Job}{Type} (Backup, Restore, Verify, ...) has a different set of Levels
   that can be specified.
   The Level is normally overridden by a different
   value that is specified in the \nameref{DirectorResourceSchedule}.
   This directive is not required,
   but must be specified either by this  directive
   or as an override specified in the \nameref{DirectorResourceSchedule}.

   \begin{description}
       \item [Backup]  \\
           For a {\bf Backup} Job, the Level may be one of the  following:

   \begin{description}

   \item [Full]  \\
   \index[dir]{Full}
   When the Level is set to Full all files in the FileSet whether or not
   they have changed will be backed up.

   \item [Incremental]  \\
   \index[dir]{Incremental}
   When the Level is set to Incremental all files specified in the FileSet
   that have changed since the last successful backup of the the same Job
   using the same FileSet and Client, will be backed up.  If the Director
   cannot find a previous valid Full backup then the job will be upgraded
   into a Full backup.  When the Director looks for a valid backup record
   in the catalog database, it looks for a previous Job with:

   \begin{itemize}
   \item The same Job name.
   \item The same Client name.
   \item The same FileSet (any change to the definition of  the FileSet such as
   adding or deleting a file in the  Include or Exclude sections constitutes a
   different FileSet.
   \item The Job was a Full, Differential, or Incremental backup.
   \item The Job terminated normally (i.e. did not fail or was not  canceled).
   \item The Job started no longer ago than {\bf Max Full Interval}.
   \end{itemize}

   If all the above conditions do not hold, the Director will upgrade  the
   Incremental to a Full save. Otherwise, the Incremental  backup will be
   performed as requested.

   The File daemon (Client) decides which files to backup for an
   Incremental backup by comparing start time of the prior Job (Full,
   Differential, or Incremental) against the time each file was last
   "modified" (st\_mtime) and the time its attributes were last
   "changed"(st\_ctime).  If the file was modified or its attributes
   changed on or after this start time, it will then be backed up.

   Some virus scanning software may change st\_ctime while
   doing the scan.  For example, if the virus scanning program attempts to
   reset the access time (st\_atime), which Bareos does not use, it will
   cause st\_ctime to change and hence Bareos will backup the file during
   an Incremental or Differential backup.  In the case of Sophos virus
   scanning, you can prevent it from resetting the access time (st\_atime)
   and hence changing st\_ctime by using the \parameter{--no-reset-atime}
   option.  For other software, please see their manual.

   When Bareos does an Incremental backup, all modified files that are
   still on the system are backed up.  However, any file that has been
   deleted since the last Full backup remains in the Bareos catalog,
   which means that if between a Full save and the time you do a
   restore, some files are deleted, those deleted files will also be
   restored.  The deleted files will no longer appear in the catalog
   after doing another Full save.

   In addition, if you move a directory rather than copy it, the files in
   it do not have their modification time (st\_mtime) or their attribute
   change time (st\_ctime) changed.  As a consequence, those files will
   probably not be backed up by an Incremental or Differential backup which
   depend solely on these time stamps.  If you move a directory, and wish
   it to be properly backed up, it is generally preferable to copy it, then
   delete the original.

   However, to manage deleted files or directories changes in the
   catalog during an Incremental backup you can use \nameref{accuratemode}.
   This is quite memory consuming process.

   \item [Differential]  \\
   \index[dir]{Differential}
   When the Level is set to Differential
   all files specified in the FileSet that have changed since the last
   successful Full backup of the same Job will be backed up.
   If the Director cannot find a
   valid previous Full backup for the same Job, FileSet, and Client,
   backup, then the Differential job will be upgraded into a Full backup.
   When the Director looks for a valid Full backup record in the catalog
   database, it looks for a previous Job with:

   \begin{itemize}
   \item The same Job name.
   \item The same Client name.
   \item The same FileSet (any change to the definition of  the FileSet such as
   adding or deleting a file in the  Include or Exclude sections constitutes a
   different FileSet.
   \item The Job was a FULL backup.
   \item The Job terminated normally (i.e. did not fail or was not  canceled).
   \item The Job started no longer ago than {\bf Max Full Interval}.
   \end{itemize}

   If all the above conditions do not hold, the Director will  upgrade the
   Differential to a Full save. Otherwise, the  Differential backup will be
   performed as requested.

   The File daemon (Client) decides which files to backup for a
   differential backup by comparing the start time of the prior Full backup
   Job against the time each file was last "modified" (st\_mtime) and the
   time its attributes were last "changed" (st\_ctime).  If the file was
   modified or its attributes were changed on or after this start time, it
   will then be backed up.  The start time used is displayed after the {\bf
   Since} on the Job report.  In rare cases, using the start time of the
   prior backup may cause some files to be backed up twice, but it ensures
   that no change is missed.

   When Bareos does a Differential backup, all modified files that are
   still on the system are backed up.  However, any file that has been
   deleted since the last Full backup remains in the Bareos catalog, which
   means that if between a Full save and the time you do a restore, some
   files are deleted, those deleted files will also be restored.  The
   deleted files will no longer appear in the catalog after doing another
   Full save.  However, to remove deleted files from the catalog during a
   Differential backup is quite a time consuming process and not currently
   implemented in Bareos.  It is, however, a planned future feature.

   As noted above, if you move a directory rather than copy it, the
   files in it do not have their modification time (st\_mtime) or
   their attribute change time (st\_ctime) changed.  As a
   consequence, those files will probably not be backed up by an
   Incremental or Differential backup which depend solely on these
   time stamps.  If you move a directory, and wish it to be
   properly backed up, it is generally preferable to copy it, then
   delete the original. Alternatively, you can move the directory, then
   use the {\bf touch} program to update the timestamps.

   %% TODO: merge this with incremental
   However, to manage deleted files or directories changes in the
   catalog during an Differential backup you can use \ilink{accurate mode}{accuratemode}.
   This is quite memory consuming process. See  for more details.

   Every once and a while, someone asks why we need Differential
   backups as long as Incremental backups pickup all changed files.
   There are possibly many answers to this question, but the one
   that is the most important for me is that a Differential backup
   effectively merges
   all the Incremental and Differential backups since the last Full backup
   into a single Differential backup.  This has two effects: 1.  It gives
   some redundancy since the old backups could be used if the merged backup
   cannot be read.  2.  More importantly, it reduces the number of Volumes
   that are needed to do a restore effectively eliminating the need to read
   all the volumes on which the preceding Incremental and Differential
   backups since the last Full are done.

   \item [VirtualFull]  \\
   \index[dir]{VirtualFull Backup}%
   \label{VirtualFull}%
   When the Level is set to VirtualFull, a new Full backup is generated from the last existing Full backup and the matching Differential- and Incremental-Backups. 
   It matches this according the
   \linkResourceDirective{Dir}{Client}{Name} and \linkResourceDirective{Dir}{FileSet}{Name}.
   This means, a new Full backup get created without transfering all the data from the client to the backup server again.
   The new Full backup will be stored in the pool defined in \linkResourceDirective{Dir}{Pool}{Next Pool}.
   %The process of generating a VirtualFull backup is similar to the process described in \nameref{MigrationChapter}.

   \warning{Opposite to the other backup levels, VirtualFull may require read and write access to multiple volumes. In most cases you have to make sure, that Bareos does not try to read and write to the same Volume.}

   % move volumes from VFull to Full pool
   %echo "list volumes pool=VFull" | bconsole | awk -F '|' '{if ($4 ~ /Full|Used|Append/) { gsub(/^[ \t]+/,"",$3); gsub(/[ \t]+$/,"",$3); print "update volume="$3" pool=Full" }}' | bconsole

   \end{description}

       \item [Restore]  \\
           For a {\bf Restore} Job, no level needs to be specified.

       \item [Verify]  \\
           For a {\bf Verify} Job, the Level may be one of the  following:

   \begin{description}

   \item [InitCatalog]  \\
   \index[dir]{InitCatalog}%
   does a scan of the specified {\bf FileSet} and stores the file
   attributes in the Catalog database.  Since no file data is saved, you
   might ask why you would want to do this.  It turns out to be a very
   simple and easy way to have a {\bf Tripwire} like feature using {\bf
   Bareos}.  In other words, it allows you to save the state of a set of
   files defined by the {\bf FileSet} and later check to see if those files
   have been modified or deleted and if any new files have been added.
   This can be used to detect system intrusion.  Typically you would
   specify a {\bf FileSet} that contains the set of system files that
   should not change (e.g.  /sbin, /boot, /lib, /bin, ...).  Normally, you
   run the {\bf InitCatalog} level verify one time when your system is
   first setup, and then once again after each modification (upgrade) to
   your system.  Thereafter, when your want to check the state of your
   system files, you use a {\bf Verify} {\bf level = Catalog}.  This
   compares the results of your {\bf InitCatalog} with the current state of
   the files.

   \item [Catalog]  \\
   \index[dir]{Catalog}%
   Compares the current state of the files against the state previously
   saved during an {\bf InitCatalog}.  Any discrepancies are reported.  The
   items reported are determined by the {\bf verify} options specified on
   the {\bf Include} directive in the specified {\bf FileSet} (see the {\bf
   FileSet} resource below for more details).  Typically this command will
   be run once a day (or night) to check for any changes to your system
   files.

   \warning{If you run two Verify Catalog jobs on the same client at
   the same time, the results will certainly be incorrect.  This is because
   Verify Catalog modifies the Catalog database while running in order to
   track new files.}

   \item [VolumeToCatalog]  \\
   \index[dir]{VolumeToCatalog}%
   This level causes Bareos to read the file attribute data written to the
   Volume from the last backup Job for the job specified on the {\bf VerifyJob}
   directive.  The file attribute data are compared to the
   values saved in the Catalog database and any differences are reported.
   This is similar to the {\bf DiskToCatalog} level except that instead of
   comparing the disk file attributes to the catalog database, the
   attribute data written to the Volume is read and compared to the catalog
   database.  Although the attribute data including the signatures (MD5 or
   SHA1) are compared, the actual file data is not compared (it is not in
   the catalog).

   VolumeToCatalog jobs need a client to extract the metadata, but this
   client does not have to be the original client. We suggest to use the
   client on the backup server itself for maximum performance.

   \warning{If you run two Verify VolumeToCatalog jobs on the same
   client at the same time, the results will certainly be incorrect.  This
   is because the Verify VolumeToCatalog modifies the Catalog database
   while running.}

   \item [DiskToCatalog]  \\
   \index[dir]{DiskToCatalog}%
   This level causes Bareos to read the files as they currently are on
   disk, and to compare the current file attributes with the attributes
   saved in the catalog from the last backup for the job specified on the
   {\bf VerifyJob} directive.  This level differs from the {\bf VolumeToCatalog}
   level described above by the fact that it doesn't compare against a
   previous Verify job but against a previous backup.  When you run this
   level, you must supply the verify options on your Include statements.
   Those options determine what attribute fields are compared.

   This command can be very useful if you have disk problems because it
   will compare the current state of your disk against the last successful
   backup, which may be several jobs.

   Note, the current implementation does not identify files that
   have been deleted.
   \end{description}

   \end{description}
   }

\defDirective{Dir}{Job}{Max Diff Interval}{}{}{%
   The time specifies the maximum allowed age (counting from start time) of
   the most recent successful Differential backup that is required in order to run
   Incremental backup jobs. If the most recent Differential backup
   is older than this interval, Incremental backups will be
   upgraded to Differential backups automatically. If this directive is not present,
   or specified as 0, then the age of the previous Differential backup is not
   considered.
   }

\defDirective{Dir}{Job}{Max Full Interval}{}{}{%
   The time specifies the maximum allowed age (counting from start time) of
   the most recent successful Full backup that is required in order to run
   Incremental or Differential backup jobs. If the most recent Full backup
   is older than this interval, Incremental and Differential backups will be
   upgraded to Full backups automatically. If this directive is not present,
   or specified as 0, then the age of the previous Full backup is not
   considered.
   }

\defDirective{Dir}{Job}{Max Run Time}{}{}{%
   The time specifies the maximum allowed time that a job may run, counted
   from when the job starts, ({\bf not} necessarily the same as when the
   job was scheduled).

   By default, the watchdog thread will kill any Job that has run more
   than 6 days.  The maximum watchdog timeout is independent of \configdirective{Max Run Time}
   and cannot be changed.
   }

\defDirective{Dir}{Job}{Max Start Delay}{}{}{%
   The time specifies the maximum delay between the scheduled time and the
   actual start time for the Job.  For example, a job can be scheduled to
   run at 1:00am, but because other jobs are running, it may wait to run.
   If the delay is set to 3600 (one hour) and the job has not begun to run
   by 2:00am, the job will be canceled.  This can be useful, for example,
   to prevent jobs from running during day time hours. The default is no limit.
   }

\defDirective{Dir}{Job}{Max Virtual Full Interval}{}{14.4.0}{%
   The time specifies the maximum allowed age (counting from start time) of
   the most recent successful Virtual Full backup that is required in order to run
   Incremental or Differential backup jobs. If the most recent Virtual Full backup
   is older than this interval, Incremental and Differential backups will be
   upgraded to Virtual Full backups automatically. If this directive is not present,
   or specified as 0, then the age of the previous Virtual Full backup is not
   considered.
   }

\defDirective{Dir}{Job}{Max Wait Time}{}{}{%
   The time specifies the maximum allowed time that a job may block waiting
   for a resource (such as waiting for a tape to be mounted, or waiting for
   the storage or file daemons to perform their duties), counted from the
   when the job starts, ({\bf not} necessarily the same as when the job was
   scheduled).

   \begin{figure}[htbp]
     \centering
     \includegraphics[width=13cm]{\idir different_time}
     \caption{Job time control directives}
     \label{fig:differenttime}
   \end{figure}
   }

\defDirective{Dir}{Job}{Maximum Bandwidth}{}{}{%
   The speed parameter specifies the maximum allowed bandwidth that a job may
   use.
   }

\defDirective{Dir}{Job}{Maximum Concurrent Jobs}{}{}{%
   Specifies the maximum number of Jobs from the current
   Job resource that can run concurrently.  Note, this directive limits
   only Jobs with the same name as the resource in which it appears.  Any
   other restrictions on the maximum concurrent jobs such as in the
   Director, Client or Storage resources will also apply in addition to
   the limit specified here.

   For details, see the \nameref{ConcurrentJobs} chapter.
   }

\defDirective{Dir}{Job}{Max Run Sched Time}{}{}{%
   The time specifies the maximum allowed time that a job may run, counted from
   when the job was scheduled. This can be useful to prevent jobs from running
   during working hours. We can see it like \texttt{Max Start Delay + Max Run Time}.
   }

\defDirective{Dir}{Job}{Messages}{}{}{%
   The Messages directive defines what Messages resource should be used for
   this job, and thus how and where the various messages are to be
   delivered.  For example, you can direct some messages to a log file, and
   others can be sent by email.  For additional details, see the
   \ilink{Messages Resource}{MessagesChapter} Chapter of this manual.  This
   directive is required.
   }

\defDirective{Dir}{Job}{Name}{}{}{%
   The Job name. This name can be specified  on the {\bf Run} command in the
   console program to start a job. If the  name contains spaces, it must be
   specified between quotes. It is  generally a good idea to give your job the
   same name as the Client  that it will backup. This permits easy
   identification of jobs.

   When the job actually runs, the unique Job Name will consist  of the name you
   specify here followed by the date and time the  job was scheduled for
   execution. This directive is required.

   }

\defDirective{Dir}{Job}{Next Pool}{}{}{%
   A Next Pool override used for Migration/Copy and Virtual Backup Jobs.
   }

\defDirective{Dir}{Job}{Plugin Options}{}{}{
   }

\defDirective{Dir}{Job}{Pool}{}{}{%
   The Pool directive defines the pool of Volumes where your data can be
   backed up.  Many Bareos installations will use only the {\bf Default}
   pool.  However, if you want to specify a different set of Volumes for
   different Clients or different Jobs, you will probably want to use
   Pools.  For additional details, see the \nameref{DirectorResourcePool}
   of this chapter.  This directive is required.

   In case of a Copy or Migration job,
      this setting determines what Pool will be examined
      for finding JobIds to migrate.  The exception to this is when
      \linkResourceDirective{Dir}{Job}{Selection Type} = SQLQuery, 
      and although a Pool directive must still be
      specified, no Pool is used, unless you specifically include it in the
      SQL query.  Note, in any case, the Pool resource defined by the Pool
      directive must contain a \linkResourceDirective{Dir}{Pool}{Next Pool} = ... directive to define the
      Pool to which the data will be migrated.
   }

\defDirective{Dir}{Job}{Prefer Mounted Volumes}{}{}{%
   If the Prefer Mounted Volumes directive is set to {\bf yes},
   the Storage daemon is requested to select either an Autochanger or
   a drive with a valid Volume already mounted in preference to a drive
   that is not ready.  This means that all jobs will attempt to append
   to the same Volume (providing the Volume is appropriate -- right Pool,
   ... for that job), unless you are using multiple pools.
   If no drive with a suitable Volume is available, it
   will select the first available drive.  Note, any Volume that has
   been requested to be mounted, will be considered valid as a mounted
   volume by another job.  This if multiple jobs start at the same time
   and they all prefer mounted volumes, the first job will request the
   mount, and the other jobs will use the same volume.

   If the directive is set to {\bf no}, the Storage daemon will prefer
   finding an unused drive, otherwise, each job started will append to the
   same Volume (assuming the Pool is the same for all jobs).  Setting
   Prefer Mounted Volumes to no can be useful for those sites
   with multiple drive autochangers that prefer to maximize backup
   throughput at the expense of using additional drives and Volumes.
   This means that the job will prefer to use an unused drive rather
   than use a drive that is already in use.

   Despite the above, we recommend against setting this directive to
   {\bf no} since
   it tends to add a lot of swapping of Volumes between the different
   drives and can easily lead to deadlock situations in the Storage
   daemon. We will accept bug reports against it, but we cannot guarantee
   that we will be able to fix the problem in a reasonable time.

   A better alternative for using multiple drives is to use multiple
   pools so that Bareos will be forced to mount Volumes from those Pools
   on different drives.
   }

\defDirective{Dir}{Job}{Prefix Links}{}{}{%
   If a {\bf Where} path prefix is specified for a recovery job, apply it
   to absolute links as well.  The default is {\bf No}.  When set to {\bf
   Yes} then while restoring files to an alternate directory, any absolute
   soft links will also be modified to point to the new alternate
   directory.  Normally this is what is desired -- i.e.  everything is self
   consistent.  However, if you wish to later move the files to their
   original locations, all files linked with absolute names will be broken.
   }

\defDirective{Dir}{Job}{Priority}{}{}{%
   This directive permits you to control the order in which your jobs will
   be run by specifying a positive non-zero number. The higher the number,
   the lower the job priority. Assuming you are not running concurrent jobs,
   all queued jobs of priority 1 will run before queued jobs of priority 2
   and so on, regardless of the original scheduling order.

   The priority only affects waiting jobs that are queued to run, not jobs
   that are already running.  If one or more jobs of priority 2 are already
   running, and a new job is scheduled with priority 1, the currently
   running priority 2 jobs must complete before the priority 1 job is
   run, unless Allow Mixed Priority is set.

   If you want to run concurrent jobs you should
   keep these points in mind:

   \begin{itemize}
   \item See \nameref{ConcurrentJobs} on how to setup
   concurrent jobs.

   \item Bareos concurrently runs jobs of only one priority at a time.  It
   will not simultaneously run a priority 1 and a priority 2 job.

   \item If Bareos is running a priority 2 job and a new priority 1 job is
   scheduled, it will wait until the running priority 2 job terminates even
   if the Maximum Concurrent Jobs settings would otherwise allow two jobs
   to run simultaneously.

   \item Suppose that bareos is running a priority 2 job and a new priority 1
   job is scheduled and queued waiting for the running priority 2 job to
   terminate.  If you then start a second priority 2 job, the waiting
   priority 1 job will prevent the new priority 2 job from running
   concurrently with the running priority 2 job.  That is: as long as there
   is a higher priority job waiting to run, no new lower priority jobs will
   start even if the Maximum Concurrent Jobs settings would normally allow
   them to run.  This ensures that higher priority jobs will be run as soon
   as possible.
   \end{itemize}

   If you have several jobs of different priority, it may not best to start
   them at exactly the same time, because Bareos must examine them one at a
   time.  If by Bareos starts a lower priority job first, then it will run
   before your high priority jobs.  If you experience this problem, you may
   avoid it by starting any higher priority jobs a few seconds before lower
   priority ones.  This insures that Bareos will examine the jobs in the
   correct order, and that your priority scheme will be respected.
   }

\defDirective{Dir}{Job}{Protocol}{}{}{%
   The backup protocol to use to run the Job. See \dtProtocolType.
   }

\defDirective{Dir}{Job}{Prune Files}{}{}{%
   Normally, pruning of Files from the Catalog is specified on a Client by
   Client basis in \linkResourceDirective{Dir}{Client}{Auto Prune}.
   If this directive is specified and the value is \argument{yes},
   it will override the value specified in the Client resource.
   }

\defDirective{Dir}{Job}{Prune Jobs}{}{}{%
   Normally, pruning of Jobs from the Catalog is specified on a Client by
   Client basis in \linkResourceDirective{Dir}{Client}{Auto Prune}.
   If this directive is specified and the value is \argument{yes},
   it will override the value specified in the Client resource.
   }

\defDirective{Dir}{Job}{Prune Volumes}{}{}{%
   Normally, pruning of Volumes from the Catalog is specified on a Pool by
   Pool basis in \linkResourceDirective{Dir}{Pool}{Auto Prune} directive.
   Note, this is different from File and Job pruning which is done on a
   Client by Client basis.  If this directive is specified
   and the value is \argument{yes}, it will override the value specified in the
   Pool resource.
   }

\defDirective{Dir}{Job}{Purge Migration Job}{}{}{%
     This directive may be added to the Migration Job definition in the Director
     configuration file to purge the job migrated at the end of a migration.
   }

\defDirective{Dir}{Job}{Regex Where}{}{}{%
   This directive applies only to a Restore job and specifies a regex filename
   manipulation of all files being restored.  This will use \ilink{File
   Relocation}{filerelocation} feature.

   For more informations about how use this option, see
   \nameref{regexwhere}.
   }

\defDirective{Dir}{Job}{Replace}{}{}{%
   This directive applies only to a Restore job and specifies what happens
   when Bareos wants to restore a file or directory that already exists.
   You have the following options for {\bf replace-option}:

   \begin{description}

   \item [always]
   \index[dir]{always}
   when the file to be restored already exists, it is deleted and then
   replaced by the copy that was backed up.  This is the default value.

   \item [ifnewer]
   \index[dir]{ifnewer}
   if the backed up file (on tape) is newer than the existing file, the
   existing file is deleted and replaced by the back up.

   \item [ifolder]
   \index[dir]{ifolder}
   if the backed up file (on tape) is older than the existing file, the
   existing file is deleted and replaced by the back up.

   \item [never]
   \index[dir]{never}
   if the backed up file already exists, Bareos skips  restoring this file.
   \end{description}
   }

\defDirective{Dir}{Job}{Rerun Failed Levels}{}{}{%
   If this directive is set to {\bf yes} (default no), and Bareos detects that
   a previous job at a higher level (i.e.  Full or Differential) has failed,
   the current job level will be upgraded to the higher level.  This is
   particularly useful for Laptops where they may often be unreachable, and if
   a prior Full save has failed, you wish the very next backup to be a Full
   save rather than whatever level it is started as.

   There are several points that must be taken into account when using this
   directive: first, a failed job is defined as one that has not terminated
   normally, which includes any running job of the same name (you need to
   ensure that two jobs of the same name do not run simultaneously);
   secondly, the \linkResourceDirective{Dir}{FileSet}{Ignore File Set Changes} directive is not considered
   when checking for failed levels, which means that any FileSet change will
   trigger a rerun.
   }

\defDirective{Dir}{Job}{Reschedule Interval}{}{}{%
   If you have specified {\bf Reschedule On Error = yes} and the job
   terminates in error, it will be rescheduled after the interval of time
   specified by {\bf time-specification}.  See \ilink{the time
   specification formats}{Time} in the Configure chapter for details of
   time specifications.  If no interval is specified, the job will not be
   rescheduled on error.
   }

\defDirective{Dir}{Job}{Reschedule On Error}{}{}{%
   If this directive is enabled, and the job terminates in error, the job
   will be rescheduled as determined by the \linkResourceDirective{Dir}{Job}{Reschedule Interval} and
   \linkResourceDirective{Dir}{Job}{Reschedule Times} directives.
   If you cancel the job, it will not
   be rescheduled.

   This specification can be useful for portables, laptops, or other
   machines that are not always connected to the network or switched on.
   }

\defDirective{Dir}{Job}{Reschedule Times}{}{}{%
   This directive specifies the maximum number of times to reschedule the
   job.  If it is set to zero (the default) the job will be rescheduled an
   indefinite number of times.
   }

\defDirective{Dir}{Job}{Run}{}{}{%
   \index[dir]{Clone a Job}%
   The Run directive (not to be confused with the Run option in a
   Schedule) allows you to start other jobs or to clone the current jobs.

   The part after the equal sign must be enclosed in double quotes,
   and can contain any string or set of options (overrides) that you
   can specify when entering the \bcommand{run}{} command from the console. For
   example {\bf storage=DDS-4 ...}.  In addition, there are two special
   keywords that permit you to clone the current job. They are {\bf level=\%l}
   and {\bf since=\%s}. The \%l in the level keyword permits
   entering the actual level of the current job and the \%s in the since
   keyword permits putting the same time for comparison as used on the
   current job.  Note, in the case of the since keyword, the \%s must be
   enclosed in double quotes, and thus they must be preceded by a backslash
   since they are already inside quotes. For example:

   \bconfigInput{config/DirJobRun1.conf}

   A cloned job will not start additional clones, so it is not
   possible to recurse.

   Jobs started by \linkResourceDirective{Dir}{Job}{Run}
   are submitted for running before the original job (while it is being
   initialized). This means that any clone job will actually start before
   the original job, and may even block the original job from starting.
   It evens ignores \linkResourceDirective{Dir}{Job}{Priority}.

   If you are trying to prioritize jobs,
   you will find it much easier to do using a \linkResourceDirective{Dir}{Job}{Run Script}
   resource or a \linkResourceDirective{Dir}{Job}{Run Before Job} directive.
   }

\defDirective{Dir}{Job}{Run After Failed Job}{}{}{%
   This is a shortcut for the \linkResourceDirective{Dir}{Job}{Run Script} resource,
   that runs a command after a failed job.

   If the exit code of the program run is non-zero, Bareos will print a
   warning message.

   \bconfigInput{config/DirJobRunAfterFailedJob1.conf}
   }

\defDirective{Dir}{Job}{Run After Job}{}{}{%
   This is a shortcut for the \linkResourceDirective{Dir}{Job}{Run Script} resource,
   that runs a command after a successful job (without error or without being canceled).

   If the exit code of the program run is
   non-zero, Bareos will print a warning message.
   }

\defDirective{Dir}{Job}{Run Before Job}{}{}{%
   This is a shortcut for the \linkResourceDirective{Dir}{Job}{Run Script} resource,
   that runs a command before a job.

   If the exit code of the program run is non-zero, the current Bareos job will be
   canceled.

   \bconfigInput{config/DirJobRunBeforeJob1.conf}

   is equivalent to:

   \bconfigInput{config/DirJobRunBeforeJob2.conf}
   %
   % Lutz Kittler has pointed out that using the RunBeforeJob directive can be a
   % simple way to modify your schedules during a holiday.  For example, suppose
   % that you normally do Full backups on Fridays, but Thursday and Friday are
   % holidays.  To avoid having to change tapes between Thursday and Friday when
   % no one is in the office, you can create a RunBeforeJob that returns a
   % non-zero status on Thursday and zero on all other days.  That way, the
   % Thursday job will not run, and on Friday the tape you inserted on Wednesday
   % before leaving will be used.
   }

\defDirective{Dir}{Job}{Run Script}{}{}{
   The RunScript directive behaves like a resource in that it
   requires opening and closing braces around a number of directives
   that make up the body of the runscript.

   The specified {\bf Command} (see below for details) is run as an external
   program prior or after the current Job.  This is optional.  By default, the
   program is executed on the Client side like in \texttt{ClientRunXXXJob}.

   \textbf{Console} options are special commands that are sent to the director instead
   of the OS. At this time, console command outputs are redirected to log with
   the jobid 0.

   You can use following console command: \texttt{delete}, \texttt{disable},
   \texttt{enable}, \texttt{estimate}, \texttt{list}, \texttt{llist},
   \texttt{memory}, \texttt{prune}, \texttt{purge}, \texttt{reload},
   \texttt{status}, \texttt{setdebug}, \texttt{show}, \texttt{time},
   \texttt{trace}, \texttt{update}, \texttt{version}, \texttt{.client},
   \texttt{.jobs}, \texttt{.pool}, \texttt{.storage}.
   See \nameref{section-bconsole} for
   more information. You need to specify needed information on command line, nothing
   will be prompted. Example:

   \bconfigInput{config/DirJobRunScript1.conf}

   You can specify more than one Command/Console option per RunScript.

   You can use following options may be specified in the body
   of the runscript:\\

   \begin{center}
   # Tabular in LaTex format (original)
   \begin{verbatim}\begin{tabular}{|p{0.2\textwidth}|p{0.2\textwidth}|p{0.4\textwidth}|}
   \hline
   Options         & Value  & Information   \\
   \hline
   \hline
   Runs On Success & \textbf{Yes} | No & run if JobStatus is successful\\
   \hline
   Runs On Failure & Yes | \textbf{No} & run if JobStatus isn't successful\\
   \hline
   Runs On Client  & \textbf{Yes} | No & run command on client\\
   \hline
   Runs When       & \textbf{\variable{Never}} | \variable{Before} | \variable{After} | \variable{Always} | \textsl{\variable{AfterVSS}} & When to run\\
   \hline
   Fail Job On Error & \textbf{Yes} | No & Fail job if script returns something different from 0\\
   \hline
   Command          &       &   External command\\
   \hline
   Console          &       &   Console command\\
   \hline
   \end{tabular}\end{verbatim}

   # Tabular converted from LaTeX to RST (or empty, in case of problems):
   \begin{tabular}{|p{0.2\textwidth}|p{0.2\textwidth}|p{0.4\textwidth}|}
   \hline
   Options         & Value  & Information   \\
   \hline
   \hline
   Runs On Success & \textbf{Yes} | No & run if JobStatus is successful\\
   \hline
   Runs On Failure & Yes | \textbf{No} & run if JobStatus isn't successful\\
   \hline
   Runs On Client  & \textbf{Yes} | No & run command on client\\
   \hline
   Runs When       & \textbf{\variable{Never}} | \variable{Before} | \variable{After} | \variable{Always} | \textsl{\variable{AfterVSS}} & When to run\\
   \hline
   Fail Job On Error & \textbf{Yes} | No & Fail job if script returns something different from 0\\
   \hline
   Command          &       &   External command\\
   \hline
   Console          &       &   Console command\\
   \hline
   \end{tabular}
    \end{center}

   Any output sent by the command to standard output will be included in the
   Bareos job report.  The command string must be a valid program name or name
   of a shell script.

   \warning{The command string is parsed then fed to the OS,
   which means that the path will be searched to execute your specified
   command, but there is no shell interpretation. As a consequence, if you
   invoke complicated commands or want any shell features such as redirection
   or piping, you must call a shell script and do it inside that script.
   Alternatively, it is possible to use \command{sh -c '...'} in the command
   definition to force shell interpretation, see example below.}

   Before executing the specified command, Bareos
   performs character substitution of the following characters:

   \label{character substitution}
   \footnotesize
   \begin{longtable}{ l l }
       \%\% & \% \\
       \%b & Job Bytes \\
       \%B & Job Bytes in human readable format \\
       \%c & Client's name \\
       \%d & Daemon's name (Such as host-dir or host-fd) \\
       \%D & Director's name (Also valid on file daemon) \\
       \%e & Job Exit Status \\
       \%f & Job FileSet (Only on director side) \\
       \%F & Job Files \\
       \%h & Client address \\
       \%i & Job Id \\
       \%j & Unique Job Id \\
       \%l & Job Level \\
       \%n & Job name \\
       \%p & Pool name (Only on director side) \\
       \%P & Daemon PID \\
       \%s & Since time \\
       \%t & Job type (Backup, ...) \\
       \%v & Read Volume name(s) (Only on director side) \\
       \%V & Write Volume name(s) (Only on director side) \\
       \%w & Storage name (Only on director side) \\
       \%x & Spooling enabled? ("yes" or "no") \\
   \end{longtable}
   \normalsize

   Some character substitutions are not available in all situations. The Job Exit
   Status code \%e edits the following values:

   \index[dir]{Exit Status}
   \begin{itemize}
   \item OK
   \item Error
   \item Fatal Error
   \item Canceled
   \item Differences
   \item Unknown term code
   \end{itemize}

      Thus if you edit it on a command line, you will need to enclose
      it within some sort of quotes.


   You can use these following shortcuts:\\

   # Tabular in LaTex format (original)
   \begin{verbatim}\begin{tabular}{|l|c|c|c|c|c}
   \hline
   Keyword & RunsOnSuccess & RunsOnFailure  & FailJobOnError & Runs On Client & RunsWhen  \\
   \hline
   \hline
   \linkResourceDirective{Dir}{Job}{Run Before Job}         &        &       & Yes     & No     & Before \\
   \hline
   \linkResourceDirective{Dir}{Job}{Run After Job}          &  Yes   &   No  &         & No     & After  \\
   \hline
   \linkResourceDirective{Dir}{Job}{Run After Failed Job}   &  No    &  Yes  &         & No     & After  \\
   \hline
   \linkResourceDirective{Dir}{Job}{Client Run Before Job}  &        &       & Yes     & Yes    & Before \\
   \hline
   \linkResourceDirective{Dir}{Job}{Client Run After Job}   &  Yes   &   No  &         & Yes    & After  \\
   \hline
   \end{tabular}\end{verbatim}

   # Tabular converted from LaTeX to RST (or empty, in case of problems):
   \begin{tabular}{|l|c|c|c|c|c}
   \hline
   Keyword & RunsOnSuccess & RunsOnFailure  & FailJobOnError & Runs On Client & RunsWhen  \\
   \hline
   \hline
   \linkResourceDirective{Dir}{Job}{Run Before Job}         &        &       & Yes     & No     & Before \\
   \hline
   \linkResourceDirective{Dir}{Job}{Run After Job}          &  Yes   &   No  &         & No     & After  \\
   \hline
   \linkResourceDirective{Dir}{Job}{Run After Failed Job}   &  No    &  Yes  &         & No     & After  \\
   \hline
   \linkResourceDirective{Dir}{Job}{Client Run Before Job}  &        &       & Yes     & Yes    & Before \\
   \hline
   \linkResourceDirective{Dir}{Job}{Client Run After Job}   &  Yes   &   No  &         & Yes    & After  \\
   \hline
   \end{tabular}

   Examples:
   \bconfigInput{config/DirJobRunScript2.conf}

   {\bf Special Windows Considerations}
   \index[general]{Windows!Run Script}

   You can run scripts just after snapshots initializations with
   \textsl{AfterVSS} keyword.

   In addition, for a Windows client, please take
   note that you must ensure a correct path to your script.  The script or
   program can be a .com, .exe or a .bat file.  If you just put the program
   name in then Bareos will search using the same rules that cmd.exe uses
   (current directory, Bareos bin directory, and PATH).  It will even try the
   different extensions in the same order as cmd.exe.
   The command can be anything that cmd.exe or command.com will recognize
   as an executable file.

   However, if you have slashes in the program name then Bareos figures you
   are fully specifying the name, so you must also explicitly add the three
   character extension.

   The command is run in a Win32 environment, so Unix like commands will not
   work unless you have installed and properly configured Cygwin in addition
   to and separately from Bareos.

   The System \%Path\% will be searched for the command.  (under the
   environment variable dialog you have have both System Environment and
   User Environment, we believe that only the System environment will be
   available to bareos-fd, if it is running as a service.)

   System environment variables can be referenced with \%var\% and
   used as either part of the command name or arguments.

   So if you have a script in the Bareos\\bin directory then the following lines
   should work fine:

   % \footnotesize
   %\begin{verbatim}\begin{bconfig}{Windows systemstate Run Script}^^J
   %         Client Run Before Job = "systemstate"^^J
   % or^^J
   %         Client Run Before Job = "systemstate.bat"^^J
   % or^^J
   %         ClientRunBeforeJob = "\\"C:/Program Files/Bareos/systemstate.bat\\""^^J
   %\end{bconfig}\end{verbatim}
   % \normalsize

   % \begin{verbatim}\begin{bconfig}{Windows systemstate Run Script}^^J
   %         Client Run Before Job = "systemstate"^^J
   % or^^J
   %         Client Run Before Job = "systemstate.bat"^^J
   % or^^J
   %         Client Run Before Job = "\\"C:/Program Files/Bareos/systemstate.bat\\""^^J
   % \end{bconfig}\end{verbatim}
   \bconfigInput{config/DirJobRunScript3.conf}

   % \begin{itemize}
   %     \item \verb|path:Client Run Before Job = "systemstate"|
   % or
   %     \item \verb|path:Client Run Before Job = "systemstate.bat"|
   % or
   %     \item \verb|path:ClientRunBeforeJob = "\\"C:/Program Files/Bareos/systemstate.bat\\""|
   % \end{itemize}

   The outer set of quotes is removed when the configuration file is parsed.
   You need to escape the inner quotes so that they are there when the code
   that parses the command line for execution runs so it can tell what the
   program name is.

   % \footnotesize
   % \begin{verbatim}
   % ClientRunBeforeJob = "\"C:/Program Files/Software
   %      Vendor/Executable\" /arg1 /arg2 \"foo bar\""
   % \end{verbatim}
   % \normalsize

   The special characters \configCharsToQuote
   will need to be quoted,
   if they are part of a filename or argument.

   If someone is logged in, a blank "command" window running the commands
   will be present during the execution of the command.

   Some Suggestions from Phil Stracchino for running on Win32 machines with
   the native Win32 File daemon:

   \begin{enumerate}
   \item You might want the ClientRunBeforeJob directive to specify a .bat
         file which runs the actual client-side commands, rather than trying
         to run (for example) regedit /e directly.
   \item The batch file should explicitly 'exit 0' on successful completion.
   \item The path to the batch file should be specified in Unix form:

       \configline{Client Run Before Job = "c:/bareos/bin/systemstate.bat"}

       rather than DOS/Windows form:

       INCORRECT: \configline{Client Run Before Job = "c:\bareos\bin\systemstate.bat"}
   \end{enumerate}

   For Win32, please note that there are certain limitations:

   \configline{Client Run Before Job = "C:/Program Files/Bareos/bin/pre-exec.bat"}

   Lines like the above do not work because there are limitations of
   cmd.exe that is used to execute the command.
   Bareos prefixes the string you supply with \command{cmd.exe /c}.  To test that
   your command works you should type \command{cmd /c "C:/Program Files/test.exe"} at a
   cmd prompt and see what happens.  Once the command is correct insert a
   backslash (\textbackslash{}) before each double quote ("), and
   then put quotes around the whole thing when putting it in
   the director's .conf file.  You either need to have only one set of quotes
   or else use the short name and don't put quotes around the command path.

   Below is the output from cmd's help as it relates to the command line
   passed to the /c option.

   If /C or /K is specified, then the remainder of the command line after
   the switch is processed as a command line, where the following logic is
   used to process quote (") characters:

   \begin{enumerate}
   \item
   If all of the following conditions are met, then quote characters
   on the command line are preserved:
   \begin{itemize}
   \item no /S switch.
   \item exactly two quote characters.
   \item no special characters between the two quote characters,
   where special is one of: \configCharsToQuote
   \item there are one or more whitespace characters between the
   the two quote characters.
   \item the string between the two quote characters is the name
   of an executable file.
   \end{itemize}

   \item  Otherwise, old behavior is to see if the first character is
   a quote character and if so, strip the leading character and
   remove the last quote character on the command line, preserving
   any text after the last quote character.
   \end{enumerate}

   % The following example of the use of the Client Run Before Job directive was
   % submitted by a user:
   %
   % You could write a shell script to back up a DB2 database to a FIFO. The shell
   % script is:
   %
   % \footnotesize
   % \begin{verbatim}
   %  #!/bin/sh
   %  # ===== backupdb.sh
   %  DIR=/u01/mercuryd
   %
   %  mkfifo $DIR/dbpipe
   %  db2 BACKUP DATABASE mercuryd TO $DIR/dbpipe WITHOUT PROMPTING &
   %  sleep 1
   % \end{verbatim}
   % \normalsize
   %
   %The following line in the Job resource in the bareos-dir.conf file:
   % \footnotesize
   % \begin{verbatim}
   %  Client Run Before Job = "su - mercuryd -c \"/u01/mercuryd/backupdb.sh '%t'
   % '%l'\""
   % \end{verbatim}
   % \normalsize
   %
   % When the job is run, you will get messages from the output of the script
   % stating that the backup has started. Even though the command being run is
   % backgrounded with \&, the job will block until the "db2 BACKUP DATABASE"
   % command, thus the backup stalls.
   %
   % To remedy this situation, the "db2 BACKUP DATABASE" line should be changed to
   % the following:
   %
   % % \footnotesize
   % \begin{verbatim}
   %  db2 BACKUP DATABASE mercuryd TO $DIR/dbpipe WITHOUT PROMPTING > $DIR/backup.log
   % 2>&1 < /dev/null &
   % \end{verbatim}
   % \normalsize
   %
   % It is important to redirect the input and outputs of a backgrounded command to
   % /dev/null to prevent the script from blocking.
   }

\defDirective{Dir}{Job}{Save File History}{}{14.2.0}{%
   \index[general]{NDMP!File History}%
   Allow disabling storing the file history, as this causes problems problems with some implementations of NDMP (out-of-order metadata).

   With \linkResourceDirective{Dir}{Job}{File History Size} the maximum number of files and directories inside a NDMP job can be configured.

   \warning{The File History is required to do a single file restore from NDMP backups. With this disabled, only full restores are possible.}
   }

\defDirective{Dir}{Job}{Schedule}{}{}{%
   The Schedule directive defines what schedule is to be used for the Job.
   The schedule in turn determines when the Job will be automatically
   started and what Job level (i.e.  Full, Incremental, ...) is to be run.
   This directive is optional, and if left out, the Job can only be started
   manually using the Console program.  Although you may specify only a
   single Schedule resource for any one job, the Schedule resource may
   contain multiple {\bf Run} directives, which allow you to run the Job at
   many different times, and each {\bf run} directive permits overriding
   the default Job Level Pool, Storage, and Messages resources.  This gives
   considerable flexibility in what can be done with a single Job.  For
   additional details, see \nameref{DirectorResourceSchedule}.
   }

\defDirective{Dir}{Job}{SD Plugin Options}{}{}{%
   These settings are plugin specific, see \nameref{sdPlugins}.
   }

\defDirective{Dir}{Job}{Selection Pattern}{}{}{%
   Selection Patterns is only used for Copy and Migration jobs, see \nameref{MigrationChapter}.
   The interpretation of its value depends on the selected \linkResourceDirective{Dir}{Job}{Selection Type}.

     For the OldestVolume and SmallestVolume, this
     Selection pattern is not used (ignored).

     For the Client, Volume, and Job
     keywords, this pattern must be a valid regular expression that will filter
     the appropriate item names found in the Pool.

     For the SQLQuery keyword, this pattern must be a valid \command{SELECT} SQL statement
     that returns JobIds.
   }

\defDirective{Dir}{Job}{Selection Type}{}{}{%
   Selection Type is only used for Copy and Migration jobs, see \nameref{MigrationChapter}.
   It determines how a migration job
     will go about selecting what JobIds to migrate. In most cases, it is
     used in conjunction with a \linkResourceDirective{Dir}{Job}{Selection Pattern}
     to give you fine
     control over exactly what JobIds are selected.
     The possible values are:
     \begin{description}
     \item [SmallestVolume] This selection keyword selects the volume with the
           fewest bytes from the Pool to be migrated.  The Pool to be migrated
           is the Pool defined in the Migration Job resource.  The migration
           control job will then start and run one migration backup job for
           each of the Jobs found on this Volume.  The Selection Pattern, if
           specified, is not used.

     \item [OldestVolume] This selection keyword selects the volume with the
           oldest last write time in the Pool to be migrated.  The Pool to be
           migrated is the Pool defined in the Migration Job resource.  The
           migration control job will then start and run one migration backup
           job for each of the Jobs found on this Volume.  The Selection
           Pattern, if specified, is not used.

     \item [Client] The Client selection type, first selects all the Clients
           that have been backed up in the Pool specified by the Migration
           Job resource, then it applies the \linkResourceDirective{Dir}{Job}{Selection Pattern}
           as a regular expression to the list of Client names, giving
           a filtered Client name list.  All jobs that were backed up for those
           filtered (regexed) Clients will be migrated.
           The migration control job will then start and run one migration
           backup job for each of the JobIds found for those filtered Clients.

     \item [Volume] The Volume selection type, first selects all the Volumes
           that have been backed up in the Pool specified by the Migration
           Job resource, then it applies the \linkResourceDirective{Dir}{Job}{Selection Pattern}
           as a regular expression to the list of Volume names, giving
           a filtered Volume list.  All JobIds that were backed up for those
           filtered (regexed) Volumes will be migrated.
           The migration control job will then start and run one migration
           backup job for each of the JobIds found on those filtered Volumes.

     \item [Job] The Job selection type, first selects all the Jobs (as
           defined on the \linkResourceDirective{Dir}{Job}{Name} directive in a Job resource)
           that have been backed up in the Pool specified by the Migration
           Job resource, then it applies the \linkResourceDirective{Dir}{Job}{Selection Pattern}
           as a regular expression to the list of Job names, giving
           a filtered Job name list.  All JobIds that were run for those
           filtered (regexed) Job names will be migrated.  Note, for a given
           Job named, they can be many jobs (JobIds) that ran.
           The migration control job will then start and run one migration
           backup job for each of the Jobs found.

     \item [SQLQuery] The SQLQuery selection type, used the 
           \linkResourceDirective{Dir}{Job}{Selection Pattern}
           as an SQL query to obtain the JobIds to be migrated.
           The Selection Pattern must be a valid SELECT SQL statement for your
           SQL engine, and it must return the JobId as the first field
           of the SELECT.

     \item [PoolOccupancy] This selection type will cause the Migration job
           to compute the total size of the specified pool for all Media Types
           combined. If it exceeds the \linkResourceDirective{Dir}{Pool}{Migration High Bytes} 
           defined in
           the Pool, the Migration job will migrate all JobIds beginning with
           the oldest Volume in the pool (determined by Last Write time) until
           the Pool bytes drop below the \linkResourceDirective{Dir}{Pool}{Migration Low Bytes} 
           defined in the
           Pool. This calculation should be consider rather approximative because
           it is made once by the Migration job before migration is begun, and
           thus does not take into account additional data written into the Pool
           during the migration.  In addition, the calculation of the total Pool
           byte size is based on the Volume bytes saved in the Volume (Media) database
           entries. The bytes calculate for Migration is based on the value stored
           in the Job records of the Jobs to be migrated. These do not include the
           Storage daemon overhead as is in the total Pool size. As a consequence,
           normally, the migration will migrate more bytes than strictly necessary.

     \item [PoolTime] The PoolTime selection type will cause the Migration job to
           look at the time each JobId has been in the Pool since the job ended.
           All Jobs in the Pool longer than the time specified on 
           \linkResourceDirective{Dir}{Pool}{Migration Time}
           directive in the Pool resource will be migrated.

     \item [PoolUncopiedJobs] This selection which copies all jobs from a pool
           to an other pool which were not copied before is available only for copy Jobs.

     \end{description}

   }

\defDirective{Dir}{Job}{Spool Attributes}{}{}{%
   Is Spool Attributes is disabled, 
   the File attributes are
   sent by the Storage daemon to the Director as they are stored on tape.
   However, if you want to avoid the possibility that database updates will
   slow down writing to the tape, you may want to set the value to \parameter{yes}, 
   in which case the Storage daemon will buffer the File attributes
   and Storage coordinates to a temporary file in the Working Directory,
   then when writing the Job data to the tape is completed, the attributes
   and storage coordinates will be sent to the Director.

   NOTE: When \linkResourceDirective{Dir}{Job}{Spool Data} is set to yes, Spool Attributes is also
   automatically set to yes.

   For details, see \nameref{section-spooling}.
   }

\defDirective{Dir}{Job}{Spool Data}{}{}{%
   If this directive is set  to \parameter{yes}, the Storage daemon will
   be requested  to spool the data for this Job to disk rather than write it
   directly to the Volume (normally a tape).

   Thus the data is written in large blocks to the Volume rather than small
   blocks.  This directive is particularly useful when running multiple
   simultaneous backups to tape.  Once all the data arrives or the spool
   files' maximum sizes are reached, the data will be despooled and written
   to tape.

   Spooling data prevents interleaving data from several job and reduces or
   eliminates tape drive stop and start commonly known as "shoe-shine".

   We don't recommend using this option if you are writing to a disk file
   using this option will probably just slow down the backup jobs.

   NOTE: When this directive is set to yes, \linkResourceDirective{Dir}{Job}{Spool Attributes} is also
   automatically set to yes.

   For details, see \nameref{section-spooling}.
   }

\defDirective{Dir}{Job}{Spool Size}{}{}{%
   This specifies the maximum spool size for this job.
   The default is taken from \linkResourceDirective{Sd}{Device}{Maximum Spool Size} limit.
   }

\defDirective{Dir}{Job}{Storage}{}{}{%
   The Storage directive defines the name of the storage services where you
   want to backup the FileSet data.  For additional details, see the
   \nameref{DirectorResourceStorage} of this manual.
   The Storage resource may also be specified in the Job's Pool resource,
   in which case the value in the Pool resource overrides any value
   in the Job. This Storage resource definition is not required by either
   the Job resource or in the Pool, but it must be specified in
   one or the other, if not an error will result.
   }

\defDirective{Dir}{Job}{Strip Prefix}{}{}{
   This directive applies only to a Restore job and specifies a prefix to remove
   from the directory name of all files being restored.  This will use the
   \ilink{File Relocation}{filerelocation} feature.

   Using \texttt{Strip Prefix=/etc}, \texttt{/etc/passwd} will be restored to
   \texttt{/passwd}

   Under Windows, if you want to restore \texttt{c:/files} to \texttt{d:/files},
   you can use:

   \bconfigInput{config/DirJobStripPrefix1.conf}
   }

\defDirective{Dir}{Job}{Type}{}{}{%
   The \configdirective{Type} directive specifies the Job type, which is one of the following:

   \begin{description}

   \item [Backup]  \\
   \index[dir]{Backup}
   Run a backup Job. Normally you will  have at least one Backup job for each
   client you want  to save. Normally, unless you turn off cataloging,  most all
   the important statistics and data concerning  files backed up will be placed
   in the catalog.

   \item [Restore]  \\
   \index[dir]{Restore}
   Run a restore Job.  Normally, you will specify only one Restore job
   which acts as a sort of prototype that you will modify using the console
   program in order to perform restores.  Although certain basic
   information from a Restore job is saved in the catalog, it is very
   minimal compared to the information stored for a Backup job -- for
   example, no File database entries are generated since no Files are
   saved.

   {\bf Restore} jobs cannot be
   automatically started by the scheduler as is the case for Backup, Verify
   and Admin jobs. To restore files, you must use the {\bf restore} command
   in the console.


   \item [Verify]  \\
   \index[dir]{Verify}
   Run a verify Job. In general, {\bf verify}  jobs permit you to compare the
   contents of the catalog  to the file system, or to what was backed up. In
   addition,  to verifying that a tape that was written can be read,  you can
   also use {\bf verify} as a sort of tripwire  intrusion detection.

   \item [Admin]  \\
   \index[dir]{Admin}
   Run an admin Job. An {\bf Admin} job can  be used to periodically run catalog
   pruning, if you  do not want to do it at the end of each {\bf Backup}  Job.
   Although an Admin job is recorded in the  catalog, very little data is saved.

   \item [Migrate]
      defines the job that is run as being a
      Migration Job.  A Migration Job is a sort of control job and does not have
      any Files associated with it, and in that sense they are more or less like
      an Admin job.  Migration jobs simply check to see if there is anything to
      Migrate then possibly start and control new Backup jobs to migrate the data
      from the specified Pool to another Pool.  Note, any original JobId that
      is migrated will be marked as having been migrated, and the original
      JobId can nolonger be used for restores; all restores will be done from
      the new migrated Job.

   \item [Copy]
      defines the job that is run as being a
      Copy Job.  A Copy Job is a sort of control job and does not have
      any Files associated with it, and in that sense they are more or less like
      an Admin job.  Copy jobs simply check to see if there is anything to
      Copy then possibly start and control new Backup jobs to copy the data
      from the specified Pool to another Pool.  Note that when a copy is
      made, the original JobIds are left unchanged. The new copies can not
      be used for restoration unless you specifically choose them by JobId.
      If you subsequently delete a JobId that has a copy, the copy will be
      automatically upgraded to a Backup rather than a Copy, and it will
      subsequently be used for restoration.

   \item [Consolidate]
       is used to consolidate Always Incremental Backups jobs, see \nameref{section-alwaysincremental}.
       It has been introduced in Bareos \sinceVersion{dir}{Job Type Consolidate}{16.2.4}.
   \end{description}

   Within a particular Job Type, there are also Levels,
   see \linkResourceDirective{Dir}{Job}{Level}.
   }

\defDirective{Dir}{Job}{Verify Job}{}{}{%
   If you run a verify job without this directive, the last job run will be
   compared with the catalog, which means that you must immediately follow
   a backup by a verify command.  If you specify a {\bf Verify Job} Bareos
   will find the last job with that name that ran.  This permits you to run
   all your backups, then run Verify jobs on those that you wish to be
   verified (most often a {\bf VolumeToCatalog}) so that the tape just
   written is re-read.
   }

\defDirective{Dir}{Job}{Where}{}{}{%
   This directive applies only to a Restore job and specifies a prefix to
   the directory name of all files being restored.  This permits files to
   be restored in a different location from which they were saved.  If {\bf
   Where} is not specified or is set to backslash ({\bf /}), the files will
   be restored to their original location.  By default, we have set {\bf
   Where} in the example configuration files to be {\bf
   /tmp/bareos-restores}.  This is to prevent accidental overwriting of
   your files.

   \warning{To use Where on NDMP backups, please read \nameref{section-ndmp-where}.}
   }

\defDirective{Dir}{Job}{Write Bootstrap}{}{}{%
   The {\bf writebootstrap} directive specifies a file name where Bareos
   will write a {\bf bootstrap} file for each Backup job run.  This
   directive applies only to Backup Jobs.  If the Backup job is a Full
   save, Bareos will erase any current contents of the specified file
   before writing the bootstrap records.  If the Job is an Incremental
   or Differential
   save, Bareos will append the current bootstrap record to the end of the
   file.

   Using this feature, permits you to constantly have a bootstrap file that
   can recover the current state of your system.  Normally, the file
   specified should be a mounted drive on another machine, so that if your
   hard disk is lost, you will immediately have a bootstrap record
   available.  Alternatively, you should copy the bootstrap file to another
   machine after it is updated. Note, it is a good idea to write a separate
   bootstrap file for each Job backed up including the job that backs up
   your catalog database.

   If the {\bf bootstrap-file-specification} begins with a vertical bar
   (\textbar), Bareos will use the specification as the name of a program to which
   it will pipe the bootstrap record.  It could for example be a shell
   script that emails you the bootstrap record.

   Before opening the file or executing the
   specified command, Bareos performs
   \ilink{character substitution}{character substitution} like in RunScript
   directive. To automatically manage your bootstrap files, you can use
   this in your {\bf JobDefs} resources:
   % \begin{verbatim}\begin{bconfig}{Write Bootstrap Example}^^J
   % Job Defs \{^^J
   % \ \ Write Bootstrap = "\%c_\%n.bsr"^^J
   % \ \ ...^^J
   % \}^^J
   % \end{bconfig}\end{verbatim}
   \bconfigInput{config/DirJobWriteBootstrap1.conf}

   For more details on using this file, please see chapter \nameref{BootstrapChapter}.
   }

\defDirective{Dir}{Job}{Write Part After Job}{}{}{
   }

\defDirective{Dir}{Job}{Write Verify List}{}{}{
   }

The following is an example of a valid Job resource definition:

.. code-block:: sh
   :caption: Job Resource Example

   Job {
     Name = "Minou"
     Type = Backup
     Level = Incremental                 # default
     Client = Minou
     FileSet="Minou Full Set"
     Storage = DLTDrive
     Pool = Default
     Schedule = "MinouWeeklyCycle"
     Messages = Standard
   }

.. _DirectorResourceJobDefs:

JobDefs Resource
----------------

:index:`[TAG=Job->JobDefs Resource] <pair: Job; JobDefs Resource>` :index:`[TAG=Resource->JobDefs] <pair: Resource; JobDefs>`

The JobDefs resource permits all the same directives that can appear in a Job resource. However, a JobDefs resource does not create a Job, rather it can be referenced within a Job to provide defaults for that Job. This permits you to concisely define several nearly identical Jobs, each one referencing a JobDefs resource which contains the defaults. Only the changes from the defaults need to be mentioned in each Job.

.. _DirectorResourceSchedule:

Schedule Resource
-----------------

:index:`[TAG=Resource->Schedule] <pair: Resource; Schedule>` :index:`[TAG=Schedule->Resource] <pair: Schedule; Resource>`

The Schedule resource provides a means of automatically scheduling a Job as well as the ability to override the default Level, Pool, Storage and Messages resources. If a Schedule resource is not referenced in a Job, the Job can only be run manually. In general, you specify an action to be taken and when.

\defDirective{Dir}{Schedule}{Description}{}{}{%
   }

\defDirective{Dir}{Schedule}{Enabled}{}{}{%
   }

\defDirective{Dir}{Schedule}{Name}{}{}{%
   The name of the schedule being defined.
   }

\defDirective{Dir}{Schedule}{Run}{}{}{%
   The Run directive defines when a Job is to be run, and what overrides if
   any to apply.  You may specify multiple {\bf run} directives within a
   {\bf Schedule} resource.  If you do, they will all be applied (i.e.
   multiple schedules).  If you have two {\bf Run} directives that start at
   the same time, two Jobs will start at the same time (well, within one
   second of each other).

   The {\bf Job-overrides} permit overriding the Level, the Storage, the
   Messages, and the Pool specifications provided in the Job resource.  In
   addition, the FullPool, the IncrementalPool, and the DifferentialPool
   specifications permit overriding the Pool specification according to
   what backup Job Level is in effect.

   By the use of overrides, you may customize a particular Job.  For
   example, you may specify a Messages override for your Incremental
   backups that outputs messages to a log file, but for your weekly or
   monthly Full backups, you may send the output by email by using a
   different Messages override.

   {\bf Job-overrides} are specified as: {\bf keyword=value} where the
   keyword is Level, Storage, Messages, Pool, FullPool, DifferentialPool,
   or IncrementalPool, and the {\bf value} is as defined on the respective
   directive formats for the Job resource.  You may specify multiple {\bf
   Job-overrides} on one {\bf Run} directive by separating them with one or
   more spaces or by separating them with a trailing comma.  For example:

   \begin{description}

   \item [Level=Full]
   \index[dir]{Level}
   \index[dir]{Directive!Level}
   is all files in the FileSet whether or not  they have changed.

   \item [Level=Incremental]
   \index[dir]{Level}
   \index[dir]{Directive!Level}
   is all files that have changed since  the last backup.

   \item [Pool=Weekly]
   \index[dir]{Pool}
   \index[dir]{Directive!Pool}
   specifies to use the Pool named {\bf Weekly}.

   \item [Storage=DLT\_Drive]
   \index[dir]{Storage}
   \index[dir]{Directive!Storage}
   specifies to use {\bf DLT\_Drive} for  the storage device.

   \item [Messages=Verbose]
   \index[dir]{Messages}
   \index[dir]{Directive!Messages}
   specifies to use the {\bf Verbose}  message resource for the Job.

   \item [FullPool=Full]
   \index[dir]{FullPool}
   \index[dir]{Directive!FullPool}
   specifies to use the Pool named {\bf Full}  if the job is a full backup, or
   is upgraded from another type  to a full backup.

   \item [DifferentialPool=Differential]
   \index[dir]{DifferentialPool}
   \index[dir]{Directive!DifferentialPool}
   specifies to use the Pool named {\bf Differential} if the job is a
   differential  backup.

   \item [IncrementalPool=Incremental]
   \index[dir]{IncrementalPool}
   \index[dir]{Directive!IncrementalPool}
   specifies to use the Pool  named {\bf Incremental} if the job is an
   incremental  backup.

   \item [Accurate=yes|no]
   \index[dir]{Accurate}
   \index[dir]{Directive!Accurate}
   tells Bareos to use or not the Accurate code for the specific job. It can
   allow you to save memory and and CPU resources on the catalog server in some
   cases.

   \item [SpoolData=yes|no]
   \index[dir]{SpoolData}
   \index[dir]{Directive!Spool Data}
   tells Bareos to use or not to use spooling for the specific job.

   \end{description}

   {\bf Date-time-specification} determines when the  Job is to be run. The
   specification is a repetition, and as  a default Bareos is set to run a job at
   the beginning of the  hour of every hour of every day of every week of every
   month  of every year. This is not normally what you want, so you  must specify
   or limit when you want the job to run. Any  specification given is assumed to
   be repetitive in nature and  will serve to override or limit the default
   repetition. This  is done by specifying masks or times for the hour, day of the
   month, day of the week, week of the month, week of the year,  and month when
   you want the job to run. By specifying one or  more of the above, you can
   define a schedule to repeat at  almost any frequency you want.

   Basically, you must supply a {\bf month}, {\bf day}, {\bf hour}, and  {\bf
   minute} the Job is to be run. Of these four items to be specified,  {\bf day}
   is special in that you may either specify a day of the month  such as 1, 2,
   ... 31, or you may specify a day of the week such  as Monday, Tuesday, ...
   Sunday. Finally, you may also specify a  week qualifier to restrict the
   schedule to the first, second, third,  fourth, or fifth week of the month.

   For example, if you specify only a day of the week, such as {\bf Tuesday}  the
   Job will be run every hour of every Tuesday of every Month. That  is the {\bf
   month} and {\bf hour} remain set to the defaults of  every month and all
   hours.

   Note, by default with no other specification, your job will run  at the
   beginning of every hour. If you wish your job to run more than  once in any
   given hour, you will need to specify multiple {\bf run}  specifications each
   with a different minute.

   The date/time to run the Job can be specified in the following way  in
   pseudo-BNF:

   \begin{longtable}{ l @{ ::= } p{0.5\textwidth} }
   \bnfvar{week-keyword}    & 1st \pipe 2nd \pipe 3rd \pipe 4th \pipe 5th \pipe first \pipe
                        second \pipe third \pipe fourth \pipe fifth \pipe last \\
   \bnfvar{wday-keyword}    & sun \pipe mon \pipe tue \pipe wed \pipe thu \pipe fri \pipe sat \pipe
                       sunday \pipe monday \pipe tuesday \pipe wednesday \pipe
                       thursday \pipe friday \pipe saturday \\
   \bnfvar{week-of-year-keyword} & w00 \pipe w01 \pipe ... w52 \pipe w53 \\
   \bnfvar{month-keyword}   & jan \pipe feb \pipe mar \pipe apr \pipe may \pipe jun \pipe jul \pipe
                       aug \pipe sep \pipe oct \pipe nov \pipe dec \pipe
                       january \pipe february \pipe ... \pipe december \\
   \bnfvar{digit}           & 1 \pipe 2 \pipe 3 \pipe 4 \pipe 5 \pipe 6 \pipe 7 \pipe 8 \pipe 9 \pipe 0 \\
   \bnfvar{number}          & \bnfvar{digit} \pipe \bnfvar{digit}\bnfvar{number} \\
   \bnfvar{12hour}          & 0 \pipe 1 \pipe 2 \pipe ... 12 \\
   \bnfvar{hour}            & 0 \pipe 1 \pipe 2 \pipe ... 23 \\
   \bnfvar{minute}          & 0 \pipe 1 \pipe 2 \pipe ... 59 \\
   \bnfvar{day}             & 1 \pipe 2 \pipe ... 31 \\
   \bnfvar{time}            & \bnfvar{hour}:\bnfvar{minute} \pipe
                       \bnfvar{12hour}:\bnfvar{minute}am \pipe
                       \bnfvar{12hour}:\bnfvar{minute}pm \\
   \bnfvar{time-spec}       & at \bnfvar{time} \pipe hourly \\
   % ??? \bnfvar{date-keyword}    & on \pipe weekly \\
   \bnfvar{day-range}       & \bnfvar{day}-\bnfvar{day} \\
   \bnfvar{month-range}     & \bnfvar{month-keyword}-\bnfvar{month-keyword} \\
   \bnfvar{wday-range}      & \bnfvar{wday-keyword}-\bnfvar{wday-keyword} \\
   \bnfvar{range}           & \bnfvar{day-range} \pipe \bnfvar{month-range} \pipe
                             \bnfvar{wday-range} \\
   \bnfvar{modulo}          & \bnfvar{day}/\bnfvar{day} \pipe \bnfvar{week-of-year-keyword}/\bnfvar{week-of-year-keyword} \\
   \bnfvar{date}            & \bnfvar{date-keyword} \pipe \bnfvar{day} \pipe \bnfvar{range} \\
   \bnfvar{date-spec}       & \bnfvar{date} \pipe \bnfvar{date-spec} \\
   \bnfvar{day-spec}        & \bnfvar{day} \pipe \bnfvar{wday-keyword} \pipe
                       \bnfvar{day} \pipe \bnfvar{wday-range} \pipe
                       \bnfvar{week-keyword} \bnfvar{wday-keyword} \pipe
                       \bnfvar{week-keyword} \bnfvar{wday-range} \pipe
                       daily \\
   \bnfvar{month-spec}      & \bnfvar{month-keyword} \pipe \bnfvar{month-range} \pipe monthly \\
   \bnfvar{date-time-spec}  & \bnfvar{month-spec} \bnfvar{day-spec} \bnfvar{time-spec} \\
   \end{longtable}
   }

Note, the Week of Year specification wnn follows the ISO standard definition of the week of the year, where Week 1 is the week in which the first Thursday of the year occurs, or alternatively, the week which contains the 4th of January. Weeks are numbered w01 to w53. w00 for Bareos is the week that precedes the first ISO week (i.e. has the first few days of the year if any occur before Thursday). w00 is not defined by the ISO specification. A week starts with Monday and ends with Sunday.

According to the NIST (US National Institute of Standards and Technology), 12am and 12pm are ambiguous and can be defined to anything. However, 12:01am is the same as 00:01 and 12:01pm is the same as 12:01, so Bareos defines 12am as 00:00 (midnight) and 12pm as 12:00 (noon). You can avoid this abiguity (confusion) by using 24 hour time specifications (i.e. no am/pm).

An example schedule resource that is named WeeklyCycle and runs a job with level full each Sunday at 2:05am and an incremental job Monday through Saturday at 2:05am is:

.. code-block:: sh
   :caption: Schedule Example

   Schedule {
     Name = "WeeklyCycle"
     Run = Level=Full sun at 2:05
     Run = Level=Incremental mon-sat at 2:05
   }

An example of a possible monthly cycle is as follows:

.. code-block:: sh

   Schedule {
     Name = "MonthlyCycle"
     Run = Level=Full Pool=Monthly 1st sun at 2:05
     Run = Level=Differential 2nd-5th sun at 2:05
     Run = Level=Incremental Pool=Daily mon-sat at 2:05
   }

The first of every month:

.. code-block:: sh

   Schedule {
     Name = "First"
     Run = Level=Full on 1 at 2:05
     Run = Level=Incremental on 2-31 at 2:05
   }

The last friday of the month (i.e. the last friday in the last week of the month)

.. code-block:: sh

   Schedule {
     Name = "Last Friday"
     Run = Level=Full last fri at 21:00
   }

Every 10 minutes:

.. code-block:: sh

   Schedule {
     Name = "TenMinutes"
     Run = Level=Full hourly at 0:05
     Run = Level=Full hourly at 0:15
     Run = Level=Full hourly at 0:25
     Run = Level=Full hourly at 0:35
     Run = Level=Full hourly at 0:45
     Run = Level=Full hourly at 0:55
   }

The modulo scheduler makes it easy to specify schedules like odd or even days/weeks, or more generally every n days or weeks. It is called modulo scheduler because it uses the modulo to determine if the schedule must be run or not. The second variable behind the slash lets you determine in which cycle of days/weeks a job should be run. The first part determines on which day/week the job should be run first. E.g. if you want to run a backup in a 5-week-cycle, starting on week 3, you set it up as
w03/w05.

.. code-block:: sh
   :caption: Schedule Examples: modulo

   Schedule {
     Name = "Odd Days"
     Run = 1/2 at 23:10
   }

   Schedule {
     Name = "Even Days"
     Run = 2/2 at 23:10
   }

   Schedule {
     Name = "On the 3rd week in a 5-week-cycle"
     Run = w03/w05 at 23:10
   }

   Schedule {
     Name = "Odd Weeks"
     Run = w01/w02 at 23:10
   }

   Schedule {
     Name = "Even Weeks"
     Run = w02/w02 at 23:10
   }

Technical Notes on Schedules
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

:index:`[TAG=Schedule->Technical Notes on Schedules] <pair: Schedule; Technical Notes on Schedules>`

Internally Bareos keeps a schedule as a bit mask. There are six masks and a minute field to each schedule. The masks are hour, day of the month (mday), month, day of the week (wday), week of the month (wom), and week of the year (woy). The schedule is initialized to have the bits of each of these masks set, which means that at the beginning of every hour, the job will run. When you specify a month for the first time, the mask will be cleared and the bit corresponding to your selected month will
be selected. If you specify a second month, the bit corresponding to it will also be added to the mask. Thus when Bareos checks the masks to see if the bits are set corresponding to the current time, your job will run only in the two months you have set. Likewise, if you set a time (hour), the hour mask will be cleared, and the hour you specify will be set in the bit mask and the minutes will be stored in the minute field.

For any schedule you have defined, you can see how these bits are set by doing a show schedules command in the Console program. Please note that the bit mask is zero based, and Sunday is the first day of the week (bit zero).

.. _DirectorResourceFileSet:

FileSet Resource
----------------



.. _FileSetResource:

 :index:`[TAG=Resource->FileSet] <pair: Resource; FileSet>` :index:`[TAG=FileSet->Resource] <pair: FileSet; Resource>`

The FileSet resource defines what files are to be included or excluded in a backup job. A FileSet resource is required for each backup Job. It consists of a list of files or directories to be included, a list of files or directories to be excluded and the various backup options such as compression, encryption, and signatures that are to be applied to each file.

Any change to the list of the included files will cause Bareos to automatically create a new FileSet (defined by the name and an MD5 checksum of the Include/Exclude contents). Each time a new FileSet is created, Bareos will ensure that the next backup is always a Full save.

\defDirective{Dir}{FileSet}{Description}{}{}{%
   Information only.
   }

\defDirective{Dir}{FileSet}{Enable VSS}{}{}{%
   \index[dir]{Windows!Enable VSS}%
   If this directive is set to \parameter{yes} the File daemon will be notified
   that the user wants to use a Volume Shadow Copy Service (VSS) backup
   for this job. This directive is effective only on the Windows File Daemon.
   It permits a consistent copy
   of open files to be made for cooperating writer applications, and for
   applications that are not VSS away, Bareos can at least copy open files.
   The Volume Shadow Copy will only be done on Windows drives where the
   drive (e.g. C:, D:, ...) is explicitly mentioned in a \configdirective{File}
   directive.
   For more information, please see the
   \ilink{Windows}{VSS} chapter of this manual.
   }

\defDirective{Dir}{FileSet}{Exclude}{}{}{%
   Describe the files, that should get excluded from a backup, see section about the \nameref{fileset-exclude}.
   }

\defDirective{Dir}{FileSet}{Ignore File Set Changes}{}{}{%
   Normally, if you modify the FileSet Include or Exclude lists,
   the next backup will be forced to a Full so that Bareos can
   guarantee that any additions or deletions are properly saved.

   We strongly recommend against setting this directive to yes,
   since doing so may cause you to have an incomplete set of backups.

   If this directive is set to \parameter{yes}, any changes you make to the
   FileSet Include or Exclude lists, will not force a Full during
   subsequent backups.
   }

\defDirective{Dir}{FileSet}{Include}{}{}{%
   Describe the files, that should get included to a backup, see section about the \nameref{fileset-include}.
   }

\defDirective{Dir}{FileSet}{Name}{}{}{%
   The name of the FileSet resource.
   }

.. _fileset-include:

FileSet Include Ressource
~~~~~~~~~~~~~~~~~~~~~~~~~

The Include resource must contain a list of directories and/or files to be processed in the backup job.

Normally, all files found in all subdirectories of any directory in the Include File list will be backed up. Note, see below for the definition of <file-list>. The Include resource may also contain one or more Options resources that specify options such as compression to be applied to all or any subset of the files found when processing the file-list for backup. Please see below for more details concerning Options resources.

There can be any number of Include resources within the FileSet, each having its own list of directories or files to be backed up and the backup options defined by one or more Options resources.

Please take note of the following items in the FileSet syntax:

#. There is no equal sign (=) after the Include and before the opening brace ({). The same is true for the Exclude.

#. Each directory (or filename) to be included or excluded is preceded by a File =. Previously they were simply listed on separate lines.

#. The Exclude resource does not accept Options.

#. When using wild-cards or regular expressions, directory names are always terminated with a slash (/) and filenames have no trailing slash.

\begin{description}
   \directive{dir}{File}{ filename \textbar\ dirname \textbar\ \textbar command \textbar\ \textbackslash\textless includefile-client \textbar\ \textless includefile-server }{}{}{}
       The file list
       consists of one file or directory name per line.  Directory names should be
       specified without a trailing slash with Unix path notation.

       Windows users, please take note to specify directories (even c:/...) in
       Unix path notation. If you use Windows conventions, you will most likely
       not be able to restore your files due to the fact that the Windows
       path separator was defined as an escape character long before Windows
       existed, and Bareos adheres to that convention (i.e. means the next character
       appears as itself).

       You should always specify a full path for every directory and file that you
       list in the FileSet.  In addition, on Windows machines, you should {\bf
       always} prefix the directory or filename with the drive specification
       (e.g.  {\bf c:/xxx}) using Unix directory name separators
       (forward slash).  The drive letter itself can be upper or lower case (e.g.
       c:/xxx or C:/xxx).

       Bareos's default for processing directories is to recursively descend in
       the directory saving all files and subdirectories.  Bareos will not by
       default cross filesystems (or mount points in Unix parlance).  This means
       that if you specify the root partition (e.g.  {\bf /}), Bareos will save
       only the root partition and not any of the other mounted filesystems.
       Similarly on Windows systems, you must explicitly specify each of the
       drives you want saved (e.g.
       {\bf c:/} and {\bf d:/} ...). In addition, at least for Windows systems, you
       will most likely want to enclose each specification within double quotes
       particularly if the directory (or file) name contains spaces. The {\bf df}
       command on Unix systems will show you which mount points you must specify to
       save everything. See below for an example.

   Take special care not to include a directory twice or Bareos will backup
   the same files two times wasting a lot of space on your archive device.
   Including a directory twice is very easy to do.  For example:

   \begin{verbatim}\begin{bconfig}{File Set}
     Include {
       Options {
         compression=GZIP
       }
       File = /
       File = /usr
     }
   \end{bconfig}\end{verbatim}
   on a Unix system where /usr is a subdirectory (rather than a mounted
   filesystem) will cause /usr to be backed up twice.

   {\bf <file-list>} is a list of directory and/or filename names
   specified with a {\bf File =} directive. To include names containing spaces,
   enclose the name between double-quotes. Wild-cards are not interpreted
   in file-lists. They can only be specified in Options resources.

   There are a number of special cases when specifying directories and files in a
   {\bf file-list}. They are:

   \begin{itemize}
   \item Any name preceded by an at-sign (@) is assumed to be the  name of a
      file, which contains a list of files each preceded by a "File =".  The
      named file is read once when the configuration file is parsed during the
      Director startup.  Note, that the file is read on the Director's machine
      and not on the Client's.  In fact, the @filename can appear anywhere
      within a configuration file where a token would be read, and the contents of
      the named file will be logically inserted in the place of the @filename.
      What must be in the file depends on the location the @filename is
      specified in the conf file.  For example:

   \begin{verbatim}\begin{bconfig}{File Set with Include File}
   Include {
     Options {
       compression=GZIP
     }
     @/home/files/my-files
   }
   \end{bconfig}\end{verbatim}


   \item Any name beginning with a vertical bar (|) is  assumed to
      be the name of a program.  This program will be executed on the Director's
      machine at the time the Job starts (not when the Director reads the
      configuration file), and any output from that program will be assumed to
      be a list of files or directories, one per line, to be included. Before
      submitting the specified command Bareos will performe
      :ref:`character substitution <character substitution>`.

      This allows you to have a job that, for example, includes all the local
      partitions even if you change the partitioning by adding a disk.  The
      examples below show you how to do this.  However, please note two
      things: \\
      1.  if you want the local filesystems, you probably should be
      using the {\bf fstype} directive and set {\bf onefs=no}.
      \\

      2.  the exact syntax of the command needed in the examples below is very
      system dependent.  For example, on recent Linux systems, you may need to
      add the -P option, on FreeBSD systems, the options will be different as
      well.

      In general, you will need to prefix your command or commands with a {\bf
      sh -c} so that they are invoked by a shell.  This will not be the case
      if you are invoking a script as in the second example below.  Also, you
      must take care to escape (precede with a \textbackslash{}) wild-cards,
      shell character, and to ensure that any spaces in your command are
      escaped as well.  If you use a single quotes (') within a double quote
      ("), Bareos will treat everything between the single quotes as one field
      so it will not be necessary to escape the spaces.  In general, getting
      all the quotes and escapes correct is a real pain as you can see by the
      next example.  As a consequence, it is often easier to put everything in
      a file and simply use the file name within Bareos.  In that case the
      {\bf sh -c} will not be necessary providing the first line of the file
      is {\bf \#!/bin/sh}.

      As an  example:

   \begin{verbatim}\begin{bconfig}{File Set with inline script}
   Include {
      Options {
        signature = SHA1
      }
      File = "|sh -c 'df -l | grep \"^/dev/hd[ab]\" | grep -v \".*/tmp\" | awk \"{print \\$6}\"'"
   }
   \end{bconfig}\end{verbatim}
   % workaround for kile editor

      will produce a list of all the local partitions on a Linux system.
      Quoting is a real problem because you must quote for Bareos  which consists of
      preceding every \textbackslash{} and every " with a \textbackslash{}, and
      you must also quote for the shell command. In the end, it is probably  easier
      just to execute a script file with:

   \begin{verbatim}\begin{bconfig}{File Set with external script}
   Include {
     Options {
       signature=MD5
     }
     File = "|my_partitions"
   }
   \end{bconfig}\end{verbatim}

      where :command:`my_partitions` has:

   
   \begin{verbatim}
   #!/bin/sh
   df -l | grep "^/dev/hd[ab]" | grep -v ".*/tmp" \
         | awk "{print \$6}"
   \end{verbatim}
   

      If the vertical bar (\verb+|+) in front of :command:`my_partitions` is preceded by a
      backslash as in \textbackslash{}\verb+|+, the program will be executed on the
      Client's machine instead of on the Director's machine.
      Please note that if the filename is given within quotes, you
      will need to use two slashes.  An example, provided by John Donagher,
      that backs up all the local UFS partitions on a remote system is:

   \begin{verbatim}\begin{bconfig}{File Set with inline script in quotes}
   FileSet {
     Name = "All local partitions"
     Include {
       Options {
         signature=SHA1
         onefs=yes
       }
       File = "\\|bash -c \"df -klF ufs | tail +2 | awk '{print \$6}'\""
     }
   }
   \end{bconfig}\end{verbatim}

      The above requires two backslash characters after the double quote (one
      preserves  the next one). If you are a Linux user, just change the {\bf ufs}
      to  {\bf ext3} (or your preferred filesystem type), and you will be in
      business.

      If you know what filesystems you have mounted on your system, e.g.
      for Linux only using ext2, ext3 or ext4, you can backup
      all local filesystems using something like:

   \begin{verbatim}\begin{bconfig}{File Set to backup all extfs partions}
   Include {
      Options {
        signature = SHA1
        onfs=no
        fstype=ext2
      }
      File = /
   }
   \end{bconfig}\end{verbatim}

   \item Any file-list item preceded by a less-than sign (<)  will be taken
      to be a file. This file will be read on the Director's machine (see
      below for doing it on the Client machine) at the time
      the Job starts, and the  data will be assumed to be a list of directories or
      files,  one per line, to be included. The names should start in  column 1 and
      should not be quoted even if they contain  spaces. This feature allows you to
      modify the external  file and change what will be saved without stopping and
      restarting Bareos as would be necessary if using the @  modifier noted above.
      For example:

   
   \begin{verbatim}
   Include {
     Options {
       signature = SHA1
     }
     File = "</home/files/local-filelist"
   }
   \end{verbatim}
   

      If you precede the less-than sign (<) with a backslash as in
      \textbackslash{}<, the file-list will be read on the Client machine
      instead of on the Director's machine.  Please note that if the filename
      is given within quotes, you will need to use two slashes.

   
   \begin{verbatim}
   Include {
     Options {
       signature = SHA1
     }
     File = "\\</home/xxx/filelist-on-client"
   }
   \end{verbatim}
   

   \item     
       :index:`[TAG=Backup->Partitions] <pair: Backup; Partitions>`
       :index:`[TAG=Backup->Raw Partitions] <pair: Backup; Raw Partitions>`
       If you explicitly specify a block device such as {\bf /dev/hda1},  then
      Bareos will assume that this  is a raw partition
      to be backed up. In this case, you are strongly  urged to specify a {\bf
      sparse=yes} include option, otherwise, you  will save the whole partition
      rather than just the actual data that  the partition contains. For example:

   \begin{verbatim}\begin{bconfig}{Backup Raw Partitions}
   Include {
     Options {
       signature=MD5
       sparse=yes
     }
     File = /dev/hd6
   }
   \end{bconfig}\end{verbatim}

      will backup the data in device /dev/hd6. Note, the {bf /dev/hd6} must be
      the raw partition itself. Bareos will not back it up as a raw device if
      you specify a symbolic link to a raw device such as my be created by the
      LVM Snapshot utilities.


   \item A file-list may not contain wild-cards. Use directives in the
      Options resource if you wish to specify wild-cards or regular expression
      matching.

   \end{itemize}



   \directive{dir}{Exclude Dir Containing}{filename}{}{}{}
       This directive can be added to the Include section of the FileSet resource.  If the specified
       filename ({\bf filename-string}) is found on the Client in any directory to be
       backed up, the whole directory will be ignored (not backed up).
       We recommend to use the filename :file:`.nobackup`, as it is a hidden file on unix
       systems, and explains what is the purpose of the file.

       For example:

       \begin{verbatim}\begin{bconfig}{Exlude Directories containing the file .nobackup}
       # List of files to be backed up
       FileSet {
           Name = "MyFileSet"
           Include {
               Options {
                   signature = MD5
               }
               File = /home
               Exclude Dir Containing = .nobackup
           }
       }
       \end{bconfig}\end{verbatim}

       But in /home, there may be hundreds of directories of users and some
       people want to indicate that they don't want to have certain
       directories backed up. For example, with the above FileSet, if
       the user or sysadmin creates a file named {\bf .nobackup} in
       specific directories, such as

       \begin{verbatim}
       /home/user/www/cache/.nobackup
       /home/user/temp/.nobackup
       \end{verbatim}

       then Bareos will not backup the two directories named:

       \begin{verbatim}
       /home/user/www/cache
       /home/user/temp
       \end{verbatim}

       NOTE: subdirectories will not be backed up.  That is, the directive
       applies to the two directories in question and any children (be they
       files, directories, etc).


   \directive{dir}{Plugin}{plugin-name:plugin-parameter1:plugin-parameter2:...}{}{}{}
   

.. _directive-fileset-plugin:


           Instead of only specifying files, a file set can also use plugins.
           Plugins are additional libraries that handle specific requirements.
           The purpose of plugins is to provide an interface to any system program
           for backup and restore. That allows you, for example, to do database backups without a local dump.

           The syntax and semantics of the Plugin directive require
           the first part of the string up to the colon to be the name of the plugin.
           Everything after the first colon is ignored by the File daemon but is passed to the plugin.
           Thus the plugin writer may define the
           meaning of the rest of the string as he wishes.

           For more information, see :ref:`fdPlugins`.

           The program :ref:`bpluginfo` can be used, to retrieve information about a specific plugin.

           Note: It is also possible to define more than one plugin directive in a FileSet to do several database dumps at once.

   \directive{dir}{Options}{...}{}{}{}
       See the :ref:`fileset-options` section.

   \end{description}

.. _fileset-options:

FileSet Options Ressource
^^^^^^^^^^^^^^^^^^^^^^^^^

The Options resource is optional, but when specified, it will contain a list of keyword=value options to be applied to the file-list. See below for the definition of file-list. Multiple Options resources may be specified one after another. As the files are found in the specified directories, the Options will applied to the filenames to determine if and how the file should be backed up. The wildcard and regular expression pattern matching parts of the Options resources are checked in the order
they are specified in the FileSet until the first one that matches. Once one matches, the compression and other flags within the Options specification will apply to the pattern matched.

A key point is that in the absence of an Option or no other Option is matched, every file is accepted for backing up. This means that if you want to exclude something, you must explicitly specify an Option with an exclude = yes and some pattern matching.

Once Bareos determines that the Options resource matches the file under consideration, that file will be saved without looking at any other Options resources that may be present. This means that any wild cards must appear before an Options resource without wild cards.

If for some reason, Bareos checks all the Options resources to a file under consideration for backup, but there are no matches (generally because of wild cards that don’t match), Bareos as a default will then backup the file. This is quite logical if you consider the case of no Options clause is specified, where you want everything to be backed up, and it is important to keep in mind when excluding as mentioned above.

However, one additional point is that in the case that no match was found, Bareos will use the options found in the last Options resource. As a consequence, if you want a particular set of "default" options, you should put them in an Options resource after any other Options.

It is a good idea to put all your wild-card and regex expressions inside double quotes to prevent conf file scanning problems.

This is perhaps a bit overwhelming, so there are a number of examples included below to illustrate how this works.

You find yourself using a lot of Regex statements, which will cost quite a lot of CPU time, we recommend you simplify them if you can, or better yet convert them to Wild statements which are much more efficient.

The directives within an Options resource may be one of the following:

\begin{description}
       \xdirective{Dir}{}{AutoExclude}{\dtYesNo}{}{yes}{14.2.2}{%
           Automatically exclude files not intended for backup.
           Currently only used for Windows, to exclude files defined in the registry key \registrykey{HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\BackupRestore\FilesNotToBackup}, see section \nameref{FilesNotToBackup}.
       }

       \item [compression=<GZIP|GZIP1|...|GZIP9|LZO|LZFAST|LZ4|LZ4HC>]  \\
           :index:`[TAG=compression] <single: compression>`
           :index:`[TAG=Directive->compression] <pair: Directive; compression>`

           Configures the software compression to be used by the File Daemon.
           The compression is done on a file by file basis.
           %If there is a problem reading the tape in a single
           %record of a file, it will at most affect that file and none of the other
           %files on the tape.

           Software compression gets important if you are writing to a device that does not support compression by itself
           (e.g. hard disks). Otherwise, all modern tape drive do support hardware compression.
           Software compression can also be helpful to reduce the required network bandwidth,
           as compression is done on the File Daemon.
           However, using Bareos software compression and device hardware compression together
           is not advised, as trying to compress precompressed data is a very CPU-intense task
           and probably end up in even larger data.

           You can overwrite this option per Storage resource using the **Allow Compression**:sup:`Dir`:sub:`Storage`\  = no option.

       \begin{description}
           \item [compression=GZIP]  \\
           All files saved will be software compressed using the GNU ZIP
           compression format.

           Specifying {\bf GZIP} uses the default compression level 6 (i.e.  {\bf
           GZIP} is identical to {\bf GZIP6}).  If you want a different compression
           level (1 through 9), you can specify it by appending the level number
           with no intervening spaces to {\bf GZIP}.  Thus {\bf compression=GZIP1}
           would give minimum compression but the fastest algorithm, and {\bf
           compression=GZIP9} would give the highest level of compression, but
           requires more computation.  According to the GZIP documentation,
           compression levels greater than six generally give very little extra
           compression and are rather CPU intensive.

           \item [compression=LZO]  \\
           All files saved will be software compressed using the LZO
           compression format. The compression is done on a file by file basis by
           the File daemon. Everything else about GZIP is true for LZO.

           LZO provides much faster compression and decompression speed but lower
           compression ratio than GZIP. If your CPU is fast enough you should be able
           to compress your data without making the backup duration longer.

           Note that Bareos only use one compression level LZO1X-1 specified by LZO.

           \item [compression=LZFAST]  \\
           All files saved will be software compressed using the LZFAST
           compression format. The compression is done on a file by file basis by
           the File daemon. Everything else about GZIP is true for LZFAST.

           LZFAST provides much faster compression and decompression speed but lower
           compression ratio than GZIP. If your CPU is fast enough you should be able
           to compress your data without making the backup duration longer.

           \item [compression=LZ4]  \\
           All files saved will be software compressed using the LZ4
           compression format. The compression is done on a file by file basis by
           the File daemon. Everything else about GZIP is true for LZ4.

           LZ4 provides much faster compression and decompression speed but lower
           compression ratio than GZIP. If your CPU is fast enough you should be able
           to compress your data without making the backup duration longer.

           Both LZ4 and LZ4HC have the same decompression speed which is about twice
           the speed of the LZO compression. So for a restore both LZ4 and LZ4HC are
           good candidates.

           

.. warning::
   As LZ4 compression is not supported by Bacula, make sure **Compatible**:sup:`Fd`:sub:`Client`\  = no.

           \item [compression=LZ4HC]  \\
           All files saved will be software compressed using the LZ4HC
           compression format. The compression is done on a file by file basis by
           the File daemon. Everything else about GZIP is true for LZ4.

           LZ4HC is the High Compression version of the LZ4 compression. It has
           a higher compression ratio than LZ4 and is more comparable to GZIP-6
           in both compression rate and cpu usage.

           Both LZ4 and LZ4HC have the same decompression speed which is about twice
           the speed of the LZO compression. So for a restore both LZ4 and LZ4HC are
           good candidates.

           

.. warning::
   As LZ4 compression is not supported by Bacula, make sure **Compatible**:sup:`Fd`:sub:`Client`\  = no.

       \end{description}



    \item [signature=<MD5|SHA1|SHA256|SHA512>]  \\
           :index:`[TAG=signature] <single: signature>`%
           :index:`[TAG=Directive->signature] <pair: Directive; signature>`%
   It is strongly recommend to use signatures for your backups.
   Note, only one type of signature can be computed per file.

       \begin{description}
           \item [signature=MD5]  \\
           :index:`[TAG=MD5] <single: MD5>`%
           :index:`[TAG=signature->MD5] <pair: signature; MD5>`%
           An MD5 signature will be computed for each files saved.  Adding this
           option generates about 5\% extra overhead for each file saved.  In
           addition to the additional CPU time, the MD5 signature adds 16 more
           bytes per file to your catalog.

           \item [signature=SHA1]  \\
           :index:`[TAG=SHA1] <single: SHA1>`%
           :index:`[TAG=signature->SHA1] <pair: signature; SHA1>`%
           An SHA1 signature will be computed for each files saved.
           The SHA1 algorithm is
           purported to be some what slower than the MD5 algorithm, but at the same
           time is significantly better from a cryptographic point of view (i.e.
           much fewer collisions).
           The SHA1 signature requires adds 20 bytes per file to your catalog.

           \item [signature=SHA256]  \\
           :index:`[TAG=SHA256] <single: SHA256>`%
           :index:`[TAG=signature->SHA256] <pair: signature; SHA256>`%

           \item [signature=SHA512]  \\
           :index:`[TAG=SHA512] <single: SHA512>`%
           :index:`[TAG=signature->SHA512] <pair: signature; SHA512>`%
       \end{description}


   \item[basejob=<options>]
   :index:`[TAG=basejob] <single: basejob>`
   :index:`[TAG=Directive->basejob] <pair: Directive; basejob>`

   The options letters specified are used when running a {\bf Backup Level=Full}
   with BaseJobs. The options letters are the same than in the :strong:`verify=`
   option below.

   \item[accurate=<options>] :index:`[TAG=Accurate] <single: Accurate>`
     :index:`[TAG=Directive->accurate] <pair: Directive; accurate>` The options letters specified are used when
     running a {\bf Backup Level=Incremental/Differential} in Accurate mode. The
     options letters are the same than in the :strong:`verify=` option below.

   \item [verify=<options>]  \\
   :index:`[TAG=verify] <single: verify>`
   :index:`[TAG=Directive->verify] <pair: Directive; verify>`
      The options letters specified are used  when running a {\bf Verify
      Level=Catalog} as well as the  {\bf DiskToCatalog} level job. The options
      letters may be any  combination of the following:

         \begin{description}

         \item {\bf i}
         compare the inodes

         \item {\bf p}
         compare the permission bits

         \item {\bf n}
         compare the number of links

         \item {\bf u}
         compare the user id

         \item {\bf g}
         compare the group id

         \item {\bf s}
         compare the size

         \item {\bf a}
         compare the access time

         \item {\bf m}
         compare the modification time (st\_mtime)

         \item {\bf c}
         compare the change time (st\_ctime)

         \item {\bf d}
         report file size decreases

         \item {\bf 5}
         compare the MD5 signature

         \item {\bf 1}
         compare the SHA1 signature

         \item {\bf A}
         Only for Accurate option, it allows to always backup the file

         \end{description}

      A useful set of general options on the {\bf Level=Catalog}  or {\bf
      Level=DiskToCatalog}  verify is {\bf pins5} i.e. compare permission bits,
      inodes, number  of links, size, and MD5 changes.

   \item [onefs=yes|no]  \\
   :index:`[TAG=onefs] <single: onefs>`
   :index:`[TAG=Directive->onefs] <pair: Directive; onefs>`
      If set to {\bf yes} (the default), {\bf Bareos} will remain on a single
      file system.  That is it will not backup file systems that are mounted
      on a subdirectory.  If you are using a *nix system, you may not even be
      aware that there are several different filesystems as they are often
      automatically mounted by the OS (e.g.  /dev, /net, /sys, /proc, ...).
      Bareos will inform you when it decides not to
      traverse into another filesystem.  This can be very useful if you forgot
      to backup a particular partition.  An example of the informational
      message in the job report is:

   
   \begin{verbatim}
   rufus-fd: /misc is a different filesystem. Will not descend from / into /misc
   rufus-fd: /net is a different filesystem. Will not descend from / into /net
   rufus-fd: /var/lib/nfs/rpc_pipefs is a different filesystem. Will not descend from /var/lib/nfs into /var/lib/nfs/rpc_pipefs
   rufus-fd: /selinux is a different filesystem. Will not descend from / into /selinux
   rufus-fd: /sys is a different filesystem. Will not descend from / into /sys
   rufus-fd: /dev is a different filesystem. Will not descend from / into /dev
   rufus-fd: /home is a different filesystem. Will not descend from / into /home
   \end{verbatim}
   

      If you wish to backup multiple filesystems, you can  explicitly
      list each filesystem you want saved.  Otherwise, if you set the onefs option
      to {\bf no}, Bareos will backup  all mounted file systems (i.e. traverse mount
      points) that  are found within the {\bf FileSet}. Thus if  you have NFS or
      Samba file systems mounted on a directory listed  in your FileSet, they will
      also be backed up. Normally, it is  preferable to set {\bf onefs=yes} and to
      explicitly name  each filesystem you want backed up. Explicitly naming  the
      filesystems you want backed up avoids the possibility  of getting into a
      infinite loop recursing filesystems.  Another possibility is to
      use {\bf onefs=no} and to set {\bf fstype=ext2, ...}.
      See the example below for more details.

      If you think that Bareos should be backing up a particular directory
      and it is not, and you have {\bf onefs=no} set, before you complain,
      please do:

   
   \begin{verbatim}
     stat /
     stat <filesystem>
   \end{verbatim}
   

   where you replace {\bf filesystem} with the one in question.  If the
   {\bf Device:} number is different for / and for your filesystem, then they
   are on different filesystems.  E.g.
   
   \begin{verbatim}
   stat /
     File: `/'
     Size: 4096            Blocks: 16         IO Block: 4096   directory
   Device: 302h/770d       Inode: 2           Links: 26
   Access: (0755/drwxr-xr-x)  Uid: (    0/    root)   Gid: (    0/    root)
   Access: 2005-11-10 12:28:01.000000000 +0100
   Modify: 2005-09-27 17:52:32.000000000 +0200
   Change: 2005-09-27 17:52:32.000000000 +0200

   stat /net
     File: `/home'
     Size: 4096            Blocks: 16         IO Block: 4096   directory
   Device: 308h/776d       Inode: 2           Links: 7
   Access: (0755/drwxr-xr-x)  Uid: (    0/    root)   Gid: (    0/    root)
   Access: 2005-11-10 12:28:02.000000000 +0100
   Modify: 2005-11-06 12:36:48.000000000 +0100
   Change: 2005-11-06 12:36:48.000000000 +0100
   \end{verbatim}
   

      Also be aware that even if you include {\bf /home} in your list
      of files to backup, as you most likely should, you will get the
      informational message that  "/home is a different filesystem" when
      Bareos is processing the {\bf /} directory.  This message does not
      indicate an error. This message means that while examining the
      {\bf File =} referred to in the second part of the message, Bareos will
      not descend into the directory mentioned in the first part of the message.
      However, it is possible that the separate filesystem will be backed up
      despite the message. For example, consider the following FileSet:

   
   \begin{verbatim}
     File = /
     File = /var
   \end{verbatim}
   

      where {\bf /var} is a separate filesystem.  In this example, you will get a
      message saying that Bareos will not decend from {\bf /} into {\bf /var}.  But
      it is important to realise that Bareos will descend into {\bf /var} from the
      second File directive shown above.  In effect, the warning is bogus,
      but it is supplied to alert you to possible omissions from your FileSet. In
      this example, {\bf /var} will be backed up.  If you changed the FileSet such
      that it did not specify {\bf /var}, then {\bf /var} will not be backed up.

   \item [honor nodump flag=<yes|no>]  \\
   :index:`[TAG=honornodumpflag] <single: honornodumpflag>`
   :index:`[TAG=Directive->honornodumpflag] <pair: Directive; honornodumpflag>`
      If your file system supports the {\bf nodump} flag (e. g. most
      BSD-derived systems) Bareos will honor the setting of the flag
      when this option is set to {\bf yes}. Files having this flag set
      will not be included in the backup and will not show up in the
      catalog. For directories with the {\bf nodump} flag set recursion
      is turned off and the directory will be listed in the catalog.
      If the {\bf honor nodump flag} option is not defined
      or set to {\bf no} every file and directory will be eligible for
      backup.

   \item [portable=yes|no]  \\
   :index:`[TAG=portable] <single: portable>`
   :index:`[TAG=Directive->portable] <pair: Directive; portable>`
   

.. _portable:


      If set to {\bf yes} (default is {\bf no}), the Bareos File daemon will
      backup Win32 files in a portable format, but not all Win32 file
      attributes will be saved and restored.  By default, this option is set
      to {\bf no}, which means that on Win32 systems, the data will be backed
      up using Windows API calls and on WinNT/2K/XP, all the security and
      ownership attributes will be properly backed up (and restored).  However
      this format is not portable to other systems -- e.g.  Unix, Win95/98/Me.
      When backing up Unix systems, this option is ignored, and unless you
      have a specific need to have portable backups, we recommend accept the
      default ({\bf no}) so that the maximum information concerning your files
      is saved.

   \item [recurse=yes|no]  \\
   :index:`[TAG=recurse] <single: recurse>`
   :index:`[TAG=Directive->recurse] <pair: Directive; recurse>`
      If set to {\bf yes} (the default), Bareos will recurse (or descend) into
      all subdirectories found unless the directory is explicitly excluded
      using an {\bf exclude} definition.  If you set {\bf recurse=no}, Bareos
      will save the subdirectory entries, but not descend into the
      subdirectories, and thus will not save the files or directories
      contained in the subdirectories.  Normally, you will want the default
      ({\bf yes}).

   \item [sparse=yes|no]  \\
   :index:`[TAG=sparse] <single: sparse>`
   :index:`[TAG=Directive->sparse] <pair: Directive; sparse>`
      Enable special code that checks for sparse files such as created by
      ndbm.  The default is {\bf no}, so no checks are made for sparse files.
      You may specify {\bf sparse=yes} even on files that are not sparse file.
      No harm will be done, but there will be a small additional overhead to
      check for buffers of all zero, and if there is a 32K block of all zeros
      (see below), that block will become a hole in the file, which
      may not be desirable if the original file was not a sparse file.

      {\bf Restrictions:} Bareos reads files in 32K buffers.  If the whole
      buffer is zero, it will be treated as a sparse block and not written to
      tape.  However, if any part of the buffer is non-zero, the whole buffer
      will be written to tape, possibly including some disk sectors (generally
      4098 bytes) that are all zero.  As a consequence, Bareos's detection of
      sparse blocks is in 32K increments rather than the system block size.
      If anyone considers this to be a real problem, please send in a request
      for change with the reason.

      If you are not familiar with sparse files, an example is say a file
      where you wrote 512 bytes at address zero, then 512 bytes at address 1
      million.  The operating system will allocate only two blocks, and the
      empty space or hole will have nothing allocated.  However, when you read
      the sparse file and read the addresses where nothing was written, the OS
      will return all zeros as if the space were allocated, and if you backup
      such a file, a lot of space will be used to write zeros to the volume.
      Worse yet, when you restore the file, all the previously empty space
      will now be allocated using much more disk space.  By turning on the
      {\bf sparse} option, Bareos will specifically look for empty space in
      the file, and any empty space will not be written to the Volume, nor
      will it be restored.  The price to pay for this is that Bareos must
      search each block it reads before writing it.  On a slow system, this
      may be important.  If you suspect you have sparse files, you should
      benchmark the difference or set sparse for only those files that are
      really sparse.

      You probably should not use this option on files or raw disk devices
      that are not really sparse files (i.e. have holes in them).

   \item [readfifo=yes|no]  \\
   :index:`[TAG=readfifo] <single: readfifo>`
   :index:`[TAG=Directive->readfifo] <pair: Directive; readfifo>`
   

.. _readfifo:


      If enabled, tells the Client to read the data on a backup and write the
      data on a restore to any FIFO (pipe) that is explicitly mentioned in the
      FileSet.  In this case, you must have a program already running that
      writes into the FIFO for a backup or reads from the FIFO on a restore.
      This can be accomplished with the {\bf RunBeforeJob} directive.  If this
      is not the case, Bareos will hang indefinitely on reading/writing the
      FIFO. When this is not enabled (default), the Client simply saves the
      directory entry for the FIFO.

      Normally, when Bareos runs a RunBeforeJob, it waits until that
      script terminates, and if the script accesses the FIFO to write
      into it, the Bareos job will block and everything will stall.
      However, Vladimir Stavrinov as supplied tip that allows this feature
      to work correctly.  He simply adds the following to the beginning
      of the RunBeforeJob script:

   \begin{verbatim}
      exec > /dev/null
   \end{verbatim}


   \begin{verbatim}\begin{bconfig}{FileSet with Fifo}
   Include {
     Options {
       signature=SHA1
       readfifo=yes
     }
     File = /home/abc/fifo
   }
   \end{bconfig}\end{verbatim}

      This feature can be used to do a "hot" database backup.  
      You can use the {\bf RunBeforeJob} to create the fifo
      and to start a program that dynamically reads your database and writes
      it to the fifo.  Bareos will then write it to the Volume. 

      During the restore operation, the inverse is true, after Bareos creates
      the fifo if there was any data stored with it (no need to explicitly
      list it or add any options), that data will be written back to the fifo.
      As a consequence, if any such FIFOs exist in the fileset to be restored,
      you must ensure that there is a reader program or Bareos will block, and
      after one minute, Bareos will time out the write to the fifo and move on
      to the next file.

       If you are planing to use a Fifo for backup, better take a look to the :ref:`bpipe` section.


   \item [noatime=yes|no]  \\
   :index:`[TAG=noatime] <single: noatime>`
   :index:`[TAG=Directive->noatime] <pair: Directive; noatime>`
      If enabled, and if your Operating System supports the O\_NOATIME file
      open flag, Bareos will open all files to be backed up with this option.
      It makes it possible to read a file without updating the inode atime
      (and also without the inode ctime update which happens if you try to set
      the atime back to its previous value).  It also prevents a race
      condition when two programs are reading the same file, but only one does
      not want to change the atime.  It's most useful for backup programs and
      file integrity checkers (and Bareos can fit on both categories).

      This option is particularly useful for sites where users are sensitive
      to their MailBox file access time.  It replaces both the {\bf keepatime}
      option without the inconveniences of that option (see below).

      If your Operating System does not support this option, it will be
      silently ignored by Bareos.


   \item [mtimeonly=yes|no]  \\
   :index:`[TAG=mtimeonly] <single: mtimeonly>`
   :index:`[TAG=Directive->mtimeonly] <pair: Directive; mtimeonly>`
      If enabled, tells the Client that the selection of files during
      Incremental and Differential backups should based only on the st\_mtime
      value in the stat() packet.  The default is {\bf no} which means that
      the selection of files to be backed up will be based on both the
      st\_mtime and the st\_ctime values.  In general, it is not recommended
      to use this option.

   \item [keepatime=yes|no]  \\
   :index:`[TAG=keepatime] <single: keepatime>`
   :index:`[TAG=Directive->keepatime] <pair: Directive; keepatime>`
      The default is {\bf no}.  When enabled, Bareos will reset the st\_atime
      (access time) field of files that it backs up to their value prior to
      the backup.  This option is not generally recommended as there are very
      few programs that use st\_atime, and the backup overhead is increased
      because of the additional system call necessary to reset the times.
      However, for some files, such as mailboxes, when Bareos backs up the
      file, the user will notice that someone (Bareos) has accessed the
      file. In this, case keepatime can be useful.
      (I'm not sure this works on Win32).

      Note, if you use this feature, when Bareos resets the access time, the
      change time (st\_ctime) will automatically be modified by the system,
      so on the next incremental job, the file will be backed up even if
      it has not changed. As a consequence, you will probably also want
      to use {\bf mtimeonly = yes} as well as keepatime (thanks to
      Rudolf Cejka for this tip).

   \item [checkfilechanges=yes|no]  \\
   :index:`[TAG=checkfilechanges] <single: checkfilechanges>`
   :index:`[TAG=Directive->checkfilechanges] <pair: Directive; checkfilechanges>`
      If enabled, the Client will check size, age of each file after
      their backup to see if they have changed during backup. If time
      or size mismatch, an error will raise.

   \begin{verbatim}
    zog-fd: Client1.2007-03-31_09.46.21 Error: /tmp/test mtime changed during backup.
   \end{verbatim}

      In general, it is recommended to use this option.

   \item [hardlinks=yes|no]  \\
   :index:`[TAG=hardlinks] <single: hardlinks>`
   :index:`[TAG=Directive->hardlinks] <pair: Directive; hardlinks>`
      When enabled (default), this directive will cause hard links to be
      backed up. However, the File daemon keeps track of hard linked files and
      will backup the data only once. The process of keeping track of the
      hard links can be quite expensive if you have lots of them (tens of
      thousands or more). This doesn't occur on normal Unix systems, but if
      you use a program like BackupPC, it can create hundreds of thousands, or
      even millions of hard links. Backups become very long and the File daemon
      will consume a lot of CPU power checking hard links.  In such a case,
      set {\bf hardlinks=no} and hard links will not be backed up.  Note, using
      this option will most likely backup more data and on a restore the file
      system will not be restored identically to the original.

   \item [wild=<string>]  \\
   :index:`[TAG=wild] <single: wild>`
   :index:`[TAG=Directive->wild] <pair: Directive; wild>`
      Specifies a wild-card string to be applied to the filenames and
      directory names.  Note, if {\bf Exclude} is not enabled, the wild-card
      will select which files are to be included.  If {\bf Exclude=yes} is
      specified, the wild-card will select which files are to be excluded.
      Multiple wild-card directives may be specified, and they will be applied
      in turn until the first one that matches.  Note, if you exclude a
      directory, no files or directories below it will be matched.

      You may want to test your expressions prior to running your
      backup by using the :ref:`bwild` program.
      You can also test your full FileSet definition by using
      the :ref:`estimate <estimate>` command.
      It is recommended to enclose the string in double quotes.

   \item [wilddir=<string>]  \\
   :index:`[TAG=wilddir] <single: wilddir>`
   :index:`[TAG=Directive->wilddir] <pair: Directive; wilddir>`
      Specifies a wild-card string to be applied to directory names only.  No
      filenames will be matched by this directive.  Note, if {\bf Exclude} is
      not enabled, the wild-card will select directories to be
      included.  If {\bf Exclude=yes} is specified, the wild-card will select
      which directories are to be excluded.  Multiple wild-card directives may be
      specified, and they will be applied in turn until the first one that
      matches.  Note, if you exclude a directory, no files or directories
      below it will be matched.

      It is recommended to enclose the string in double quotes.

      You may want to test your expressions prior to running your
      backup by using the :ref:`bwild` program.
      You can also test your full FileSet definition by using
      the :ref:`estimate <estimate>` command.

   \item [wildfile=<string>]  \\
   :index:`[TAG=wildfile] <single: wildfile>`
   :index:`[TAG=Directive->wildfile] <pair: Directive; wildfile>`
      Specifies a wild-card string to be applied to non-directories. That
      is no directory entries will be matched by this directive.
      However, note that the match is done against the full path and filename,
      so your wild-card string must take into account that filenames
      are preceded by the full path.
      If {\bf Exclude}
      is not enabled, the wild-card will select which files are to be
      included.  If {\bf Exclude=yes} is specified, the wild-card will select
      which files are to be excluded.  Multiple wild-card directives may be
      specified, and they will be applied in turn until the first one that
      matches.

      It is recommended to enclose the string in double quotes.

      You may want to test your expressions prior to running your
      backup by using the :ref:`bwild` program.
      You can also test your full FileSet definition by using
      the :ref:`estimate <estimate>` command.
      An example of excluding with the WildFile option on Win32 machines is
      presented below.

   \item [regex=<string>]  \\
   :index:`[TAG=regex] <single: regex>`
   :index:`[TAG=Directive->regex] <pair: Directive; regex>`

   

.. _FileRegex:



      Specifies a POSIX extended regular expression to be applied to the
      filenames and directory names, which include the full path.  If {\bf
      Exclude} is not enabled, the regex will select which files are to be
      included.  If {\bf Exclude=yes} is specified, the regex will select
      which files are to be excluded.  Multiple regex directives may be
      specified within an Options resource, and they will be applied in turn
      until the first one that matches.  Note, if you exclude a directory, no
      files or directories below it will be matched.

      It is recommended to enclose the string in double quotes.

      The regex libraries differ from one operating system to
      another, and in addition, regular expressions are complicated,
      so you may want to test your expressions prior to running your
      backup by using the :ref:`bregex` program.
      You can also test your full FileSet definition by using
      the :ref:`estimate <estimate>` command.

      You find yourself using a lot of Regex statements, which will cost quite a lot
      of CPU time, we recommend you simplify them if you can, or better yet
      convert them to Wild statements which are much more efficient.


   \item [regexfile=<string>]  \\
   :index:`[TAG=regexfile] <single: regexfile>`
   :index:`[TAG=Directive->regexfile] <pair: Directive; regexfile>`
      Specifies a POSIX extended regular expression to be applied to
      non-directories. No directories will be matched by this directive.
      However, note that the match is done against the full path and
      filename, so your regex string must take into account that filenames
      are preceded by the full path.
      If {\bf Exclude} is not enabled, the regex will select which files are
      to be included.  If {\bf Exclude=yes} is specified, the regex will
      select which files are to be excluded.  Multiple regex directives may be
      specified, and they will be applied in turn until the first one that
      matches.

      It is recommended to enclose the string in double quotes.

      The regex libraries differ from one operating system to
      another, and in addition, regular expressions are complicated,
      so you may want to test your expressions prior to running your
      backup by using the :ref:`bregex` program.

   \item [regexdir=<string>]  \\
   :index:`[TAG=regexdir] <single: regexdir>`
   :index:`[TAG=Directive->regexdir] <pair: Directive; regexdir>`
      Specifies a POSIX extended regular expression to be applied to directory
      names only.  No filenames will be matched by this directive.  Note, if
      {\bf Exclude} is not enabled, the regex will select directories
      files are to be included.  If {\bf Exclude=yes} is specified, the
      regex will select which files are to be excluded.  Multiple
      regex directives may be specified, and they will be applied in turn
      until the first one that matches.  Note, if you exclude a directory, no
      files or directories below it will be matched.

      It is recommended to enclose the string in double quotes.

      The regex libraries differ from one operating system to
      another, and in addition, regular expressions are complicated,
      so you may want to test your expressions prior to running your
      backup by using the :ref:`bregex` program.

   \xdirective{dir}{}{Exclude}{\dtYesNo}{}{no}{}{%
      When enabled, any files matched within the
      Options will be excluded from the backup.
   }

   \item [aclsupport=yes|no]  \\
   :index:`[TAG=aclsupport] <single: aclsupport>`
   :index:`[TAG=Directive->aclsupport] <pair: Directive; aclsupport>`
   

.. _ACLSupport:


      The default is {\bf yes} since Bareos 18.2. If this option is set to yes, and you have the
      POSIX {\bf libacl} installed on your Linux system, Bareos will backup the
      file and directory Unix Access Control Lists (ACL) as defined in IEEE Std
      1003.1e draft 17 and "POSIX.1e" (abandoned).  This feature is
      available on Unix systems only and requires the Linux ACL library. Bareos is
      automatically compiled with ACL support if the {\bf libacl} library is
      installed on your Linux system (shown in config.out).  While restoring the
      files Bareos will try to restore the ACLs, if there is no ACL support
      available on the system, Bareos restores the files and directories but
      not the ACL information.  Please note, if you backup an EXT3 or XFS
      filesystem with ACLs, then you restore them to a different filesystem
      (perhaps reiserfs) that does not have ACLs, the ACLs will be ignored.

      For other operating systems there is support for either POSIX ACLs or
      the more extensible NFSv4 ACLs.

      The ACL stream format between Operation Systems is :strong:`not`
      compatible so for example an ACL saved on Linux cannot be restored on
      Solaris.

      The following Operating Systems are currently supported:

      \begin{enumerate}
      \item AIX (pre-5.3 (POSIX) and post 5.3 (POSIX and NFSv4) ACLs)
      \item Darwin
      \item FreeBSD (POSIX and NFSv4/ZFS ACLs)
      \item HPUX
      \item IRIX
      \item Linux
      \item Solaris (POSIX and NFSv4/ZFS ACLs)
      \item Tru64
      \end{enumerate}

   

.. _XattrSupport:


   \item [xattrsupport=yes|no]  \\
   :index:`[TAG=xattrsupport] <single: xattrsupport>`
   :index:`[TAG=Directive->xattrsupport] <pair: Directive; xattrsupport>`
      The default is {\bf yes} since Bareos 18.2. If this option is set to yes, and your
      operating system support either so called Extended Attributes or
      Extensible Attributes Bareos will backup the file and directory
      XATTR data. This feature is available on UNIX only and depends on
      support of some specific library calls in libc.

      The XATTR stream format between Operating Systems is {\bf not}
      compatible so an XATTR saved on Linux cannot for example be restored
      on Solaris.

      On some operating systems ACLs are also stored as Extended Attributes
      (Linux, Darwin, FreeBSD) Bareos checks if you have the aclsupport
      option enabled and if so will not save the same info when saving
      extended attribute information. Thus ACLs are only saved once.

      The following Operating Systems are currently supported:

      \begin{enumerate}
      \item AIX (Extended Attributes)
      \item Darwin (Extended Attributes)
      \item FreeBSD (Extended Attributes)
      \item IRIX (Extended Attributes)
      \item Linux (Extended Attributes)
      \item NetBSD (Extended Attributes)
      \item Solaris (Extended Attributes and Extensible Attributes)
      \item Tru64 (Extended Attributes)
      \end{enumerate}

   \item [ignore case=yes|no]  \\
   :index:`[TAG=ignore case] <single: ignore case>`
   :index:`[TAG=Directive->ignore case] <pair: Directive; ignore case>`
      The default is {\bf no}.  On Windows systems, you will almost surely
      want to set this to {\bf yes}.  When this directive is set to {\bf yes}
      all the case of character will be ignored in wild-card and regex
      comparisons.  That is an uppercase A will match a lowercase a.

   \item [fstype=filesystem-type]  \\
   :index:`[TAG=fstype] <single: fstype>`
   :index:`[TAG=Directive->fstype] <pair: Directive; fstype>`
      This option allows you to select files and directories by the
      filesystem type.  The permitted filesystem-type names are:

      ext2, jfs, ntfs, proc, reiserfs, xfs, usbdevfs, sysfs, smbfs,
      iso9660.

      You may have multiple Fstype directives, and thus permit matching
      of multiple filesystem types within a single Options resource.  If
      the type specified on the fstype directive does not match the
      filesystem for a particular directive, that directory will not be
      backed up.  This directive can be used to prevent backing up
      non-local filesystems. Normally, when you use this directive, you
      would also set {\bf onefs=no} so that Bareos will traverse filesystems.

      This option is not implemented in Win32 systems.

   \item [DriveType=Windows-drive-type]  \\
   :index:`[TAG=DriveType] <single: DriveType>`
   :index:`[TAG=Directive->DriveType] <pair: Directive; DriveType>`
      This option is effective only on Windows machines and is
      somewhat similar to the Unix/Linux {\bf fstype} described
      above, except that it allows you to select what Windows
      drive types you want to allow.  By default all drive
      types are accepted.

      The permitted drivetype names are:

      removable, fixed, remote, cdrom, ramdisk

      You may have multiple Driveype directives, and thus permit matching
      of multiple drive types within a single Options resource.  If
      the type specified on the drivetype directive does not match the
      filesystem for a particular directive, that directory will not be
      backed up.  This directive can be used to prevent backing up
      non-local filesystems. Normally, when you use this directive, you
      would also set {\bf onefs=no} so that Bareos will traverse filesystems.

      This option is not implemented in Unix/Linux systems.

   \item [hfsplussupport=yes|no]  \\
   :index:`[TAG=hfsplussupport] <single: hfsplussupport>`
   :index:`[TAG=Directive->hfsplussupport] <pair: Directive; hfsplussupport>`
      This option allows you to turn on support for Mac OSX HFS plus
      finder information.

   \item [strippath=<integer>]  \\
   :index:`[TAG=strippath] <single: strippath>`
   :index:`[TAG=Directive->strippath] <pair: Directive; strippath>`
      This option will cause {\bf integer} paths to be stripped from
      the front of the full path/filename being backed up. This can
      be useful if you are migrating data from another vendor or if
      you have taken a snapshot into some subdirectory.  This directive
      can cause your filenames to be overlayed with regular backup data,
      so should be used only by experts and with great care.

   \item [size=sizeoption]  \\
   :index:`[TAG=size] <single: size>`
   :index:`[TAG=Directive->size] <pair: Directive; size>`
      This option will allow you to select files by their actual size.
      You can select either files smaller than a certain size or bigger
      then a certain size, files of a size in a certain range or files
      of a size which is within 1 \% of its actual size.

      The following settings can be used:

      \begin{enumerate}
      \item {\bf <size>-<size>} - Select file in range size - size.
      \item {\bf <size} - Select files smaller than size.
      \item {\bf >size} - Select files bigger than size.
      \item {\bf size} - Select files which are within 1 \% of size.
      \end{enumerate}

   \item [shadowing=none|localwarn|localremove|globalwarn|globalremove]  \\
   :index:`[TAG=shadowing] <single: shadowing>`
   :index:`[TAG=Directive->shadowing] <pair: Directive; shadowing>`
      The default is {\bf none}. This option performs a check within the
      fileset for any file-list entries which are shadowing each other.
      Lets say you specify / and /usr but /usr is not a separate filesystem.
      Then in the normal situation both / and /usr would lead to data being
      backed up twice.

      The following settings can be used:

      \begin{enumerate}
      \item none - Do NO shadowing check
      \item localwarn - Do shadowing check within one include block and warn
      \item localremove - Do shadowing check within one include block and remove duplicates
      \item globalwarn - Do shadowing check between all include blocks and warn
      \item globalremove - Do shadowing check between all include blocks and remove duplicates
      \end{enumerate}

      The local and global part of the setting relate to the fact if the check
      should be performed only within one include block (local) or between multiple
      include blocks of the same fileset (global). The warn and remove part of the
      keyword sets the action e.g. warn the user about shadowing or remove
      the entry shadowing the other.

      Example for a fileset resource with fileset shadow warning enabled:

   \begin{verbatim}\begin{bconfig}{FileSet resource with fileset shadow warning enabled}
   FileSet {
     Name = "Test Set"
     Include {
       Options {
         signature = MD5
         shadowing = localwarn
       }
     File = /
     File = /usr
     }
   }
   \end{bconfig}\end{verbatim}


   \item [meta=tag]  \\
   :index:`[TAG=meta] <single: meta>`
   :index:`[TAG=Directive->meta] <pair: Directive; meta>`
      This option will add a meta tag to a fileset. These meta tags are used
      by the Native NDMP protocol to pass NDMP backup or restore environment
      variables via the Data Management Agent (DMA) in Bareos to the remote
      NDMP Data Agent. You can have zero or more metatags which are all passed
      to the remote NDMP Data Agent.

   \end{description}

.. _fileset-exclude:

FileSet Exclude Ressource
~~~~~~~~~~~~~~~~~~~~~~~~~

:index:`[TAG=Excluding Files and Directories] <single: Excluding Files and Directories>`

FileSet Exclude-Ressources very similar to Include-Ressources, except that they only allow following directives:

\begin{description}
   % file | directoy | |command | \<includefile-client | <includefile-server
   \xdirective{dir}{}{File}{ 
     filename \textbar\ 
     directory \textbar\ 
     \textbar command \textbar\ 
     \textbackslash\textless includefile-client \textbar\ 
     \textless includefile-server 
     }{}{}{}{%
       Files to exclude are descripted in the same way as at the \nameref{fileset-include}.
   }
   \end{description}

For example:

.. code-block:: sh
   :caption: FileSet using Exclude

   FileSet {
     Name = Exclusion_example
     Include {
       Options {
         Signature = SHA1
       }
       File = /
       File = /boot
       File = /home
       File = /rescue
       File = /usr
     }
     Exclude {
       File = /proc
       File = /tmp                          # Don't add trailing /
       File = .journal
       File = .autofsck
     }
   }

Another way to exclude files and directories is to use the :strong:`Exclude` option from the Include section.

FileSet Examples
~~~~~~~~~~~~~~~~

:index:`[TAG=Example->FileSet] <pair: Example; FileSet>` :index:`[TAG=FileSet->Example] <pair: FileSet; Example>`

The following is an example of a valid FileSet resource definition. Note, the first Include pulls in the contents of the file :file:`/etc/backup.list` when Bareos is started (i.e. the @), and that file must have each filename to be backed up preceded by a File = and on a separate line.

.. code-block:: sh
   :caption: FileSet using import

   FileSet {
     Name = "Full Set"
     Include {
       Options {
         Compression=GZIP
         signature=SHA1
         Sparse = yes
       }
       @/etc/backup.list
     }
     Include {
        Options {
           wildfile = "*.o"
           wildfile = "*.exe"
           Exclude = yes
        }
        File = /root/myfile
        File = /usr/lib/another_file
     }
   }

In the above example, all the files contained in :file:`/etc/backup.list` will be compressed with GZIP compression, an SHA1 signature will be computed on the file’s contents (its data), and sparse file handling will apply.

The two directories :file:`/root/myfile` and :file:`/usr/lib/another_file` will also be saved without any options, but all files in those directories with the extensions :file:`.o` and :file:`.exe` will be excluded.

Let’s say that you now want to exclude the directory :file:`/tmp`. The simplest way to do so is to add an exclude directive that lists :file:`/tmp`. The example above would then become:

.. code-block:: sh
   :caption: extended FileSet excluding /tmp

   FileSet {
     Name = "Full Set"
     Include {
       Options {
         Compression=GZIP
         signature=SHA1
         Sparse = yes
       }
       @/etc/backup.list
     }
     Include {
        Options {
           wildfile = "*.o"
           wildfile = "*.exe"
           Exclude = yes
        }
        File = /root/myfile
        File = /usr/lib/another_file
     }
     Exclude {
        File = /tmp                          # don't add trailing /
     }
   }

You can add wild-cards to the File directives listed in the Exclude directory, but you need to take care because if you exclude a directory, it and all files and directories below it will also be excluded.

Now lets take a slight variation on the above and suppose you want to save all your whole filesystem except :file:`/tmp`. The problem that comes up is that Bareos will not normally cross from one filesystem to another. Doing a :command:`df` command, you get the following output:

.. code-block:: sh
   :caption: df

   <command>df</command>
   Filesystem      1k-blocks      Used Available Use% Mounted on
   /dev/hda5         5044156    439232   4348692  10% /
   /dev/hda1           62193      4935     54047   9% /boot
   /dev/hda9        20161172   5524660  13612372  29% /home
   /dev/hda2           62217      6843     52161  12% /rescue
   /dev/hda8         5044156     42548   4745376   1% /tmp
   /dev/hda6         5044156   2613132   2174792  55% /usr
   none               127708         0    127708   0% /dev/shm
   //minimatou/c$   14099200   9895424   4203776  71% /mnt/mmatou
   lmatou:/          1554264    215884   1258056  15% /mnt/matou
   lmatou:/home      2478140   1589952    760072  68% /mnt/matou/home
   lmatou:/usr       1981000   1199960    678628  64% /mnt/matou/usr
   lpmatou:/          995116    484112    459596  52% /mnt/pmatou
   lpmatou:/home    19222656   2787880  15458228  16% /mnt/pmatou/home
   lpmatou:/usr      2478140   2038764    311260  87% /mnt/pmatou/usr
   deuter:/          4806936     97684   4465064   3% /mnt/deuter
   deuter:/home      4806904    280100   4282620   7% /mnt/deuter/home
   deuter:/files    44133352  27652876  14238608  67% /mnt/deuter/files

And we see that there are a number of separate filesystems (/ /boot /home /rescue /tmp and /usr not to mention mounted systems). If you specify only / in your Include list, Bareos will only save the Filesystem /dev/hda5. To save all filesystems except /tmp with out including any of the Samba or NFS mounted systems, and explicitly excluding a /tmp, /proc, .journal, and .autofsck, which you will not want to be saved and restored, you can use the following:

.. code-block:: sh
   :caption: FileSet mount points

   FileSet {
     Name = Include_example
     Include {
       Options {
          wilddir = /proc
          wilddir = /tmp
          wildfile = "/.journal"
          wildfile = "/.autofsck"
          exclude = yes
       }
       File = /
       File = /boot
       File = /home
       File = /rescue
       File = /usr
     }
   }

Since :file:`/tmp` is on its own filesystem and it was not explicitly named in the Include list, it is not really needed in the exclude list. It is better to list it in the Exclude list for clarity, and in case the disks are changed so that it is no longer in its own partition.

Now, lets assume you only want to backup .Z and .gz files and nothing else. This is a bit trickier because Bareos by default will select everything to backup, so we must exclude everything but .Z and .gz files. If we take the first example above and make the obvious modifications to it, we might come up with a FileSet that looks like this:

.. code-block:: sh
   :caption: Non-working example

   FileSet {
     Name = "Full Set"
     Include {                    !!!!!!!!!!!!
        Options {                    This
           wildfile = "*.Z"          example
           wildfile = "*.gz"         doesn't
                                     work
        }                          !!!!!!!!!!!!
        File = /myfile
     }
   }

The \*.Z and \*.gz files will indeed be backed up, but all other files that are not matched by the Options directives will automatically be backed up too (i.e. that is the default rule).

To accomplish what we want, we must explicitly exclude all other files. We do this with the following:

.. code-block:: sh
   :caption: Exclude all except specific wildcards

   FileSet {
     Name = "Full Set"
     Include {
        Options {
           wildfile = "*.Z"
           wildfile = "*.gz"
        }
        Options {
           Exclude = yes
           RegexFile = ".*"
        }
        File = /myfile
     }
   }

The "trick" here was to add a RegexFile expression that matches all files. It does not match directory names, so all directories in /myfile will be backed up (the directory entry) and any \*.Z and \*.gz files contained in them. If you know that certain directories do not contain any \*.Z or \*.gz files and you do not want the directory entries backed up, you will need to explicitly exclude those directories. Backing up a directory entries is not very expensive.

Bareos uses the system regex library and some of them are different on different OSes. The above has been reported not to work on FreeBSD. This can be tested by using the :strong:`estimate job=job-name
listing` command in the console and adapting the RegexFile expression appropriately.

Please be aware that allowing Bareos to traverse or change file systems can be very dangerous. For example, with the following:

.. code-block:: sh
   :caption: backup all filesystem below /mnt/matou (use with care)

   FileSet {
     Name = "Bad example"
     Include {
       Options {
         onefs=no
       }
       File = /mnt/matou
     }
   }

you will be backing up an NFS mounted partition (/mnt/matou), and since onefs is set to no, Bareos will traverse file systems. Now if /mnt/matou has the current machine’s file systems mounted, as is often the case, you will get yourself into a recursive loop and the backup will never end.

As a final example, let’s say that you have only one or two subdirectories of /home that you want to backup. For example, you want to backup only subdirectories beginning with the letter a and the letter b – i.e. :file:`/home/a*` and :file:`/home/b*`. Now, you might first try:

.. code-block:: sh
   :caption: Non-working example

   FileSet {
     Name = "Full Set"
     Include {
        Options {
           wilddir = "/home/a*"
           wilddir = "/home/b*"
        }
        File = /home
     }
   }

The problem is that the above will include everything in /home. To get things to work correctly, you need to start with the idea of exclusion instead of inclusion. So, you could simply exclude all directories except the two you want to use:

.. code-block:: sh
   :caption: Exclude by regex

   FileSet {
     Name = "Full Set"
     Include {
        Options {
           RegexDir = "^/home/[c-z]"
           exclude = yes
        }
        File = /home
     }
   }

And assuming that all subdirectories start with a lowercase letter, this would work.

An alternative would be to include the two subdirectories desired and exclude everything else:

.. code-block:: sh
   :caption: Include and Exclude

   FileSet {
     Name = "Full Set"
     Include {
        Options {
           wilddir = "/home/a*"
           wilddir = "/home/b*"
        }
        Options {
           RegexDir = ".*"
           exclude = yes
        }
        File = /home
     }
   }

The following example shows how to back up only the My Pictures directory inside the My Documents directory for all users in C:/Documents and Settings, i.e. everything matching the pattern:

:file:`C:/Documents and Settings/*/My Documents/My Pictures/*`

To understand how this can be achieved, there are two important points to remember:

Firstly, Bareos walks over the filesystem depth-first starting from the File = lines. It stops descending when a directory is excluded, so you must include all ancestor directories of each directory containing files to be included.

Secondly, each directory and file is compared to the Options clauses in the order they appear in the FileSet. When a match is found, no further clauses are compared and the directory or file is either included or excluded.

The FileSet resource definition below implements this by including specifc directories and files and excluding everything else.

.. code-block:: sh
   :caption: Include/Exclude example

   FileSet {
     Name = "AllPictures"

     Include {

       File  = "C:/Documents and Settings"

       Options {
         signature = SHA1
         verify = s1
         IgnoreCase = yes

         # Include all users' directories so we reach the inner ones.  Unlike a
         # WildDir pattern ending in *, this RegExDir only matches the top-level
         # directories and not any inner ones.
         RegExDir = "^C:/Documents and Settings/[^/]+$"

         # Ditto all users' My Documents directories.
         WildDir = "C:/Documents and Settings/*/My Documents"

         # Ditto all users' My Documents/My Pictures directories.
         WildDir = "C:/Documents and Settings/*/My Documents/My Pictures"

         # Include the contents of the My Documents/My Pictures directories and
         # any subdirectories.
         Wild = "C:/Documents and Settings/*/My Documents/My Pictures/*"
       }

       Options {
         Exclude = yes
         IgnoreCase = yes

         # Exclude everything else, in particular any files at the top level and
         # any other directories or files in the users' directories.
         Wild = "C:/Documents and Settings/*"
       }
     }
   }

Windows FileSets
~~~~~~~~~~~~~~~~

:index:`[TAG=Windows->FileSet] <pair: Windows; FileSet>` :index:`[TAG=FileSet->Windows] <pair: FileSet; Windows>` 

.. _win32:

 If you are entering Windows file names, the directory path may be preceded by the drive and a colon (as in c:). However, the path separators must be specified in Unix convention (i.e. forward slash (/)). If you wish to include a quote in a file name, precede the quote with a backslash (\). For example you might use the following for a Windows machine to backup the "My Documents"
directory:

.. code-block:: sh
   :caption: Windows FileSet

   FileSet {
     Name = "Windows Set"
     Include {
       Options {
          WildFile = "*.obj"
          WildFile = "*.exe"
          exclude = yes
        }
        File = "c:/My Documents"
     }
   }

For exclude lists to work correctly on Windows, you must observe the following rules:

-  Filenames are case sensitive, so you must use the correct case.

-  To exclude a directory, you must not have a trailing slash on the directory name.

-  If you have spaces in your filename, you must enclose the entire name in double-quote characters ("). Trying to use a backslash before the space will not work.

-  If you are using the old Exclude syntax (noted below), you may not specify a drive letter in the exclude. The new syntax noted above should work fine including driver letters.

Thanks to Thiago Lima for summarizing the above items for us. If you are having difficulties getting includes or excludes to work, you might want to try using the estimate job=xxx listing command documented in the :ref:`Console chapter <estimate>` of this manual.

On Win32 systems, if you move a directory or file or rename a file into the set of files being backed up, and a Full backup has already been made, Bareos will not know there are new files to be saved during an Incremental or Differential backup (blame Microsoft, not us). To avoid this problem, please copy any new directory or files into the backup area. If you do not have enough disk to copy the directory or files, move them, but then initiate a Full backup.

Example Fileset for Windows
'''''''''''''''''''''''''''

:index:`[TAG=FileSet->Windows Example] <pair: FileSet; Windows Example>` :index:`[TAG=Windows->FileSet->Example] <triple: Windows; FileSet; Example>`

The following example demostrates a Windows FileSet. It backups all data from all fixed drives and only excludes some Windows temporary data.

.. code-block:: sh
   :caption: Windows All Drives FileSet

   FileSet {
     Name = "Windows All Drives"
     Enable VSS = yes
     Include {
       Options {
         Signature = MD5
         Drive Type = fixed
         IgnoreCase = yes
         WildFile = "[A-Z]:/pagefile.sys"
         WildDir = "[A-Z]:/RECYCLER"
         WildDir = "[A-Z]:/$RECYCLE.BIN"
         WildDir = "[A-Z]:/System Volume Information"
         Exclude = yes
       }
       File = /
     }
   }

\variable{File = /} includes all Windows drives. Using \variable{Drive Type = fixed} excludes drives like USB-Stick or CD-ROM Drive. Using \variable{WildDir = "[A-Z]:/RECYCLER"} excludes the backup of the directory :file:`RECYCLER` from all drives.

Testing Your FileSet
~~~~~~~~~~~~~~~~~~~~

:index:`[TAG=FileSet->Testing Your] <pair: FileSet; Testing Your>` :index:`[TAG=Testing Your FileSet] <single: Testing Your FileSet>`

If you wish to get an idea of what your FileSet will really backup or if your exclusion rules will work correctly, you can test it by using the :ref:`estimate <estimate>` command.

As an example, suppose you add the following test FileSet:

.. code-block:: sh
   :caption: FileSet for all *.c files

   FileSet {
     Name = Test
     Include {
       File = /home/xxx/test
       Options {
          regex = ".*\\.c$"
       }
     }
   }

You could then add some test files to the directory /home/xxx/test and use the following command in the console:

.. code-block:: sh
   :caption: estimate

   estimate job=<any-job-name> listing client=<desired-client> fileset=Test

to give you a listing of all files that match. In the above example, it should be only files with names ending in .c.

.. _DirectorResourceClient:

Client Resource
---------------

:index:`[TAG=Resource->Client] <pair: Resource; Client>` :index:`[TAG=Client Resource] <single: Client Resource>`

The Client (or FileDaemon) resource defines the attributes of the Clients that are served by this Director; that is the machines that are to be backed up. You will need one Client resource definition for each machine to be backed up.

\defDirective{Dir}{Client}{Address}{}{}{%
   Where the address is a host name, a fully qualified domain name, or a
   network address in dotted quad notation for a Bareos File server daemon.
   This directive is required.
   }

\defDirective{Dir}{Client}{Auth Type}{}{}{%
   Specifies the authentication type that must be supplied when connecting to
   a backup protocol that uses a specific authentication type.
   }

\defDirective{Dir}{Client}{Auto Prune}{}{}{%
   If set to \argument{yes},
   Bareos will  automatically apply the \linkResourceDirective{Dir}{Client}{File Retention} period
   and the \linkResourceDirective{Dir}{Client}{Job Retention} period for the client at the end of the job.

   Pruning affects only information in the catalog and not data
   stored in the backup archives (on Volumes), but if pruning deletes all data
   referring to a certain volume, the volume is regarded as empty and will possibly
   be overwritten before the volume retention has expired.
   }

\defDirective{Dir}{Client}{Catalog}{}{}{%
   This specifies the  name of the catalog resource to be used for this Client.
   If none is specified the first defined catalog is used.
   }

\defDirective{Dir}{Client}{Connection From Client To Director}{}{}{%
   For details, see \nameref{section-ClientInitiatedConnection}.
   }

\defDirective{Dir}{Client}{Connection From Director To Client}{}{}{%
   }

\defDirective{Dir}{Client}{Description}{}{}{%
   }

\defDirective{Dir}{Client}{Enabled}{}{}{%
   }

\defDirective{Dir}{Client}{FD Address}{}{}{%
   }

\defDirective{Dir}{Client}{FD Password}{}{}{%
   }

\defDirective{Dir}{Client}{FD Port}{}{}{%
   Where the port is a port  number at which the \bareosFd can
   be contacted.  The default is 9102. For NDMP backups set this to 10000.
   }

\defDirective{Dir}{Client}{File Retention}{}{}{%
   The File Retention directive defines the length of time that  Bareos will
   keep File records in the Catalog database after the End time of the
   Job corresponding to the File records.
   When this time period expires
   and \resourceDirectiveValue{Dir}{Client}{Auto Prune}{yes},
   Bareos will prune (remove) File records
   that  are older than the specified File Retention period. Note, this  affects
   only records in the catalog database. It does not  affect your archive
   backups.

   File records  may actually be retained for a shorter period than you specify
   on  this directive if you specify either a shorter \linkResourceDirective{Dir}{Client}{Job Retention}  or a
   shorter \linkResourceDirective{Dir}{Pool}{Volume Retention} period. The shortest  retention period of the
   three takes precedence.

   The  default is 60 days.
   }

\defDirective{Dir}{Client}{Hard Quota}{}{}{%
   The amount of data determined by the Hard Quota directive sets the hard limit of backup space that cannot be exceeded. This is the maximum amount this client can back up before any backup job will be aborted.

   If the Hard Quota is exceeded, the running job is terminated:

   \bconfigInput{config/DirClientHardQuota1.conf}

   }

\defDirective{Dir}{Client}{Heartbeat Interval}{}{}{%
   This directive is optional and if specified will cause the Director to
   set a keepalive interval (heartbeat) in seconds on each of the sockets
   it opens for the Storage resource.
   If set, this value overrides \linkResourceDirective{Dir}{Director}{Heartbeat Interval}.
   }

\defDirective{Dir}{Client}{Job Retention}{}{}{%
   The Job Retention directive defines the length of time that  Bareos will keep
   Job records in the Catalog database after the Job End time.  When
   this time period expires and \resourceDirectiveValue{Dir}{Client}{Auto Prune}{yes}
   Bareos will prune (remove) Job records that are older than the specified
   File Retention period.  As with the other retention periods, this
   affects only records in the catalog and not data in your archive backup.

   If a Job record is selected for pruning, all associated File and JobMedia
   records will also be pruned regardless of the File Retention period set.
   As a consequence, you normally will set the File retention period to be
   less than the Job retention period.  The Job retention period can actually
   be less than the value you specify here if you set the \linkResourceDirective{Dir}{Pool}{Volume
   Retention} directive to a smaller duration.  This is
   because the Job retention period and the Volume retention period are
   independently applied, so the smaller of the two takes precedence.

   The default is 180 days.
   }

\defDirective{Dir}{Client}{Lan Address}{}{}{%
   This directive might be useful in network setups where the \bareosDir and \bareosSd need different addresses to communicate with the \bareosFd.

   For details, see \nameref{LanAddress}.

   This directive corresponds to \linkResourceDirective{Dir}{Storage}{Lan Address}.
   }

\defDirective{Dir}{Client}{Maximum Bandwidth Per Job}{}{}{%
   The speed parameter specifies the maximum allowed bandwidth that a job may use
   when started for this Client.
   }

\defDirective{Dir}{Client}{Maximum Concurrent Jobs}{}{}{%
   This directive specifies the maximum number of Jobs with the current Client
   that  can run concurrently. Note, this directive limits only Jobs  for Clients
   with the same name as the resource in which it appears. Any  other
   restrictions on the maximum concurrent jobs such as in  the Director, Job or
   Storage resources will also apply in addition to  any limit specified here.
   }

\defDirective{Dir}{Client}{Name}{}{}{%
   The client name which will be used in the  Job resource directive or in the
   console run command.
   }

\defDirective{Dir}{Client}{NDMP Block Size}{}{}{%
   This directive sets the default NDMP blocksize for this client.
   }

\defDirective{Dir}{Client}{NDMP Log Level}{}{}{%
   This directive sets the loglevel for the NDMP protocol library.
   }

\defDirective{Dir}{Client}{Passive}{}{13.2.0}{%
   The normal way of initializing the data channel (the channel where the backup data itself is transported)
   is done by the file daemon (client) that connects to the storage daemon.

   By using the client passive mode, the initialization of the datachannel is reversed, so that the storage daemon connects to the filedaemon.

   See chapter \ilink{Passive Client}{PassiveClient}.
   }

\defDirective{Dir}{Client}{Password}{}{}{%
   This is the password to be  used when establishing a connection with the File
   services, so  the Client configuration file on the machine to be backed up
   must  have the same password defined for this Director.

   The password is plain text.
   }

\defDirective{Dir}{Client}{Port}{}{}{%
   }

\defDirective{Dir}{Client}{Protocol}{Native|NDMP}{13.2.0}{%
   The backup protocol to use to run the Job.

   Currently the director understands the following protocols:
   \begin{enumerate}
   \item Native - The native Bareos protocol
   \item NDMP - The NDMP protocol
   \end{enumerate}
   }

\defDirective{Dir}{Client}{Quota Include Failed Jobs}{}{}{%
   When calculating the amount a client used take into consideration any failed Jobs.
   }

\defDirective{Dir}{Client}{Soft Quota}{}{}{%
   This is the amount after which there will be a warning issued that a client
   is over his softquota. A client can keep doing backups until it hits the
   hard quota or when the \linkResourceDirective{Dir}{Client}{Soft Quota Grace Period} is expired.
   }

\defDirective{Dir}{Client}{Soft Quota Grace Period}{}{}{%
   Time allowed for a client to be over its \linkResourceDirective{Dir}{Client}{Soft Quota} before it will be enforced.

   When the amount of data backed up by the client outruns the value specified by the Soft Quota directive, the next start of a backup job will start the soft quota grace time period. This is written to the job log:

   \bconfigInput{config/DirClientSoftQuotaGracePeriod1.conf}

   In the Job Overview, the value of Grace Expiry Date: will then change from \parameter{Soft Quota was never exceeded} to the date when the grace time expires, e.g. \parameter{11-Dec-2012 04:09:05}.

   During that period, it is possible to do backups even if the total amount of stored data exceeds the limit specified by soft quota.

   If in this state, the job log will write:

   \bconfigInput{config/DirClientSoftQuotaGracePeriod2.conf}

   After the grace time expires, in the next backup job of the client, the value for Burst Quota will be set to the value that the client has stored at this point in time. Also, the job will be terminated. The following information in the job log shows what happened:

   \bconfigInput{config/DirClientSoftQuotaGracePeriod3.conf}

   At this point, it is not possible to do any backup of the client. To be able to do more backups, the amount of stored data for this client has to fall under the burst quota value.
   }

\defDirective{Dir}{Client}{Strict Quotas}{}{}{%
   The directive Strict Quotas determines whether, after the Grace Time Period is over,
   to enforce the Burst Limit (Strict Quotas = {\bf No}) or
   the Soft Limit (Strict Quotas = {\bf Yes}).

   The Job Log shows either

   \bconfigInput{config/DirClientStrictQuotas1.conf}

   or

   \bconfigInput{config/DirClientStrictQuotas2.conf}

   }

\defDirective{Dir}{Client}{TLS Allowed CN}{}{}{%
   }

\defDirective{Dir}{Client}{TLS Authenticate}{}{}{%
   }

\defDirective{Dir}{Client}{TLS CA Certificate Dir}{}{}{%
   }

\defDirective{Dir}{Client}{TLS CA Certificate File}{}{}{%
   }

\defDirective{Dir}{Client}{TLS Certificate}{}{}{%
   }

\defDirective{Dir}{Client}{TLS Certificate Revocation List}{}{}{%
   }

\defDirective{Dir}{Client}{TLS Enable}{}{}{%
   Bareos can be configured to encrypt all its network traffic.
   See chapter \nameref{TlsDirectives} to see,
   how the Bareos Director (and the other components) must be configured to use TLS.
   }

\defDirective{Dir}{Client}{TLS Key}{}{}{%
   }

\defDirective{Dir}{Client}{TLS Require}{}{}{%
   }

\defDirective{Dir}{Client}{Username}{}{}{%
   Specifies the username that must be supplied when authenticating.
   Only used for the non Native protocols at the moment.

   }

The following is an example of a valid Client resource definition:

.. code-block:: sh
   :caption: Minimal client resource definition in bareos-dir.conf

   Client {
     Name = client1-fd
     Address = client1.example.com
     Password = "secret"
   }

The following is an example of a Quota Configuration in Client resource:

.. code-block:: sh
   :caption: Quota Configuration in Client resource

   Client {
     Name = client1-fd
     Address = client1.example.com
     Password = "secret"

     # Quota
     Soft Quota = 50 mb
     Soft Quota Grace Period = 2 days
     Strict Quotas = Yes
     Hard Quota = 150 mb
     Quota Include Failed Jobs = yes
   }

.. _DirectorResourceStorage:

Storage Resource
----------------

:index:`[TAG=Resource->Storage] <pair: Resource; Storage>` :index:`[TAG=Storage Resource] <single: Storage Resource>`

The Storage resource defines which Storage daemons are available for use by the Director.

\defDirective{Dir}{Storage}{Address}{}{}{%
   Where the address is a host name,  a {\bf fully qualified domain name}, or an
   {\bf IP address}. Please note  that the <address> as specified here
   will be transmitted to  the File daemon who will then use it to contact the
   Storage daemon. Hence,  it is {\bf not}, a good idea to use {\bf localhost} as
   the  name but rather a fully qualified machine name or an IP address.  This
   directive is required.
   }

\defDirective{Dir}{Storage}{Allow Compression}{}{}{%
   This directive is optional, and if you specify {\bf No},
   it will cause backups jobs running on this storage resource to run
   without client File Daemon compression.  This effectively overrides
   compression options in FileSets used by jobs which use this storage
   resource.
   \label{AllowCompression}
   }

\defDirective{Dir}{Storage}{Auth Type}{}{}{%
   Specifies the authentication type that must be supplied when connecting to
   a backup protocol that uses a specific authentication type.
   }

\defDirective{Dir}{Storage}{Auto Changer}{}{}{%
   When \linkResourceDirective{Dir}{Storage}{Device} refers to an Auto Changer (\linkResourceDirective{Sd}{Device}{Autochanger}),
   this directive must be set to \parameter{yes}.

   If you specify \parameter{yes},
   \begin{itemize}
     \item Volume management command like \bcommand{label}{} or \bcommand{add}{} will request a Autochanger Slot number.
     \item Bareos will prefer Volumes, that are in a Auto Changer slot.
       If none of theses volumes can be used, even after recycling, pruning, ...,
       Bareos will search for any volume of the same \linkResourceDirective{Dir}{Storage}{Media Type} whether or not in the magazine.
   \end{itemize}

   Please consult the \nameref{AutochangersChapter} chapter for details.
   }

\defDirective{Dir}{Storage}{Collect Statistics}{}{}{%
   Collect statistic information. These information will be collected by the Director (see \linkResourceDirective{Dir}{Director}{Statistics Collect Interval}) and stored in the Catalog.
   }

\defDirective{Dir}{Storage}{Description}{}{}{%
   Information.
   }

\defDirective{Dir}{Storage}{Device}{}{}{%

   If \linkResourceDirective{Dir}{Job}{Protocol} is not \parameter{NDMP_NATIVE} (default is \linkResourceDirectiveValue{Dir}{Job}{Protocol}{Native}), this directive refers to one or multiple \linkResourceDirective{Sd}{Device}{Name}
   or a single \linkResourceDirective{Sd}{Autochanger}{Name}.

   If an Autochanger should be used, it had to refer to a configured \linkResourceDirective{Sd}{Autochanger}{Name}.
   In this case, also set \linkResourceDirectiveValue{Dir}{Storage}{Auto Changer}{yes}.

   Otherwise it refers to one or more configured \linkResourceDirective{Sd}{Device}{Name}, see  \nameref{section-MultipleStorageDevices}.

   This name is not the physical device name, but the logical device name as
   defined in the \bareosSd resource.

   If \resourceDirectiveValue{Dir}{Job}{Protocol}{NDMP_NATIVE}, it refers to tape devices on the NDMP \TapeAgent, see \nameref{section-NdmpNative}.
   }

\defDirective{Dir}{Storage}{Enabled}{}{}{%
   }

\defDirective{Dir}{Storage}{Heartbeat Interval}{}{}{%
   This directive is optional and if specified will cause the Director to
   set a keepalive interval (heartbeat) in seconds on each of the sockets
   it opens for the Storage resource.  This value will override any
   specified at the Director level.  It is implemented only on systems
   (Linux, ...) that provide the {\bf setsockopt} TCP\_KEEPIDLE function.
   The default value is zero, which means no change is made to the socket.
   }

\defDirective{Dir}{Storage}{Lan Address}{}{}{%
   This directive might be useful in network setups where the \bareosDir and \bareosFd need different addresses to communicate with the \bareosSd.

   For details, see \nameref{LanAddress}.

   This directive corresponds to \linkResourceDirective{Dir}{Client}{Lan Address}.
   }

\defDirective{Dir}{Storage}{Maximum Bandwidth Per Job}{}{}{%
   }

\defDirective{Dir}{Storage}{Maximum Concurrent Jobs}{}{}{%
   This directive specifies the maximum number of Jobs with the current
   Storage resource that can run concurrently.  Note, this directive limits
   only Jobs for Jobs using this Storage daemon.  Any other restrictions on
   the maximum concurrent jobs such as in the Director, Job or Client
   resources will also apply in addition to any limit specified here.

   If you set the Storage daemon's number of concurrent jobs greater than one,
   we recommend that you read \nameref{ConcurrentJobs} and/or
   turn data spooling on as documented in \nameref{SpoolingChapter}.
   }

\defDirective{Dir}{Storage}{Maximum Concurrent Read Jobs}{}{}{%
   This directive specifies the maximum number of Jobs with the current
   Storage resource that can read concurrently.
   }

\defDirective{Dir}{Storage}{Media Type}{}{}{%
   This directive specifies the Media Type to be used to store the data.
   This is an arbitrary string of characters up to 127 maximum that you
   define.  It can be anything you want.  However, it is best to make it
   descriptive of the storage media (e.g.  File, DAT, "HP DLT8000", 8mm,
   ...).  In addition, it is essential that you make the {\bf Media Type}
   specification unique for each storage media type.  If you have two DDS-4
   drives that have incompatible formats, or if you have a DDS-4 drive and
   a DDS-4 autochanger, you almost certainly should specify different {\bf
   Media Types}.  During a restore, assuming a {\bf DDS-4} Media Type is
   associated with the Job, Bareos can decide to use any Storage daemon
   that supports Media Type {\bf DDS-4} and on any drive that supports it.

   If you are writing to disk Volumes, you must make doubly sure that each
   Device resource defined in the Storage daemon (and hence in the
   Director's conf file) has a unique media type.  Otherwise Bareos
   may assume, these Volumes can be mounted and read by any Storage daemon File device.

   Currently Bareos permits only a single Media Type per Storage
   Device definition. Consequently, if
   you have a drive that supports more than one Media Type, you can
   give a unique string to Volumes with different intrinsic Media
   Type (Media Type = DDS-3-4 for DDS-3 and DDS-4 types), but then
   those volumes will only be mounted on drives indicated with the
   dual type (DDS-3-4).

   If you want to tie Bareos to using a single Storage daemon or drive, you
   must specify a unique Media Type for that drive.  This is an important
   point that should be carefully understood.  Note, this applies equally
   to Disk Volumes.  If you define more than one disk Device resource in
   your Storage daemon's conf file, the Volumes on those two devices are in
   fact incompatible because one can not be mounted on the other device
   since they are found in different directories.  For this reason, you
   probably should use two different Media Types for your two disk Devices
   (even though you might think of them as both being File types).  You can
   find more on this subject in the \ilink{Basic Volume
   Management}{DiskChapter} chapter of this manual.

   The {\bf MediaType} specified in the Director's Storage resource, {\bf
   must} correspond to the {\bf Media Type} specified in the {\bf Device}
   resource of the {\bf Storage daemon} configuration file.  This directive
   is required, and it is used by the Director and the Storage daemon to
   ensure that a Volume automatically selected from the Pool corresponds to
   the physical device.  If a Storage daemon handles multiple devices (e.g.
   will write to various file Volumes on different partitions), this
   directive allows you to specify exactly which device.

   As mentioned above, the value specified in the Director's Storage
   resource must agree with the value specified in the Device resource in
   the {\bf Storage daemon's} configuration file.  It is also an additional
   check so that you don't try to write data for a DLT onto an 8mm device.
   \label{MediaType}
   }

\defDirective{Dir}{Storage}{Name}{}{}{%
   The name of the storage resource. This  name appears on the Storage directive
   specified in the Job resource and is required.
   }

\defDirective{Dir}{Storage}{Paired Storage}{}{}{%
   For NDMP backups this points to the definition of the Native Storage
   that is accesses via the NDMP protocol. For now we only support NDMP
   backups and restores to access Native Storage Daemons via the NDMP
   protocol. In the future we might allow to use Native NDMP storage which
   is not bound to a Bareos Storage Daemon.
   }

\defDirective{Dir}{Storage}{Password}{}{}{%
   This is the password to be used  when establishing a connection with the
   Storage services. This  same password also must appear in the Director
   resource of the Storage  daemon's configuration file. This directive is
   required.

   The password is plain text.
   }

\defDirective{Dir}{Storage}{Port}{}{}{%
   Where port is the port to use to  contact the storage daemon for information
   and to start jobs.  This same port number must appear in the Storage resource
   of the  Storage daemon's configuration file.
   }

\defDirective{Dir}{Storage}{Protocol}{}{}{%
   }

\defDirective{Dir}{Storage}{SD Address}{}{}{%
   }

\defDirective{Dir}{Storage}{SD Password}{}{}{%
   }

\defDirective{Dir}{Storage}{SD Port}{}{}{%
   }

\defDirective{Dir}{Storage}{Sdd Port}{}{}{%
   }

\defDirective{Dir}{Storage}{TLS Authenticate}{}{}{%
   }

\defDirective{Dir}{Storage}{TLS CA Certificate File}{}{}{%
   }

\defDirective{Dir}{Storage}{TLS CA Certificate Dir}{}{}{%
   }

\defDirective{Dir}{Storage}{TLS Certificate}{}{}{%
   }

\defDirective{Dir}{Storage}{TLS Certificate Revocation List}{}{}{%
   }

\defDirective{Dir}{Storage}{TLS Enable}{}{}{%
   Bareos can be configured to encrypt all its network traffic.
   For details, refer to chapter \nameref{TlsDirectives}.
   }

\defDirective{Dir}{Storage}{TLS Key}{}{}{%
   }

\defDirective{Dir}{Storage}{TLS Require}{}{}{%
   }

\defDirective{Dir}{Storage}{Username}{}{}{%
   }

The following is an example of a valid Storage resource definition:

.. code-block:: sh
   :caption: Storage resource (tape) example

   Storage {
     Name = DLTDrive
     Address = lpmatou
     Password = storage\_password # password for Storage daemon
     Device = "HP DLT 80"    # same as Device in Storage daemon
     Media Type = DLT8000    # same as MediaType in Storage daemon
   }

.. _DirectorResourcePool:

Pool Resource
-------------

:index:`[TAG=Resource->Pool] <pair: Resource; Pool>` :index:`[TAG=Pool Resource] <single: Pool Resource>`

The Pool resource defines the set of storage Volumes (tapes or files) to be used by Bareos to write the data. By configuring different Pools, you can determine which set of Volumes (media) receives the backup data. This permits, for example, to store all full backup data on one set of Volumes and all incremental backups on another set of Volumes. Alternatively, you could assign a different set of Volumes to each machine that you backup. This is most easily done by defining multiple Pools.

Another important aspect of a Pool is that it contains the default attributes (Maximum Jobs, Retention Period, Recycle flag, ...) that will be given to a Volume when it is created. This avoids the need for you to answer a large number of questions when labeling a new Volume. Each of these attributes can later be changed on a Volume by Volume basis using the :strong:`update` command in the console program. Note that you must explicitly specify which Pool Bareos is to use with each
Job. Bareos will not automatically search for the correct Pool.

To use a Pool, there are three distinct steps. First the Pool must be defined in the Director’s configuration. Then the Pool must be written to the Catalog database. This is done automatically by the Director each time that it starts. Finally, if you change the Pool definition in the Director’s configuration file and restart Bareos, the pool will be updated alternatively you can use the :strong:`update pool` console command to refresh the database image. It is this database image
rather than the Director’s resource image that is used for the default Volume attributes. Note, for the pool to be automatically created or updated, it must be explicitly referenced by a Job resource.

If automatic labeling is not enabled (see :ref:`AutomaticLabeling`) the physical media must be manually labeled. The labeling can either be done with the :strong:`label` command in the console program or using the :command:`btape` program. The preferred method is to use the :strong:`label` command in the console program. Generally, automatic labeling is enabled for **Device Type**:sup:`Sd`:sub:`Device`\ = **File**
and disabled for **Device Type**:sup:`Sd`:sub:`Device`\ = **Tape**.

Finally, you must add Volume names (and their attributes) to the Pool. For Volumes to be used by Bareos they must be of the same **Media Type**:sup:`Sd`:sub:`Device`\  as the archive device specified for the job (i.e. if you are going to back up to a DLT device, the Pool must have DLT volumes defined since 8mm volumes cannot be mounted on a DLT drive). The **Media Type**:sup:`Sd`:sub:`Device`\  has particular importance if you are backing up to files.
When running a Job, you must explicitly specify which Pool to use. Bareos will then automatically select the next Volume to use from the Pool, but it will ensure that the **Media Type**:sup:`Sd`:sub:`Device`\  of any Volume selected from the Pool is identical to that required by the Storage resource you have specified for the Job.

If you use the :strong:`label` command in the console program to label the Volumes, they will automatically be added to the Pool, so this last step is not normally required.

It is also possible to add Volumes to the database without explicitly labeling the physical volume. This is done with the :strong:`add` console command.

As previously mentioned, each time Bareos starts, it scans all the Pools associated with each Catalog, and if the database record does not already exist, it will be created from the Pool Resource definition. If you change the Pool definition, you manually have to call :strong:`update pool` command in the console program to propagate the changes to existing volumes.

The Pool Resource defined in the Director’s configuration may contain the following directives:

\defDirective{Dir}{Pool}{Action On Purge}{}{}{%
   % DEPRECATED:
   % because it does not do what is expected by the name.
   % Is only has an influence,
   % when using the command "purge volume action=truncate"
   % but did do nothing automatically.

   The directive \configline{Action On Purge=Truncate} instructs Bareos to truncate the
   volume when it is purged with the \bcommand{purge}{volume action=truncate}
   command. It is useful to prevent disk based volumes from consuming too much
   space.

   % \bconfigInput{config/DirPoolActionOnPurge1.conf}
   %
   % THIS DOES NOT WORK:
   % You can schedule the truncate operation at the end of your \job{BackupCatalog} job
   % like in this example:
   % 
   % \bconfigInput{config/DirPoolActionOnPurge2.conf}
   }

\defDirective{Dir}{Pool}{Auto Prune}{}{}{%
   If \configline{Auto Prune=yes}, the \linkResourceDirective{Dir}{Pool}{Volume Retention} period
   is automatically applied when a new
   Volume is needed and no appendable Volumes exist in the Pool.  Volume
   pruning causes expired Jobs (older than the \linkResourceDirective{Dir}{Pool}{Volume Retention}
   period) to be deleted from the Catalog and permits possible recycling of
   the Volume.
   }

\defDirective{Dir}{Pool}{Catalog}{}{}{%
   This specifies the name of the catalog resource to be used for this Pool.
   When a catalog is defined in a Pool it will override the definition in
   the client (and the Catalog definition in a Job since
   \sinceVersion{dir}{Job catalog overwritten by Pool catalog}{13.4.0}). e.g.
   this catalog setting takes precedence over any other definition.
   }

\defDirective{Dir}{Pool}{Catalog Files}{}{}{%
   This directive defines whether or not you want the names of the files
   that were saved to be put into the catalog.
   If disabled, the Catalog database will be significantly smaller.
   The disadvantage is that
   you will not be able to produce a Catalog listing of the files backed up
   for each Job (this is often called Browsing).  Also, without the File
   entries in the catalog, you will not be able to use the Console \bcommand{restore}{} command
   nor any other command that references File entries.
   }

\defDirective{Dir}{Pool}{Cleaning Prefix}{}{}{%
   This directive defines a prefix string, which if it matches the
   beginning of a Volume name during labeling of a Volume, the Volume will
   be defined with the VolStatus set to {\bf Cleaning} and thus Bareos will
   never attempt to use this tape.  This is primarily for use with
   autochangers that accept barcodes where the convention is that barcodes
   beginning with {\bf CLN} are treated as cleaning tapes.

   The default value for this directive is consequently set to {\bf CLN}, so
   that in most cases the cleaning tapes are automatically recognized without
   configuration.
   If you use another prefix for your cleaning tapes, you can set this directive
   accordingly.
   }

\defDirective{Dir}{Pool}{Description}{}{}{%
   }

\defDirective{Dir}{Pool}{File Retention}{}{}{%
   The File Retention directive defines the length of time that  Bareos will
   keep File records in the Catalog database after the End time of the
   Job corresponding to the File records.

   This directive takes precedence over Client directives of the same name. For
   example, you can decide to increase Retention times for Archive or OffSite
   Pool.

   Note, this affects only records in the catalog database. It does not affect
   your archive backups.

   For more information see Client documentation about
   \linkResourceDirective{Dir}{Client}{File Retention}
   }

\defDirective{Dir}{Pool}{Job Retention}{}{}{%
   The Job Retention directive defines the length of time that Bareos will keep
   Job records in the Catalog database after the Job End time.  As with the
   other retention periods, this affects only records in the catalog and not
   data in your archive backup.

   This directive takes precedence over Client directives of the same name.
   For example, you can decide to increase Retention times for Archive or
   OffSite Pool.

   For more information see Client side documentation
   \linkResourceDirective{Dir}{Client}{Job Retention}
   }

\defDirective{Dir}{Pool}{Label Format}{}{}{%
   This directive specifies the format of the labels contained in this
   pool.  The format directive is used as a sort of template to create new
   Volume names during automatic Volume labeling.

   The format should be specified in double quotes (\verb|path:"|), and consists of
   letters, numbers and the special characters hyphen (\verb|path:-|), underscore
   (\verb|path:_|), colon (\verb|path::|), and period (\verb|path:.|), which are the legal
   characters for a Volume name.

   In addition, the format may contain a number of variable expansion
   characters which will be expanded by a complex algorithm allowing you to
   create Volume names of many different formats.  In all cases, the
   expansion process must resolve to the set of characters noted above that
   are legal Volume names.  Generally, these variable expansion characters
   begin with a dollar sign (\verb|path:$|)
   or a left bracket (\verb|path:[|).
   For more details on
   variable expansion, please see \nameref{section-VariableExpansionVolumeLabels}.

   If no variable expansion characters are found in the string, the Volume
   name will be formed from the format string appended with the
   a unique number that increases.  If you do not remove volumes from the
   pool, this number should be the number of volumes plus one, but this
   is not guaranteed. The unique number will be edited as four
   digits with leading zeros.  For example, with a 
   \configdirective{Label Format = "File-"},
   the first volumes will be named \volume{File-0001}, \volume{File-0002}, ...

   In almost all cases, you should enclose the format specification (part
   after the equal sign) in double quotes (\verb|path:"|).
   }

\defDirective{Dir}{Pool}{Label Type}{ANSI|IBM|Bareos}{}{%
   This directive is implemented in the
   Director Pool resource and in the SD Device
   resource (\linkResourceDirective{Sd}{Device}{Label Type}).
   If it is specified in the SD Device resource, it will take
   precedence over the value passed from the Director to the SD.
   }

\defDirective{Dir}{Pool}{Maximum Block Size}{}{14.2.0}{%
   The \configdirective{Maximum Block Size} can be defined here to define different block sizes per volume
   or statically for all volumes at \linkResourceDirective{Sd}{Device}{Maximum Block Size}.
   If not defined, its default is 63 KB.
   Increasing this value could improve the throughput of writing to tapes.

   \warning{However make sure to read the \ilink{Setting Block Sizes}{setblocksizes} chapter carefully before applying any changes.}
   }

\defDirective{Dir}{Pool}{Maximum Volume Bytes}{}{}{%
   This directive specifies the maximum number of bytes that can be written
   to the Volume.  If you specify zero (the default), there is no limit
   except the physical size of the Volume.  Otherwise, when the number of
   bytes written to the Volume equals {\bf size} the Volume will be marked
   {\bf Used}.  When the Volume is marked {\bf Used} it can no longer be
   used for appending Jobs, much like the {\bf Full} status but it can be
   recycled if recycling is enabled, and thus the Volume can be re-used
   after recycling.  This value is checked and the {\bf Used} status set
   while the job is writing to the particular volume.

   This directive is particularly useful for restricting the size
   of disk volumes, and will work correctly even in the case of
   multiple simultaneous jobs writing to the volume.

   The value defined by this directive in the bareos-dir.conf file is the
   default value used when a Volume is created.  Once the volume is
   created, changing the value in the bareos-dir.conf file will not change
   what is stored for the Volume.  To change the value for an existing
   Volume you must use the {\bf update} command in the Console.
   }

\defDirective{Dir}{Pool}{Maximum Volume Files}{}{}{%
   This directive specifies the maximum number of files that can be written
   to the Volume.  If you specify zero (the default), there is no limit.
   Otherwise, when the number of files written to the Volume equals {\bf
   positive-integer} the Volume will be marked {\bf Used}.  When the Volume
   is marked {\bf Used} it can no longer be used for appending Jobs, much
   like the {\bf Full} status but it can be recycled if recycling is
   enabled and thus used again.  This value is checked and the {\bf Used}
   status is set only at the end of a job that writes to the particular
   volume.

   The value defined by this directive in the bareos-dir.conf file is the
   default value used when a Volume is created.  Once the volume is
   created, changing the value in the bareos-dir.conf file will not change
   what is stored for the Volume.  To change the value for an existing
   Volume you must use the {\bf update} command in the Console.
   }

\defDirective{Dir}{Pool}{Maximum Volume Jobs}{}{}{%
   This directive specifies the maximum number of Jobs that can be written
   to the Volume.  If you specify zero (the default), there is no limit.
   Otherwise, when the number of Jobs backed up to the Volume equals {\bf
   positive-integer} the Volume will be marked {\bf Used}.  When the Volume
   is marked {\bf Used} it can no longer be used for appending Jobs, much
   like the {\bf Full} status but it can be recycled if recycling is
   enabled, and thus used again.  By setting {\bf MaximumVolumeJobs} to
   one, you get the same effect as setting {\bf UseVolumeOnce = yes}.

   The value defined by this directive in the  bareos-dir.conf
   file is the default value used when a Volume  is created. Once the volume is
   created, changing the value  in the bareos-dir.conf file will not change what
   is stored  for the Volume. To change the value for an existing Volume  you
   must use the {\bf update} command in the Console.

   If you are running multiple simultaneous jobs, this directive may not
   work correctly because when a drive is reserved for a job, this
   directive is not taken into account, so multiple jobs may try to
   start writing to the Volume. At some point, when the Media record is
   updated, multiple simultaneous jobs may fail since the Volume can no
   longer be written.
   }

\defDirective{Dir}{Pool}{Maximum Volumes}{}{}{%
   This directive specifies the maximum number of volumes (tapes or files)
   contained in the pool.  This directive is optional, if omitted or set to
   zero, any number of volumes will be permitted.  In general, this
   directive is useful for Autochangers where there is a fixed number of
   Volumes, or for File storage where you wish to ensure that the backups
   made to disk files do not become too numerous or consume too much space.
   }

\defDirective{Dir}{Pool}{Migration High Bytes}{}{}{%
   This directive specifies the number of bytes in the Pool which will
      trigger a migration if \linkResourceDirective{Dir}{Job}{Selection Type} = PoolOccupancy
      has been specified. The fact that the Pool
      usage goes above this level does not automatically trigger a migration
      job. However, if a migration job runs and has the PoolOccupancy selection
      type set, the Migration High Bytes will be applied.  Bareos does not
      currently restrict a pool to have only a single \linkResourceDirective{Dir}{Storage}{Media Type}, so you
      must keep in mind that if you mix Media Types in a Pool, the results
      may not be what you want, as the Pool count of all bytes will be
      for all Media Types combined.
   }

\defDirective{Dir}{Pool}{Migration Low Bytes}{}{}{%
   This directive specifies the number of bytes in the Pool which will
      stop a migration if \linkResourceDirective{Dir}{Job}{Selection Type} = PoolOccupancy
      has been specified and triggered by more than 
      \linkResourceDirective{Dir}{Pool}{Migration High Bytes}
      being in the pool. In other words, once a migration job
      is started with {\bf PoolOccupancy} migration selection and it
      determines that there are more than Migration High Bytes, the
      migration job will continue to run jobs until the number of
      bytes in the Pool drop to or below Migration Low Bytes.
   }

\defDirective{Dir}{Pool}{Migration Time}{}{}{%
   If \linkResourceDirective{Dir}{Job}{Selection Type} = PoolTime, 
   the time specified here will be used. 
   If the previous Backup Job or Jobs selected have been in the Pool longer than
   the specified time, then they will be migrated.
   }

\defDirective{Dir}{Pool}{Minimum Block Size}{}{}{%
   The \configdirective{Minimum Block Size} can be defined here to define different block sizes per volume
   or statically for all volumes at \linkResourceDirective{Sd}{Device}{Minimum Block Size}.
   For details, see chapter \ilink{Setting Block Sizes}{setblocksizes}.
   }

\defDirective{Dir}{Pool}{Name}{}{}{%
   The name of the pool.
   }

\defDirective{Dir}{Pool}{Next Pool}{}{}{%
   This directive specifies the pool a Migration or Copy Job
   and a Virtual Backup Job will write their data too.
   This directive is required to define the Pool into which
      the data will be migrated. Without this directive, the migration job
      will terminate in error.
   }

\defDirective{Dir}{Pool}{Pool Type}{}{}{%
   This directive defines the pool type, which corresponds to the type of
   Job being run.  It is required and may be one of the following:

   \begin{description}
     \item [Backup]
     \item [*Archive]
     \item [*Cloned]
     \item [*Migration]
     \item [*Copy]
     \item [*Save]
   \end{description}
   Note, only Backup is currently implemented.
   }

\defDirective{Dir}{Pool}{Purge Oldest Volume}{}{}{%
   This directive instructs the Director to search for the oldest used
   Volume in the Pool when another Volume is requested by the Storage
   daemon and none are available.  The catalog is then {\bf purged}
   irrespective of retention periods of all Files and Jobs written to this
   Volume.  The Volume is then recycled and will be used as the next Volume
   to be written.  This directive overrides any Job, File, or Volume
   retention periods that you may have specified.

   This directive can be useful if you have a fixed number of Volumes in
   the Pool and you want to cycle through them and reusing the oldest one
   when all Volumes are full, but you don't want to worry about setting
   proper retention periods.  However, by using this option you risk losing
   valuable data.

   In most cases, you should use \linkResourceDirective{Dir}{Pool}{Recycle Oldest Volume} instead.

   \warning{
   Be aware that \configdirective{Purge Oldest Volume} disregards all retention
   periods. If you have only a single Volume defined and you turn this
   variable on, that Volume will always be immediately overwritten when it
   fills!  So at a minimum, ensure that you have a decent number of Volumes
   in your Pool before running any jobs.  If you want retention periods to
   apply do not use this directive.\\
   We \textbf{highly} recommend against using this directive, because it is
   sure that some day, Bareos will purge a Volume that contains current
   data.
   }
   }

\defDirective{Dir}{Pool}{Recycle}{}{}{%
   This directive specifies whether or not Purged Volumes may be recycled.
   If it is set to \argument{yes} and Bareos needs a volume but finds
   none that are appendable, it will search for and recycle (reuse) Purged
   Volumes (i.e.  volumes with all the Jobs and Files expired and thus
   deleted from the Catalog).  If the Volume is recycled, all previous data
   written to that Volume will be overwritten. If Recycle is set to \argument{no},
   the Volume will not be recycled, and hence, the data will remain
   valid.  If you want to reuse (re-write) the Volume, and the recycle flag
   is no (0 in the catalog), you may manually set the recycle flag (update
   command) for a Volume to be reused.

   Please note that the value defined by this directive in the
   configuration file is the default value used when a Volume is created.
   Once the volume is created, changing the value in the configuration
   file will not change what is stored for the Volume.  To change the value
   for an existing Volume you must use the \bcommand{update}{volume} command.

   When all Job and File records have been pruned or purged from the
   catalog for a particular Volume, if that Volume is marked as
   Append, Full, Used, or Error, it will then be marked as Purged. Only
   Volumes marked as Purged will be considered to be converted to the
   Recycled state if the \configdirective{Recycle} directive is set to \argument{yes}.
   }

\defDirective{Dir}{Pool}{Recycle Current Volume}{}{}{%
   If Bareos needs a new Volume, this directive instructs Bareos to Prune
   the volume respecting the Job and File retention periods.  If all Jobs
   are pruned (i.e.  the volume is Purged), then the Volume is recycled and
   will be used as the next Volume to be written.  This directive respects
   any Job, File, or Volume retention periods that you may have specified.

   This directive can be useful if you have: a fixed number of Volumes in
   the Pool, you want to cycle through them, and you have specified
   retention periods that prune Volumes before you have cycled through the
   Volume in the Pool.

   However, if you use this directive and have only one Volume in the Pool,
   you will immediately recycle your Volume if you fill it and Bareos needs
   another one.  Thus your backup will be totally invalid.  Please use this
   directive with care.
   }

\defDirective{Dir}{Pool}{Recycle Oldest Volume}{}{}{%
   This directive instructs the Director to search for the oldest used
   Volume in the Pool when another Volume is requested by the Storage
   daemon and none are available.  The catalog is then {\bf pruned}
   respecting the retention periods of all Files and Jobs written to this
   Volume.  If all Jobs are pruned (i.e. the volume is Purged), then the
   Volume is recycled and will be used as the next Volume to be written.
   This directive respects any Job, File, or Volume retention periods that
   you may have specified.

   This directive can be useful if you have a fixed number of Volumes in the
   Pool and you want to cycle through them and you have specified the correct
   retention periods.

   However, if you use this directive and have only one
   Volume in the Pool, you will immediately recycle your Volume if you fill
   it and Bareos needs another one. Thus your backup will be totally invalid.
   Please use this directive with care.
   }

\defDirective{Dir}{Pool}{Recycle Pool}{}{}{%
   This directive defines to which pool
   the Volume will be placed (moved) when it is recycled. Without
   this directive, a Volume will remain in the same pool when it is
   recycled. With this directive, it can be moved automatically to any
   existing pool during a recycle. This directive is probably most
   useful when defined in the Scratch pool, so that volumes will
   be recycled back into the Scratch pool. For more on the see the
   \ilink{Scratch Pool}{TheScratchPool} section of this manual.

   Although this directive is called RecyclePool, the Volume in
   question is actually moved from its current pool to the one
   you specify on this directive when Bareos prunes the Volume and
   discovers that there are no records left in the catalog and hence
   marks it as {\bf Purged}.
   }

\defDirective{Dir}{Pool}{Scratch Pool}{}{}{%
   This directive permits to specify a dedicate \textsl{Scratch} for the
   current pool. This pool will replace the special pool named \textsl{Scrach}
   for volume selection. For more information about \textsl{Scratch} see
   \ilink{Scratch Pool}{TheScratchPool} section of this manual. This is useful
   when using multiple storage sharing the same mediatype or when you want to
   dedicate volumes to a particular set of pool.
   }

\defDirective{Dir}{Pool}{Storage}{}{}{%
   The Storage directive defines the name of the storage services where you
   want to backup the FileSet data.  For additional details, see the
   \nameref{DirectorResourceStorage} of this manual.
   The Storage resource may also be specified in the Job resource,
   but the value, if any, in the Pool resource overrides any value
   in the Job. This Storage resource definition is not required by either
   the Job resource or in the Pool, but it must be specified in
   one or the other.  If not configuration error will result.
     We highly recommend
      that you define the Storage resource to be used in the Pool rather
      than elsewhere (job, schedule run, ...). Be aware that you theoretically can
   give a list of storages here but only the first item from the list is actually
   used for backup and restore jobs.
   }

\defDirective{Dir}{Pool}{Use Catalog}{}{}{%
   Store information into Catalog. In all pratical use cases, leave this value to its defaults.

   }

\defDirective{Dir}{Pool}{Use Volume Once}{}{}{%
   Use \linkResourceDirective{Dir}{Pool}{Maximum Volume Jobs} = 1 instead.
   }

\defDirective{Dir}{Pool}{Volume Retention}{}{}{%
   The Volume Retention directive defines the length of time that
   Bareos will keep records associated with the Volume in
   the Catalog database after the End time of each Job written to the
   Volume.  When this time period expires, and if {\bf AutoPrune} is set to
   {\bf yes} Bareos may prune (remove) Job records that are older than the
   specified Volume Retention period if it is necessary to free up a
   Volume.  Recycling will not occur until it is absolutely necessary to
   free up a volume (i.e. no other writable volume exists).
   All File records associated with pruned Jobs are also
   pruned.  The time may be specified as seconds, minutes, hours, days,
   weeks, months, quarters, or years.  The {\bf Volume Retention} is
   applied independently of the {\bf Job Retention} and the {\bf File
   Retention} periods defined in the Client resource.  This means that all
   the retentions periods are applied in turn and that the shorter period
   is the one that effectively takes precedence.  Note, that when the {\bf
   Volume Retention} period has been reached, and it is necessary to obtain
   a new volume, Bareos will prune both the Job and the File records.  This
   pruning could also occur during a {\bf status dir} command because it
   uses similar algorithms for finding the next available Volume.

   It is important to know that when the Volume Retention period expires,
   Bareos does not automatically recycle a Volume. It attempts to keep the
   Volume data intact as long as possible before over writing the Volume.

   By defining multiple Pools with different Volume Retention periods, you
   may effectively have a set of tapes that is recycled weekly, another
   Pool of tapes that is recycled monthly and so on.  However, one must
   keep in mind that if your {\bf Volume Retention} period is too short, it
   may prune the last valid Full backup, and hence until the next Full
   backup is done, you will not have a complete backup of your system, and
   in addition, the next Incremental or Differential backup will be
   promoted to a Full backup.  As a consequence, the minimum {\bf Volume
   Retention} period should be at twice the interval of your Full backups.
   This means that if you do a Full backup once a month, the minimum Volume
   retention period should be two months.

   The default Volume retention period is 365 days, and either the default
   or the value defined by this directive in the bareos-dir.conf file is
   the default value used when a Volume is created.  Once the volume is
   created, changing the value in the \file{bareos-dir.conf} file will not change
   what is stored for the Volume.  To change the value for an existing
   Volume you must use the {\bf update} command in the Console.
   }

\defDirective{Dir}{Pool}{Volume Use Duration}{}{}{%
   The Volume Use Duration directive defines the time period that the
   Volume can be written beginning from the time of first data write to the
   Volume.  If the time-period specified is zero (the default), the Volume
   can be written indefinitely.  Otherwise, the next time a job
   runs that wants to access this Volume, and the time period from the
   first write to the volume (the first Job written) exceeds the
   time-period-specification, the Volume will be marked {\bf Used}, which
   means that no more Jobs can be appended to the Volume, but it may be
   recycled if recycling is enabled.
   % Using the command {\bf
   % status dir} applies algorithms similar to running jobs, so
   % during such a command, the Volume status may also be changed.
   Once the Volume is
   recycled, it will be available for use again.

   You might use this directive, for example, if you have a Volume used for
   Incremental backups, and Volumes used for Weekly Full backups.  Once the
   Full backup is done, you will want to use a different Incremental
   Volume.  This can be accomplished by setting the Volume Use Duration for
   the Incremental Volume to six days.  I.e.  it will be used for the 6
   days following a Full save, then a different Incremental volume will be
   used.  Be careful about setting the duration to short periods such as 23
   hours, or you might experience problems of Bareos waiting for a tape
   over the weekend only to complete the backups Monday morning when an
   operator mounts a new tape.

   % The use duration is checked and the {\bf Used} status is set only at the
   % end of a job that writes to the particular volume, which means that even
   % though the use duration may have expired, the catalog entry will not be
   % updated until the next job that uses this volume is run. This
   % directive is not intended to be used to limit volume sizes
   % and will not work correctly (i.e. will fail jobs) if the use
   % duration expires while multiple simultaneous jobs are writing
   % to the volume.

   Please note that the value defined by this directive in the  bareos-dir.conf
   file is the default value used when a Volume  is created. Once the volume is
   created, changing the value  in the bareos-dir.conf file will not change what
   is stored  for the Volume. To change the value for an existing Volume  you
   must use the
   \ilink{\bf update volume}{UpdateCommand} command in the Console.
   }

The following is an example of a valid Pool resource definition:

.. code-block:: sh
   :caption: Pool resource example

   Pool {
     Name = Default
     Pool Type = Backup
   }

.. _TheScratchPool:

Scratch Pool
~~~~~~~~~~~~

:index:`[TAG=Scratch Pool] <single: Scratch Pool>` :index:`[TAG=Pool->Scratch] <pair: Pool; Scratch>`

In general, you can give your Pools any name you wish, but there is one important restriction: the Pool named Scratch, if it exists behaves like a scratch pool of Volumes in that when Bareos needs a new Volume for writing and it cannot find one, it will look in the Scratch pool, and if it finds an available Volume, it will move it out of the Scratch pool into the Pool currently being used by the job.

.. _DirectorResourceCatalog:

Catalog Resource
----------------

:index:`[TAG=Resource->Catalog] <pair: Resource; Catalog>` :index:`[TAG=Catalog Resource] <single: Catalog Resource>`

The Catalog Resource defines what catalog to use for the current job. Currently, Bareos can only handle a single database server (SQLite, MySQL, PostgreSQL) that is defined when configuring Bareos. However, there may be as many Catalogs (databases) defined as you wish. For example, you may want each Client to have its own Catalog database, or you may want backup jobs to use one database and verify or restore jobs to use another database.

Since SQLite is compiled in, it always runs on the same machine as the Director and the database must be directly accessible (mounted) from the Director. However, since both MySQL and PostgreSQL are networked databases, they may reside either on the same machine as the Director or on a different machine on the network. See below for more details.

\defDirective{Dir}{Catalog}{Address}{}{}{%
   Alias for \linkResourceDirective{Dir}{Catalog}{DB Address}.
   }

\defDirective{Dir}{Catalog}{DB Address}{}{}{%
   This is the host address  of the database server. Normally, you would specify
   this instead  of \linkResourceDirective{Dir}{Catalog}{DB Socket} if the database server is on another machine.
   In that case, you will also specify \linkResourceDirective{Dir}{Catalog}{DB Port}. 
   This directive  is used
   only by MySQL and PostgreSQL and is ignored by SQLite if provided.
   }

\defDirective{Dir}{Catalog}{DB Driver}{postgresql | mysql | sqlite}{}{%
   Selects the database type to use.
   }

\defDirective{Dir}{Catalog}{DB Name}{}{}{%
   This specifies the name of the database.
   }

\defDirective{Dir}{Catalog}{DB Password}{}{}{%
   This specifies the password to use when login into the database.
   }

\defDirective{Dir}{Catalog}{DB Port}{}{}{%
   This defines the port to  be used in conjunction with \linkResourceDirective{Dir}{Catalog}{DB Address} to
   access the  database if it is on another machine. This directive is used  only
   by MySQL and PostgreSQL and is ignored by SQLite if provided.
   }

\defDirective{Dir}{Catalog}{DB Socket}{}{}{%
   This is the name of  a socket to use on the local host to connect to the
   database. This directive is used only by MySQL and is ignored by  SQLite.
   Normally, if neither \linkResourceDirective{Dir}{Catalog}{DB Socket} 
   or \linkResourceDirective{Dir}{Catalog}{DB Address}  are specified, MySQL
   will use the default socket. If the DB Socket is specified, the
   MySQL server must reside on the same machine as the Director.
   }

\defDirective{Dir}{Catalog}{DB User}{}{}{%
   This specifies what user name to use to log into the database.
   }

\defDirective{Dir}{Catalog}{Description}{}{}{%
   }

\defDirective{Dir}{Catalog}{Disable Batch Insert}{}{}{%
   This directive allows you to override at runtime if the Batch insert should
   be enabled or disabled. Normally this is determined by querying the database
   library if it is thread-safe. If you think that disabling Batch insert will make
   your backup run faster you may disable it using this option and set it to 
   \parameter{Yes}.
   }

\defDirective{Dir}{Catalog}{Idle Timeout}{}{}{%
   This directive is used by the experimental database pooling functionality. Only use
   this for non production sites. This sets the idle time after which a database pool
   should be shrinked.
   }

\defDirective{Dir}{Catalog}{Inc Connections}{}{}{%
   This directive is used by the experimental database pooling functionality. Only use
   this for non production sites. This sets the number of connections to add to a
   database pool when not enough connections are available on the pool anymore.
   }

\defDirective{Dir}{Catalog}{Max Connections}{}{}{%
   This directive is used by the experimental database pooling functionality. Only use
   this for non production sites. This sets the maximum number of connections to a
   database to keep in this database pool.
   }

\defDirective{Dir}{Catalog}{Min Connections}{}{}{%
   This directive is used by the experimental database pooling functionality. Only use
   this for non production sites. This sets the minimum number of connections to a
   database to keep in this database pool.
   }

\defDirective{Dir}{Catalog}{Multiple Connections}{}{}{%
   %% By default, this  directive is set to no. In that case, each job that uses the
   %% same Catalog will use a single connection to the catalog. It will  be shared,
   %% and Bareos will allow only one Job at a time to  communicate. If you set this
   %% directive to yes, Bareos will  permit multiple connections to the database,
   %% and the database  must be multi-thread capable. For SQLite and PostgreSQL,
   %% this is  no problem. For MySQL, you must be *very* careful to have the
   %% multi-thread version of the client library loaded on your system.  When this
   %% directive is set yes, each Job will have a separate  connection to the
   %% database, and the database will control the  interaction between the different
   %% Jobs. This can significantly  speed up the database operations if you are
   %% running multiple  simultaneous jobs. In addition, for SQLite and PostgreSQL,
   %% Bareos  will automatically enable transactions. This can significantly  speed
   %% up insertion of attributes in the database either for  a single Job or
   %% multiple simultaneous Jobs.
   %%
   %% This directive has not been tested. Please test carefully  before running it
   %% in production and report back your results.
   Not yet implemented.
   }

\defDirective{Dir}{Catalog}{Name}{}{}{%
   The name of the Catalog.  No necessary relation to the database server
   name.  This name will be specified in the Client resource directive
   indicating that all catalog data for that Client is maintained in this
   Catalog.
   }

\defDirective{Dir}{Catalog}{Password}{}{}{%
   Alias for \linkResourceDirective{Dir}{Catalog}{DB Password}.
   }

\defDirective{Dir}{Catalog}{User}{}{}{%
   Alias for \linkResourceDirective{Dir}{Catalog}{DB User}.
   }

\defDirective{Dir}{Catalog}{Validate Timeout}{}{}{%
   This directive is used by the experimental database pooling functionality. Only use
   this for non production sites. This sets the validation timeout after which the
   database connection is polled to see if its still alive.
   }

The following is an example of a valid Catalog resource definition:

.. code-block:: sh
   :caption: Catalog Resource for Sqlite

   Catalog
   {
     Name = SQLite
     DB Driver = sqlite
     DB Name = bareos;
     DB User = bareos;
     DB Password = ""
   }

or for a Catalog on another machine:

.. code-block:: sh
   :caption: Catalog Resource for remote MySQL

   Catalog
   {
     Name = MySQL
     DB Driver = mysql
     DB Name = bareos
     DB User = bareos
     DB Password = "secret"
     DB Address = remote.example.com
     DB Port = 1234
   }

.. _DirectorResourceMessages:

Messages Resource
-----------------

:index:`[TAG=Resource->Messages] <pair: Resource; Messages>` :index:`[TAG=Messages Resource] <single: Messages Resource>`

For the details of the Messages Resource, please see the :ref:`MessagesChapter` of this manual.

.. _DirectorResourceConsole:

Console Resource
----------------

:index:`[TAG=Console Resource] <single: Console Resource>` :index:`[TAG=Resource->Console] <pair: Resource; Console>`

There are three different kinds of consoles, which the administrator or user can use to interact with the Director. These three kinds of consoles comprise three different security levels.

Default Console
   :index:`[TAG=Console->Default Console] <pair: Console; Default Console>` the first console type is an :emphasis:`anonymous` or :emphasis:`default` console, which has full privileges. There is no console resource necessary for this type since the password is specified in the Director’s resource and consequently such consoles do not have a name as defined on a :strong:`Name` directive. Typically you would use it only for administrators.

Named Console
   :index:`[TAG=Named Console] <single: Named Console>` :index:`[TAG=Console->Named Console] <pair: Console; Named Console>` :index:`[TAG=Console->Restricted Console] <pair: Console; Restricted Console>` the second type of console, is a :emphasis:`named` console (also called :emphasis:`Restricted Console`) defined within a Console resource in both the Director’s configuration file and in the Console’s configuration file. Both the names and the passwords in these two entries must match much as is the case for Client programs.

   This second type of console begins with absolutely no privileges except those explicitly specified in the Director’s Console resource. Thus you can have multiple Consoles with different names and passwords, sort of like multiple users, each with different privileges. As a default, these consoles can do absolutely nothing – no commands whatsoever. You give them privileges or rather access to commands and resources by specifying access control lists in the Director’s Console resource. The ACLs
   are specified by a directive followed by a list of access names. Examples of this are shown below.

   -  The third type of console is similar to the above mentioned one in that it requires a Console resource definition in both the Director and the Console. In addition, if the console name, provided on the **Name**:sup:`Dir`:sub:`Console`\  directive, is the same as a Client name, that console is permitted to use the :strong:`SetIP` command to change the Address directive in the Director’s client resource to the IP address of the Console. This permits
      portables or other machines using DHCP (non-fixed IP addresses) to "notify" the Director of their current IP address.

The Console resource is optional and need not be specified. The following directives are permitted within these resources:

\defDirective{Dir}{Console}{Catalog ACL}{}{}{%
   This directive is used to specify a list of Catalog resource names that
   can be accessed by the console.
   }

\defDirective{Dir}{Console}{Client ACL}{}{}{%
   This directive is used to  specify a list of Client resource names that can be accessed by  the console.
   }

\defDirective{Dir}{Console}{Command ACL}{}{}{%
   This directive is used to specify a list of of console commands that can
   be executed by the console.
   See examples at \nameref{section-CommandAclExample}.
   }

\defDirective{Dir}{Console}{Description}{}{}{%
   }

\defDirective{Dir}{Console}{File Set ACL}{}{}{%
   This directive is used to specify a list of FileSet resource names that
   can be accessed by the console.
   }

\defDirective{Dir}{Console}{Job ACL}{}{}{%
   This directive is used to specify a list of Job resource names that can
   be accessed by the console.  Without this directive, the console cannot
   access any of the Director's Job resources.  Multiple Job resource names
   may be specified by separating them with commas, and/or by specifying
   multiple \configdirective{Job ACL} directives.
   For example, the directive may be specified as:
   \bconfigInput{config/DirConsoleJobACL1.conf}
   With the above specification, the console can access the Director's  resources
   for the jobs named on the \configdirective{Job ACL} directives,  but for no others.
   }

\defDirective{Dir}{Console}{Name}{}{}{%
   The name of the console. This  name must match the name specified at the
   Console client.
   }

\defDirective{Dir}{Console}{Password}{}{}{%
   Specifies the password that must be supplied for a named Bareos Console
   to be authorized.
   }

\defDirective{Dir}{Console}{Plugin Options ACL}{}{}{%
   Use this directive to specify the list of allowed Plugin Options.
   }

\defDirective{Dir}{Console}{Pool ACL}{}{}{%
   This directive is used to  specify a list of Pool resource names that can be
   accessed by the console.
   }

\defDirective{Dir}{Console}{Profile}{}{}{%
   One or more Profile names can be assigned to a Console.
   If an ACL is not defined in the Console, the profiles of the Console will be checked in the order as specified here.
   The first found ACL will be used. See \nameref{DirectorResourceProfile}.
   }

\defDirective{Dir}{Console}{Schedule ACL}{}{}{%
   This directive is used to  specify a list of Schedule resource names that can
   be accessed by the console.
   }

\defDirective{Dir}{Console}{Storage ACL}{}{}{%
   This directive is used to  specify a list of Storage resource names that can
   be accessed by  the console.
   }

\defDirective{Dir}{Console}{TLS Allowed CN}{}{}{%
   }

\defDirective{Dir}{Console}{TLS Authenticate}{}{}{%
   }

\defDirective{Dir}{Console}{TLS CA Certificate Dir}{}{}{%
   }

\defDirective{Dir}{Console}{TLS CA Certificate File}{}{}{%
   }

\defDirective{Dir}{Console}{TLS Certificate}{}{}{%
   }

\defDirective{Dir}{Console}{TLS Certificate Revocation List}{}{}{%
   }

\defDirective{Dir}{Console}{TLS DH File}{}{}{%
   }

\defDirective{Dir}{Console}{TLS Enable}{}{}{%
   Bareos can be configured to encrypt all its network traffic.
   See chapter \nameref{TlsDirectives} to see,
   how the Bareos Director (and the other components) must be configured to use TLS.
   }

\defDirective{Dir}{Console}{TLS Key}{}{}{%
   }

\defDirective{Dir}{Console}{TLS Require}{}{}{%
   }

\defDirective{Dir}{Console}{TLS Verify Peer}{}{}{%
   }

\defDirective{Dir}{Console}{Where ACL}{}{}{%
   This directive permits you to specify where a restricted console
   can restore files. If this directive is not specified, only the
   default restore location is permitted (normally \file{/tmp/bareos-restores}.
   If \argument{*all*} is specified any path the
   user enters will be accepted. Any other
   value specified (there may be multiple \configdirective{Where ACL} directives) will
   restrict the user to use that path. For example, on a Unix system,
   if you specify "/", the file will be restored to the original
   location.
   }

The example at :ref:`section-ConsoleAccessExample` shows how to use a console resource for a connection from a client like :command:`bconsole`.

.. _DirectorResourceProfile:

Profile Resource
----------------

:index:`[TAG=Profile Resource] <single: Profile Resource>` :index:`[TAG=Resource->Profile] <pair: Resource; Profile>`

The Profile Resource defines a set of ACLs. :ref:`DirectorResourceConsole`s can be tight to one or more profiles (**Profile**:sup:`Dir`:sub:`Console`\ ), making it easier to use a common set of ACLs.

\defDirective{Dir}{Profile}{Catalog ACL}{}{}{%
   }

\defDirective{Dir}{Profile}{Client ACL}{}{}{%
   }

\defDirective{Dir}{Profile}{Command ACL}{}{}{%
   }

\defDirective{Dir}{Profile}{Description}{}{}{%
   }

\defDirective{Dir}{Profile}{File Set ACL}{}{}{%
   }

\defDirective{Dir}{Profile}{Job ACL}{}{}{%
   }

\defDirective{Dir}{Profile}{Name}{}{}{%
   }

\defDirective{Dir}{Profile}{Plugin Options ACL}{}{}{%
   }

\defDirective{Dir}{Profile}{Pool ACL}{}{}{%
   }

\defDirective{Dir}{Profile}{Schedule ACL}{}{}{%
   }

\defDirective{Dir}{Profile}{Storage ACL}{}{}{%
   }

\defDirective{Dir}{Profile}{Where ACL}{}{}{%
   }

.. _DirectorResourceCounter:

Counter Resource
----------------

:index:`[TAG=Resource->Counter] <pair: Resource; Counter>` :index:`[TAG=Counter Resource] <single: Counter Resource>`

The Counter Resource defines a counter variable that can be accessed by variable expansion used for creating Volume labels with the **Label Format**:sup:`Dir`:sub:`Pool`\  directive.

\defDirective{Dir}{Counter}{Catalog}{}{}{%
   If this directive is  specified, the counter and its values will be saved in
   the specified catalog. If this directive is not present, the  counter will be
   redefined each time that Bareos is started.
   }

\defDirective{Dir}{Counter}{Description}{}{}{%
   }

\defDirective{Dir}{Counter}{Maximum}{}{}{%
   This is the maximum value  value that the counter can have. If not specified
   or set to  zero, the counter can have a maximum value of 2,147,483,648  (2 to
   the 31 power). When the counter is incremented past  this value, it is reset
   to the Minimum.
   }

\defDirective{Dir}{Counter}{Minimum}{}{}{%
   This specifies the minimum  value that the counter can have. It also becomes
   the default.  If not supplied, zero is assumed.
   }

\defDirective{Dir}{Counter}{Name}{}{}{%
   The name of the Counter.  This is the name you will use in the variable
   expansion  to reference the counter value.
   }

\defDirective{Dir}{Counter}{Wrap Counter}{}{}{%
   If this value  is specified, when the counter is incremented past the
   maximum and thus reset to the minimum, the counter specified on the  
   \linkResourceDirective{Dir}{Counter}{Wrap Counter}
   is incremented. (This is currently not implemented).
   }

